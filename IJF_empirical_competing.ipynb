{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f31f6ab",
   "metadata": {},
   "source": [
    "## Lee TH., Seregina E.: \"Combining Forecasts under Structural Breaks Using Graphical LASSO\"\n",
    "\n",
    "### This R notebook can be used to reproduce the values for competing methods (everything except RD-FGL) in Table 1 and Table 2\n",
    "### for both empirical applications\n",
    "\n",
    "#### (Please refer to Python notebook to reproduce RD-FGL in both tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Installing necessary packages\n",
    "\n",
    "if (!require('tseries')) install.packages('tseries'); library(tseries)\n",
    "if (!require('glasso')) install.packages('glasso'); library(glasso)\n",
    "if (!require('huge')) install.packages('huge'); library(huge)\n",
    "if (!require('pracma')) install.packages('pracma'); library(pracma)\n",
    "if (!require('nlshrink')) install.packages('nlshrink'); library(nlshrink)\n",
    "if (!require('glmnet')) install.packages('glmnet'); library(glmnet)\n",
    "if (!require('missForest')) install.packages('missForest'); library(missForest)\n",
    "if (!require('POET')) install.packages('POET'); library(POET)\n",
    "if (!require('matrixcalc')) install.packages('matrixcalc'); library(matrixcalc)\n",
    "if (!require('readr')) install.packages('readr'); library(readr)\n",
    "if (!require('clime')) install.packages('clime'); library(clime)\n",
    "if (!require('MASS')) install.packages('MASS'); library(MASS)\n",
    "if (!require('devtools')) install.packages('devtools'); library(devtools)\n",
    "devtools::install_github(\"cykbennie/fbi\")\n",
    "library(fbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "##########FUNCTIONS FOR FORECAST COMBINATION###########\n",
    "FindWeights=function(INV){\n",
    "  ones=rep(1,nrow(INV))\n",
    "  W=(INV%*%t(t(ones)))/(ones%*%INV%*%t(t(ones)))[[1]]\n",
    "  return(W)\n",
    "}\n",
    "\n",
    "###updated DM test\n",
    "dm_updated = function (e1, e2) {\n",
    "  d <- c(abs(e1))^2 - c(abs(e2))^2\n",
    "  statistic <- (length(d))^(0.5)*mean(d, na.rm = TRUE)/sd(d, na.rm = TRUE)\n",
    "  pval <- 1 - pnorm(statistic, mean = 0, sd = 1)\n",
    "  output <- list(cbind(d), c(statistic), c(pval))\n",
    "  return(output)\n",
    "}\n",
    "\n",
    "# Nodewise estimation of the covariance matrix\n",
    "est_ndwcov <- function(Y,ic){\n",
    "  \n",
    "  # initialization\n",
    "  p <- ncol(Y)\n",
    "  n <- nrow(Y)\n",
    "  Y <- Y- t((apply(Y,2,mean))%*%matrix(1,1,n)) # Y is de-meaned\n",
    "  \n",
    "  C <- matrix(0,p,p)\n",
    "  diag(C) <- 1\n",
    "  tau <- NULL\n",
    "  \n",
    "  # Loop over the assets\n",
    "  for(j in 1:p){\n",
    "    # Estimate the Lasso\n",
    "    jlas <- glmnet(x=Y[,-j],y=Y[,j],family = 'gaussian',intercept = FALSE)\n",
    "    # Get fit\n",
    "    jfit <- predict(jlas, newx=Y[,-j], type=\"response\")    \n",
    "    # residuals\n",
    "    jres <- matrix(Y[,j],n,length(jlas$lambda)) - jfit\n",
    "    # std err\n",
    "    jsig <- colSums(jres^2)/n\n",
    "    # Computing information criterion\n",
    "    if(ic=='WIC') jbic  <- log(jsig) + jlas$df *log(n)/n * log(log(p)) # BIC (Wang,2010)\n",
    "    if(ic=='GIC') jbic  <- log(jsig) + jlas$df *log(p)/n * log(log(n)) # GIC\n",
    "    if(ic=='BIC') jbic  <- log(jsig) + jlas$df *log(n)/n  #BIC\n",
    "    if(ic=='MIC') jbic  <- jsig + jlas$df *log(n) * log(log(p))/n # MC's IC\n",
    "    if(ic=='AIC') jbic  <- log(jsig) + 2 * jlas$df # AIC\n",
    "    # Index of selected model \n",
    "    jind  <- which.min(jbic)\n",
    "    # Get the parameters\n",
    "    jpar <- jlas$beta[,jind]\n",
    "    # Computing tau squared\n",
    "    jtau <- sum(jres[,jind]^2)/n + (1/2)*jlas$lambda[jind]*sum(abs(jpar)) # using (10)\n",
    "    # Storing the parameters\n",
    "    C[j,-j] <- -jpar\n",
    "    tau <- c(tau,jtau)\n",
    "  }\n",
    "  \n",
    "  # Construct T-squared inverse\n",
    "  T2inv <- diag(1/tau)\n",
    "  \n",
    "  # Construct Theta-hat\n",
    "  Theta <- T2inv %*% C\n",
    "  \n",
    "  # sparsity\n",
    "  sp <- sum(Theta==0)/(p^2)\n",
    "  \n",
    "  return(list(NULL,Theta,sp))\n",
    "}\n",
    "###########################################\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e27ea7",
   "metadata": {},
   "source": [
    "### LOADING DATA INSTRUCTIONS:\n",
    "#### ECB SPF:\n",
    "- data for three series is located in DATA -> ECB SPF data -> navigate to the corresponding target series of interest when making selection\n",
    "- \"yhat.csv\" contains forecasts, \"forERR.csv has forecast errors, \"ytrue.csv\" has true series, \"breaks.csv\" contains a break vector for state breaks(as defined in the paper).\n",
    "\n",
    "(Please refer to README.txt for more detailed data instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######ECB SPF APPLICATION######\n",
    "###Loading the data for ECB SPF application\n",
    "#load the data that corresponds to your series of interest (navigate to DATA -> ECB SPF data folder and choose the target series folder)\n",
    "yhat <- read_csv(\"yhat.csv\")\n",
    "forERR <- read_csv(\"forERR.csv\")\n",
    "ytrue <- read_csv(\"ytrue.csv\")\n",
    "Yhat <- as.matrix(yhat)\n",
    "Yhat <- Yhat[1:82, ] \n",
    "# true <- as.matrix(Actual_gdpgrowth_data[,2])\n",
    "# true = true/100\n",
    "true <- as.matrix(ytrue[1:82, ]) \n",
    "forERR <- as.matrix(forERR)\n",
    "forERR <- forERR[1:82, ] \n",
    "y_frac <- as.matrix(ytrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ff141",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################FORECAST COMBINATION ECB SPF################################\n",
    "\n",
    "seqvec = seq(30,50,10)\n",
    "MSFE_total <- matrix(0,(length(seqvec)),14)#14 is the number of competing methods \n",
    "\n",
    "for (l in 1:length(seqvec)){\n",
    "R=seqvec[l]\n",
    "# R=15\n",
    "T=nrow(forERR)\n",
    "m2 =T-R  #Forecasting observations\n",
    "EW=as.matrix(rep(1/(ncol(forERR)),(ncol(forERR))))\n",
    "####FORECAST ERRORS MATRICES####\n",
    "FEEW= matrix(0,m2,1)\n",
    "FEFGL= matrix(0,m2,1)\n",
    "FEGL= matrix(0,m2,1)\n",
    "FELW= matrix(0,m2,1)\n",
    "FELW_set= matrix(0,m2,1)\n",
    "FEPOET= matrix(0,m2,1)\n",
    "FENLW= matrix(0,m2,1)\n",
    "FENLW_set= matrix(0,m2,1)\n",
    "FECLIME= matrix(0,m2,1)\n",
    "FECLIME_set= matrix(0,m2,1)\n",
    "FEnotsparse= matrix(0,m2,1)\n",
    "FEMB= matrix(0,m2,1)\n",
    "FEFMB= matrix(0,m2,1)\n",
    "FEAR1= matrix(0,m2,1)\n",
    "#####SFEs####\n",
    "SFEEW= matrix(0,m2,1)\n",
    "SFEFGL= matrix(0,m2,1)\n",
    "SFEGL= matrix(0,m2,1)\n",
    "SFELW= matrix(0,m2,1)\n",
    "SFELW_set= matrix(0,m2,1)\n",
    "SFEPOET= matrix(0,m2,1)\n",
    "SFENLW= matrix(0,m2,1)\n",
    "SFENLW_set= matrix(0,m2,1)\n",
    "SFECLIME= matrix(0,m2,1)\n",
    "SFECLIME_set= matrix(0,m2,1)\n",
    "SFEnotsparse= matrix(0,m2,1)\n",
    "SFEMB= matrix(0,m2,1)\n",
    "SFEFMB= matrix(0,m2,1)\n",
    "SFEAR1= matrix(0,m2,1)\n",
    "for(j in 1:m2)  {\n",
    "  print(paste0(\"l,j= \",l,\",\",j))\n",
    "  set = forERR[j:(j+R-1),]\n",
    "  # k=POETKhat(t(set))\n",
    "  # k= k[[\"K1BN\"]]\n",
    "  # k=1\n",
    "  k=2\n",
    "  betas <- eigen(t(set)%*%set)[[\"vectors\"]][,1:k]\n",
    "  covariate <- as.matrix(prcomp(set)[[\"x\"]][,(1:k)]) ##these are factors like Fhat\n",
    "  betas = as.matrix(betas) # p*K\n",
    "  betas = t(betas) #K*p\n",
    "  residuals <- set - covariate%*%betas\n",
    "  epshat <- as.matrix(residuals)\n",
    "  \n",
    " #######FGL########\n",
    "  covU = cov(epshat)\n",
    "  fwgl <- rglasso(covU,weight = TRUE, N=nrow(set)-1)\n",
    "  ThetaFWGL1 = fwgl[[2]]\n",
    "  # est1 = huge(epshat, method = \"glasso\", lambda=NULL, scr = TRUE, cov.output = FALSE, verbose = FALSE)\n",
    "  # out.select1 = huge.select(est1,criterion = \"ebic\",ebic.gamma = 1)\n",
    "  # ThetaFWGL1 = out.select1[[\"opt.icov\"]]\n",
    "  if (k==1){\n",
    "    ThetaFWGL2 = ThetaFWGL1 - ThetaFWGL1%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                               betas%*%ThetaFWGL1%*%t(betas))%*%betas%*%ThetaFWGL1\n",
    "  } else {\n",
    "    ThetaFWGL2 = ThetaFWGL1 - ThetaFWGL1%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                               betas%*%ThetaFWGL1%*%t(betas))%*%betas%*%ThetaFWGL1\n",
    "  }\n",
    "  \n",
    "  ########GLASSO#######\n",
    "  covE = cov(set)\n",
    "  wgl <- rglasso(covE,weight = TRUE, N=nrow(set)-1)\n",
    "  ThetaGL = wgl[[2]]\n",
    "  # est2 = huge(set, method = \"glasso\", lambda=NULL, scr = TRUE, cov.output = FALSE, verbose = FALSE)\n",
    "  # out.select2 = huge.select(est2,criterion = \"ebic\",ebic.gamma = 1)\n",
    "  # ThetaGL = out.select2[[\"opt.icov\"]]\n",
    "  \n",
    "  ########LW#############\n",
    "  cov_LW = linshrink_cov(set, k = 0)\n",
    "  \n",
    "  LWTheta_set = solve(cov_LW)\n",
    "  \n",
    "  ########FLW#############\n",
    "  covU_LW = linshrink_cov(epshat, k = 0)\n",
    "  if (k==1){\n",
    "    LWTheta = solve(covU_LW) -  solve(covU_LW)%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                       betas%*% solve(covU_LW)%*%t(betas))%*%betas%*% solve(covU_LW)\n",
    "  } else {\n",
    "    LWTheta = solve(covU_LW) -  solve(covU_LW)%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                       betas%*% solve(covU_LW)%*%t(betas))%*%betas%*% solve(covU_LW)\n",
    "  }\n",
    "  \n",
    "  ########NLW#############\n",
    "  cov_NL=nlshrink_cov(set, k = 0,method = \"nloptr\")\n",
    "  NLWTheta_set = solve(cov_NL)\n",
    "  \n",
    "  ########FNLW#############\n",
    "  covU_NL=nlshrink_cov(epshat, k = 0,method = \"nloptr\")\n",
    "  if (is.singular.matrix(covU_NL)== TRUE){\n",
    "    ThetaU_NL = ginv(covU_NL)\n",
    "  } else {\n",
    "    ThetaU_NL = solve(covU_NL)\n",
    "  }\n",
    "  if (k==1){\n",
    "    NLWTheta = ThetaU_NL -  ThetaU_NL%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                          betas%*%ThetaU_NL%*%t(betas))%*%betas%*% ThetaU_NL\n",
    "  } else {\n",
    "    NLWTheta = ThetaU_NL -  ThetaU_NL%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                          betas%*% ThetaU_NL%*%t(betas))%*%betas%*% ThetaU_NL\n",
    "  }\n",
    "  ############POET##################\n",
    "  \n",
    "  covPOET=POET(t(epshat),K=k,0.5,\"soft\",\"vad\")$SigmaY\n",
    "  #covY are sample covariancematrix of returns by POET,0.5,SOFT,VAD ARE DEFAULTS, \n",
    "  #7 FACTORS ARE  RECOMMENDED BY POET PROGRAM,ALTERNATIVE IS ESTIMATE AND FIT\n",
    "  ThetaPOET=solve(covPOET)#INVERSE MATRIX PRECISION ESTIMATE\n",
    "\n",
    "  ##########CLIME########\n",
    "  # clime_est = fastclime(set)\n",
    "  # out2 = fastclime.selector(clime_est$lambdamtx, clime_est$icovlist,0.2)\n",
    "  # ThetaFClime_set = out2$icov\n",
    "  ##optimal lambda was giving an error of non-singularity, so just using lambda=0.8\n",
    "  ## (which corresponded to smallest loss)\n",
    "  ## FOR GDP set lambda=0.8\n",
    "  ## FOR CPI set lambda=0.01 \n",
    "  ##NOTE: sometimes linsolver=\"primaldual\" raises non-singularity error -> can try simplex instead\n",
    "  re.clime <- clime(set, standardize=FALSE, lambda = 0.01, linsolver=\"simplex\") ##X is n (observations) times p (variables)\n",
    "  # re.cv <- cv.clime(re.clime)\n",
    "  # re.clime.opt <- clime(set, standardize=FALSE, re.cv$lambdaopt)\n",
    "  ThetaFClime_set <- re.clime[[\"Omegalist\"]][[1]]\n",
    "  \n",
    "  ##########FCLIME########\n",
    "  ##same issue with using optimal lambda as above\n",
    "  re.clime <- clime(epshat, standardize=FALSE, lambda = 0.01, linsolver=\"simplex\") ##X is n (observations) times p (variables)\n",
    "  # re.cv <- cv.clime(re.clime)\n",
    "  # re.clime.opt <- clime(epshat, standardize=FALSE, re.cv$lambdaopt)\n",
    "  # ClimeTheta <- re.clime.opt[[\"Omegalist\"]][[1]]\n",
    "  ClimeTheta <- re.clime[[\"Omegalist\"]][[1]]\n",
    "  \n",
    "  \n",
    "  # clime_est = fastclime(epshat)\n",
    "  # out2 = fastclime.selector(clime_est$lambdamtx, clime_est$icovlist,0.2)\n",
    "  # ClimeTheta = out2$icov\n",
    "  if (k==1){\n",
    "    ThetaFClime = ClimeTheta - ClimeTheta%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                                betas%*%ClimeTheta%*%t(betas))%*%betas%*%ClimeTheta\n",
    "  } else {\n",
    "    ThetaFClime = ClimeTheta - ClimeTheta%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                                betas%*%ClimeTheta%*%t(betas))%*%betas%*%ClimeTheta\n",
    "  }\n",
    "\n",
    "  ##########FFs WITHOUT SPARSITY RESTRICTION\n",
    "  prec1 = ginv(cov(epshat))\n",
    "  if (k==1){\n",
    "  Theta1 = prec1 - prec1%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                betas%*%prec1%*%t(betas))%*%betas%*%prec1\n",
    "  } else {\n",
    "  Theta1 = prec1 - prec1%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                  betas%*%prec1%*%t(betas))%*%betas%*%prec1\n",
    "  }\n",
    "  ########################NODEWISE REGRESSION#########################\n",
    "  ######################################################################\n",
    "  nodewise <- est_ndwcov(set,ic = \"GIC\")\n",
    "  ThetaMB <- nodewise[[2]]\n",
    "  ########################FACTOR NODEWISE REGRESSION#########################\n",
    "  ######################################################################\n",
    "  nodewise_factor <- est_ndwcov(epshat,ic = \"GIC\")\n",
    "  ThetaFMB_eps <- nodewise_factor[[2]]\n",
    "  if (k==1){\n",
    "    ThetaFMB = ThetaFMB_eps - ThetaFMB_eps%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                          betas%*%ThetaFMB_eps%*%t(betas))%*%betas%*%ThetaFMB_eps\n",
    "  } else {\n",
    "    ThetaFMB = ThetaFMB_eps - ThetaFMB_eps%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                          betas%*%ThetaFMB_eps%*%t(betas))%*%betas%*%ThetaFMB_eps\n",
    "  }\n",
    "  \n",
    "  \n",
    "  wGL=FindWeights(ThetaFWGL2)  \n",
    "  wFGL=FindWeights(ThetaGL)\n",
    "  wLW=FindWeights(LWTheta)\n",
    "  wLW_set=FindWeights(LWTheta_set)\n",
    "  wPOET=FindWeights(ThetaPOET)\n",
    "  wNLW=FindWeights(NLWTheta)\n",
    "  wNLW_set=FindWeights(NLWTheta_set)\n",
    "  wCLIME=FindWeights(ThetaFClime)\n",
    "  wCLIME_set=FindWeights(ThetaFClime_set)\n",
    "  wnotsparse=FindWeights(Theta1)\n",
    "  wMB=FindWeights(ThetaMB)\n",
    "  wFMB=FindWeights(ThetaFMB)\n",
    "  \n",
    "###############################################\n",
    "##############AR(1) FORECAST#################\n",
    "myts <- ts(ytrue_ts[,2], start=c(1999,4), end=c(2024, 1), frequency=4)  \n",
    "  \n",
    "ytrue_ar <- myts[j:(j+R-1)]  \n",
    "ar1 <- arima(ytrue_ar, order = c(1,0,0), method=\"CSS\") # method=\"ML\" forces the model to be stationary\n",
    "#BUT it sometimes raises an error that the system is singular, so can choose method=\"CSS\" \n",
    "pred_ar = y_frac[R]*ar1[[\"coef\"]][[1]]  + ar1[[\"coef\"]][[2]]\n",
    "FEAR1[j] = y_frac[R +j] - pred_ar\n",
    "###############MODEL FORECASTS ARE HERE######\n",
    "FEFGL[j]=y_frac[R +j]- t(wFGL)%*%Yhat[R +j,]\n",
    "FEEW[j]=y_frac[R +j]- t(EW)%*%Yhat[R +j,]\n",
    "FEGL[j]= y_frac[R +j]- t(wGL)%*%Yhat[R +j,]\n",
    "FELW[j]=y_frac[R +j]- t(wLW)%*%Yhat[R +j,]\n",
    "FELW_set[j]=y_frac[R +j]- t(wLW_set)%*%Yhat[R +j,]\n",
    "FEPOET[j]= y_frac[R +j]- t(wPOET)%*%Yhat[R +j,]\n",
    "FENLW[j]= y_frac[R +j]- t(wNLW)%*%Yhat[R +j,]\n",
    "FENLW_set[j]= y_frac[R +j]- t(wNLW_set)%*%Yhat[R +j,]\n",
    "FECLIME[j]= y_frac[R +j]- t(wCLIME)%*%Yhat[R +j,]\n",
    "FECLIME_set[j]= y_frac[R +j]- t(wCLIME_set)%*%Yhat[R +j,]\n",
    "FEnotsparse[j]= y_frac[R +j]- t(wnotsparse)%*%Yhat[R +j,]\n",
    "FEMB[j]=y_frac[R +j]- t(wMB)%*%Yhat[R +j,]\n",
    "FEFMB[j]= y_frac[R +j]- t(wFMB)%*%Yhat[R +j,]\n",
    "\n",
    "#################SFEs ARE HERE##################\n",
    "  SFEAR1[j] = (FEAR1[j])^2\n",
    "  SFEFGL[j]=(y_frac[R +j]- t(wFGL)%*%Yhat[R +j,])^(2)\n",
    "  SFEEW[j]=(y_frac[R +j]- t(EW)%*%Yhat[R +j,])^(2)\n",
    "  SFEGL[j]=(y_frac[R +j]- t(wGL)%*%Yhat[R +j,])^(2)\n",
    "  SFELW[j]=(y_frac[R +j]- t(wLW)%*%Yhat[R +j,])^(2)\n",
    "  SFELW_set[j]=(y_frac[R +j]- t(wLW_set)%*%Yhat[R +j,])^(2)\n",
    "  SFEPOET[j]=(y_frac[R +j]- t(wPOET)%*%Yhat[R +j,])^(2)\n",
    "  SFENLW[j]=(y_frac[R +j]- t(wNLW)%*%Yhat[R +j,])^(2)\n",
    "  SFENLW_set[j]=(y_frac[R +j]- t(wNLW_set)%*%Yhat[R +j,])^(2)\n",
    "  SFECLIME[j]=(y_frac[R +j]- t(wCLIME)%*%Yhat[R +j,])^(2)\n",
    "  SFECLIME_set[j]=(y_frac[R +j]- t(wCLIME_set)%*%Yhat[R +j,])^(2)\n",
    "  SFEnotsparse[j]=(y_frac[R +j]- t(wnotsparse)%*%Yhat[R +j,])^(2)\n",
    "  SFEMB[j]=(y_frac[R +j]- t(wMB)%*%Yhat[R +j,])^(2)\n",
    "  SFEFMB[j]=(y_frac[R +j]- t(wFMB)%*%Yhat[R +j,])^(2)\n",
    "  \n",
    "\n",
    "##################\n",
    "  \n",
    "}\n",
    "MSFE1=mean(SFEEW)\n",
    "MSFE2=mean(SFEFGL)\n",
    "MSFE3=mean(SFEGL)\n",
    "MSFE4=mean(SFELW)\n",
    "MSFE5=mean(SFENLW)\n",
    "MSFE6=mean(SFEPOET)\n",
    "MSFE7=mean(SFECLIME)\n",
    "MSFE8=mean(SFEnotsparse)\n",
    "MSFE9=mean(SFEMB)\n",
    "MSFE10=mean(SFEFMB)\n",
    "MSFE11=mean(SFELW_set)\n",
    "MSFE12=mean(SFENLW_set)\n",
    "MSFE13=mean(SFECLIME_set)\n",
    "MSFE14=mean(SFEAR1)\n",
    "\n",
    "\n",
    "A = NULL\n",
    "A = rbind(A,c(MSFE1, MSFE2, MSFE3, MSFE4, MSFE5, MSFE6,MSFE7, MSFE8,MSFE9,MSFE10,MSFE11,MSFE12,MSFE13, MSFE14))\n",
    "write.csv(A,file=\"MSFE_ECB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f251265",
   "metadata": {},
   "source": [
    "### LOADING DATA INSTRUCTIONS:\n",
    "#### FRED MD:\n",
    "- data for four series is located in DATA -> FRED MD data -> navigate to the corresponding target series of interest when making selection\n",
    "- \"yhat.csv\" contains forecasts, \"forERR.csv has forecast errors, \"ytrue.csv\" has true series, \"breaks.csv\" contains a break vector for state breaks(as defined in the paper).\n",
    "- In case you would like to update the data, we followed the following steps to obtain forecasts:\n",
    " 1) use the code cell titled \"Updating FRED MD forecasts\" below to obtain forecasts up to 4 steps ahead\n",
    "\n",
    "(Please refer to README.txt for more detailed data instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af66078",
   "metadata": {},
   "outputs": [],
   "source": [
    "##UPDATING FRED MD forecasts (DON'T RUN UNLESS you would like to reproduce forecasts OR update forecasts using recent data)\n",
    "\n",
    "data = fredmd(file='current.csv', transform = TRUE)\n",
    "\n",
    "write.csv(data,file=\"data.csv\")\n",
    "\n",
    "X1 <- as.matrix(data)\n",
    "X1 <- X1[,-c(24)] ## 6 is INDPROD, 105 is CPIAUCSL, 115 is PCEPI, 24 is UNRATE\n",
    "X1 <- X1[(1+h):788,]\n",
    "y1 <- as.matrix(current)\n",
    "y <- y[2:789]\n",
    "\n",
    "scaled.X1 <- scale(X1, center = TRUE, scale = TRUE)\n",
    "IMPscaled.X1 <- missForest(scaled.X1)\n",
    "scaled.X1 <- as.matrix(IMPscaled.X1[[\"ximp\"]])\n",
    "X <- scaled.X1\n",
    "y <- y1[2:788,24:24] \n",
    "\n",
    "sum(is.na(y))\n",
    "sum(is.na(X))\n",
    "y_backup <- y\n",
    "X_backup <- X\n",
    "\n",
    "#set forecasting horizon\n",
    "h=1\n",
    "###FOR GROWTH RATES###\n",
    "y_g <- NULL\n",
    "count=0\n",
    "for (i in 2:(length(y_backup))) {\n",
    "  count = count + 1\n",
    "  y_g[count] = (1/h)*log(y_backup[i]/y_backup[i-h])\n",
    "}\n",
    "\n",
    "y <- y_g\n",
    "\n",
    "###FOR CHANGES### (E.G. UNRATE)\n",
    "y_g <- NULL\n",
    "count=0\n",
    "for (i in 2:(length(y_backup))) {\n",
    "  count = count + 1\n",
    "  y_g[count] = (1/h)*(y_backup[i]-y_backup[i-h])\n",
    "}\n",
    "\n",
    "y <- y_g\n",
    "\n",
    "\n",
    "##DATA for FRED-MD Application can be found in DATA folder (X is the dataset of macro series excluding the target,\n",
    "#and y is the target series (INDPROD, CPIAUCSL, PCEPI, or UNRATE))\n",
    "\n",
    "#1) First we need to produce forecasts (Yhats) and forecast errors for FRED-MD application, \n",
    "#which is done by forecasting the target with each column of X one at a time\n",
    "\n",
    "###forecasting with each column at a time\n",
    "T=nrow(X)\n",
    "m1=240\n",
    "m2 =T-m1  #Forecasting observations\n",
    "\n",
    "####for trying if the code works for smaller sample size\n",
    "\n",
    "Yhat = matrix(0,m2,ncol(X))\n",
    "Yhat2 = matrix(0,(m2-2+1),ncol(X))\n",
    "Yhat3 = matrix(0,(m2-3+1),ncol(X))\n",
    "Yhat4 = matrix(0,(m2-4+1),ncol(X))\n",
    "\n",
    "\n",
    "for (col in 1:ncol(X))  {\n",
    "  x1 = X[,col]\n",
    "  for (row in 1:m2){\n",
    "    ######################\n",
    "    #FOR h=1\n",
    "    ######################\n",
    "    const = ones((m1-1),1)\n",
    "    regr <- x1[1:(m1-1)]\n",
    "    xx = cbind(const,regr)\n",
    "    \n",
    "    coef = solve(t(xx)%*%xx)%*%t(xx)%*%y[(row+1):(m1-1+row)]\n",
    "    \n",
    "    Yhat[row,col] = c(1, x1[m1-1+row])%*%coef\n",
    "    \n",
    "    # model = lm(y[(row+h):(m1-1+row)] ~ regr) #checking if using LM gives the same result (it does)\n",
    "  }\n",
    "    ######################\n",
    "    #FOR h=2\n",
    "    ######################\n",
    "  for (row2 in 1:(m2-2+1)){\n",
    "    const = ones((m1-2),1)\n",
    "    regr <- x1[1:(m1-2)]\n",
    "    xx = cbind(const,regr)\n",
    "    \n",
    "    coef = solve(t(xx)%*%xx)%*%t(xx)%*%y[(row2+2):(m1-1+row2)]\n",
    "    \n",
    "    Yhat2[row2,col] = c(1, x1[m1-1+row2])%*%coef\n",
    "  }\n",
    "    ######################\n",
    "    #FOR h=3\n",
    "    ######################\n",
    "  for (row3 in 1:(m2-3+1)){\n",
    "    const = ones((m1-3),1)\n",
    "    regr <- x1[1:(m1-3)]\n",
    "    xx = cbind(const,regr)\n",
    "    \n",
    "    coef = solve(t(xx)%*%xx)%*%t(xx)%*%y[(row3+3):(m1-1+row3)]\n",
    "    \n",
    "    Yhat3[row3,col] = c(1, x1[m1-1+row3])%*%coef\n",
    "  }\n",
    "    ######################\n",
    "    #FOR h=4\n",
    "    ######################\n",
    "  for (row4 in 1:(m2-4+1)){\n",
    "    const = ones((m1-4),1)\n",
    "    regr <- x1[1:(m1-4)]\n",
    "    xx = cbind(const,regr)\n",
    "    \n",
    "    coef = solve(t(xx)%*%xx)%*%t(xx)%*%y[(row4+4):(m1-1+row4)]\n",
    "    \n",
    "    Yhat4[row4,col] = c(1, x1[m1-1+row4])%*%coef\n",
    "\n",
    "  }\n",
    "}\n",
    "\n",
    "#####computing forecast errors\n",
    "forERR=matrix(y[(m1 +1):T], m2, (ncol(X)))-Yhat\n",
    "forERR2=matrix(y[(m1 +2):T], (m2-2+1), ncol(X))-Yhat2\n",
    "forERR3=matrix(y[(m1 +3):T], (m2-3+1), ncol(X))-Yhat3\n",
    "forERR4=matrix(y[(m1 +4):T], (m2-4+1), ncol(X))-Yhat4\n",
    "\n",
    "\n",
    "write.csv(Yhat,file=\"yhat.csv\")\n",
    "write.csv(forERR,file=\"forERR.csv\")\n",
    "\n",
    "write.csv(Yhat2,file=\"yhat2.csv\")\n",
    "write.csv(forERR2,file=\"forERR2.csv\")\n",
    "\n",
    "write.csv(Yhat3,file=\"yhat3.csv\")\n",
    "write.csv(forERR3,file=\"forERR3.csv\")\n",
    "\n",
    "write.csv(Yhat4,file=\"yhat4.csv\")\n",
    "write.csv(forERR4,file=\"forERR4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################FORECAST COMBINATION FRED-MD################################\n",
    "## DATA -> FRED MD data -> navigate to the corresponding target series of interest\n",
    "yhat <- read_csv(\"yhat.csv\", col_types = cols(...1 = col_skip()))\n",
    "forERR <- read_csv(\"forERR.csv\", col_types = cols(...1 = col_skip()))\n",
    "true <- read_csv(\"true.csv\", col_types = cols(...1 = col_skip()))\n",
    "Yhat <- as.matrix(yhat)\n",
    "true <- as.matrix(true)\n",
    "forERR <- as.matrix(forERR)\n",
    "y_frac <- true\n",
    "\n",
    "#2) Once we have the forecasts we can proceed to forecast combination\n",
    "seqvec = seq(400,400,100)\n",
    "MSFE_total <- matrix(0,(length(seqvec)),14)#14 is the number of competing methods\n",
    "PVAL_total <- matrix(0,(length(seqvec)),14) #13 is the #of competing methods (MSFE_TOTAL-1 + EW as first element of 0 since its a threshold)\n",
    "statGL <- list()\n",
    "statFGL <- list()\n",
    "statFLW <- list()\n",
    "statLW <- list()\n",
    "statPOET <- list()\n",
    "statFNLW <- list()\n",
    "statNLW <- list()\n",
    "statFCLIME <- list()\n",
    "statCLIME <- list()\n",
    "statnotsparse <- list()\n",
    "statMB <- list()\n",
    "statFMB <- list()\n",
    "statAR <- list()\n",
    "for (l in 1:length(seqvec)){\n",
    "  R=seqvec[l]\n",
    "  T=nrow(forERR)\n",
    "  m2 =T-R  #Forecasting observations\n",
    "  EW=as.matrix(rep(1/(ncol(forERR)),(ncol(forERR))))\n",
    "  ####FORECAST ERRORS MATRICES####\n",
    "  FEEW= matrix(0,m2,1)\n",
    "  FEFGL= matrix(0,m2,1)\n",
    "  FEGL= matrix(0,m2,1)\n",
    "  FELW= matrix(0,m2,1)\n",
    "  FELW_set= matrix(0,m2,1)\n",
    "  FEPOET= matrix(0,m2,1)\n",
    "  FENLW= matrix(0,m2,1)\n",
    "  FENLW_set= matrix(0,m2,1)\n",
    "  FECLIME= matrix(0,m2,1)\n",
    "  FECLIME_set= matrix(0,m2,1)\n",
    "  FEnotsparse= matrix(0,m2,1)\n",
    "  FEMB= matrix(0,m2,1)\n",
    "  FEFMB= matrix(0,m2,1)\n",
    "  FEAR1= matrix(0,m2,1)\n",
    "  #####SFEs####\n",
    "  SFEEW= matrix(0,m2,1)\n",
    "  SFEFGL= matrix(0,m2,1)\n",
    "  SFEGL= matrix(0,m2,1)\n",
    "  SFELW= matrix(0,m2,1)\n",
    "  SFELW_set= matrix(0,m2,1)\n",
    "  SFEPOET= matrix(0,m2,1)\n",
    "  SFENLW= matrix(0,m2,1)\n",
    "  SFENLW_set= matrix(0,m2,1)\n",
    "  SFECLIME= matrix(0,m2,1)\n",
    "  SFECLIME_set= matrix(0,m2,1)\n",
    "  SFEnotsparse= matrix(0,m2,1)\n",
    "  SFEMB= matrix(0,m2,1)\n",
    "  SFEFMB= matrix(0,m2,1)\n",
    "  SFEAR1= matrix(0,m2,1)\n",
    "  for(j in 1:m2)  {\n",
    "    print(paste0(\"l,j= \",l,\",\",j))\n",
    "    set = forERR[j:(j+R-1),]\n",
    "    # k=POETKhat(t(set))\n",
    "    # k= k[[\"K1BN\"]]\n",
    "    # k=1\n",
    "    k=2\n",
    "    betas <- eigen(t(set)%*%set)[[\"vectors\"]][,1:k]\n",
    "    covariate <- as.matrix(prcomp(set)[[\"x\"]][,(1:k)]) ##these are factors like Fhat\n",
    "    betas = as.matrix(betas) # p*K\n",
    "    betas = t(betas) #K*p\n",
    "    residuals <- set - covariate%*%betas\n",
    "    epshat <- as.matrix(residuals)\n",
    "    \n",
    "    #######FGL########\n",
    "    covU = cov(epshat)\n",
    "    # fwgl <- rglasso(covU,weight = TRUE, N=nrow(set)-1)\n",
    "    # ThetaFWGL1 = fwgl[[2]]\n",
    "    est1 = huge(epshat, method = \"glasso\", lambda=NULL, scr = TRUE, cov.output = FALSE, verbose = FALSE)\n",
    "    out.select1 = huge.select(est1,criterion = \"ebic\",ebic.gamma = 1)\n",
    "    ThetaFWGL1 = out.select1[[\"opt.icov\"]]\n",
    "    if (k==1){\n",
    "      ThetaFWGL2 = ThetaFWGL1 - ThetaFWGL1%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                                 betas%*%ThetaFWGL1%*%t(betas))%*%betas%*%ThetaFWGL1\n",
    "    } else {\n",
    "      ThetaFWGL2 = ThetaFWGL1 - ThetaFWGL1%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                                 betas%*%ThetaFWGL1%*%t(betas))%*%betas%*%ThetaFWGL1\n",
    "    }\n",
    "    \n",
    "    ########GLASSO#######\n",
    "    covE = cov(set)\n",
    "    # wgl <- rglasso(covE,weight = TRUE, N=nrow(set)-1)\n",
    "    # ThetaGL = wgl[[2]]\n",
    "    # set_scaled <- scale(set)\n",
    "    est2 = huge(set, method = \"glasso\", lambda=NULL, scr = TRUE, cov.output = FALSE, verbose = FALSE)\n",
    "    out.select2 = huge.select(est2,criterion = \"ebic\",ebic.gamma = 1)\n",
    "    ThetaGL = out.select2[[\"opt.icov\"]]\n",
    "    \n",
    "    ########LW#############\n",
    "    cov_LW = linshrink_cov(set, k = 0)\n",
    "    \n",
    "    LWTheta_set = solve(cov_LW)\n",
    "    \n",
    "    ########FLW#############\n",
    "    covU_LW = linshrink_cov(epshat, k = 0)\n",
    "    if (k==1){\n",
    "      LWTheta = solve(covU_LW) -  solve(covU_LW)%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                                       betas%*% solve(covU_LW)%*%t(betas))%*%betas%*% solve(covU_LW)\n",
    "    } else {\n",
    "      LWTheta = solve(covU_LW) -  solve(covU_LW)%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                                       betas%*% solve(covU_LW)%*%t(betas))%*%betas%*% solve(covU_LW)\n",
    "    }\n",
    "    \n",
    "    ########NLW#############\n",
    "    cov_NL=nlshrink_cov(set, k = 0,method = \"nloptr\")\n",
    "    NLWTheta_set = solve(cov_NL)\n",
    "    \n",
    "    ########FNLW#############\n",
    "    covU_NL=nlshrink_cov(epshat, k = 0,method = \"nloptr\")\n",
    "    if (is.singular.matrix(covU_NL)== TRUE){\n",
    "      ThetaU_NL = ginv(covU_NL)\n",
    "    } else {\n",
    "      ThetaU_NL = solve(covU_NL)\n",
    "    }\n",
    "    if (k==1){\n",
    "      NLWTheta = ThetaU_NL -  ThetaU_NL%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                              betas%*%ThetaU_NL%*%t(betas))%*%betas%*% ThetaU_NL\n",
    "    } else {\n",
    "      NLWTheta = ThetaU_NL -  ThetaU_NL%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                              betas%*% ThetaU_NL%*%t(betas))%*%betas%*% ThetaU_NL\n",
    "    }\n",
    "    ############POET##################\n",
    "    \n",
    "    covPOET=POET(t(epshat),K=k,0.5,\"soft\",\"vad\")$SigmaY\n",
    "    #covY are sample covariancematrix of returns by POET,0.5,SOFT,VAD ARE DEFAULTS, \n",
    "    ThetaPOET=solve(covPOET)#INVERSE MATRIX PRECISION ESTIMATE\n",
    "    \n",
    "    ##########CLIME########\n",
    "    # clime_est = fastclime(set)\n",
    "    # out2 = fastclime.selector(clime_est$lambdamtx, clime_est$icovlist,0.2)\n",
    "    # ThetaFClime_set = out2$icov\n",
    "    ##optimal lambda was giving an error of non-singularity, so just using lambda=0.8\n",
    "    ## (which corresponded to smallest loss)\n",
    "    ## FOR GDP set lambda=0.8\n",
    "    ## FOR CPI set lambda=0.01 \n",
    "    ##NOTE: sometimes linsolver=\"primaldual\" raises non-singularity error -> can try simplex instead\n",
    "    re.clime <- clime(set, standardize=FALSE, lambda = 0.01, linsolver=\"simplex\") ##X is n (observations) times p (variables)\n",
    "    # re.cv <- cv.clime(re.clime)\n",
    "    # re.clime.opt <- clime(set, standardize=FALSE, re.cv$lambdaopt)\n",
    "    ThetaFClime_set <- re.clime[[\"Omegalist\"]][[1]]\n",
    "    \n",
    "    ##########FCLIME########\n",
    "    ##same issue with using optimal lambda as above\n",
    "    re.clime <- clime(epshat, standardize=FALSE, lambda = 0.01, linsolver=\"simplex\") ##X is n (observations) times p (variables)\n",
    "    # re.cv <- cv.clime(re.clime)\n",
    "    # re.clime.opt <- clime(epshat, standardize=FALSE, re.cv$lambdaopt)\n",
    "    # ClimeTheta <- re.clime.opt[[\"Omegalist\"]][[1]]\n",
    "    ClimeTheta <- re.clime[[\"Omegalist\"]][[1]]\n",
    "    \n",
    "    \n",
    "    # clime_est = fastclime(epshat)\n",
    "    # out2 = fastclime.selector(clime_est$lambdamtx, clime_est$icovlist,0.2)\n",
    "    # ClimeTheta = out2$icov\n",
    "    if (k==1){\n",
    "      ThetaFClime = ClimeTheta - ClimeTheta%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                                  betas%*%ClimeTheta%*%t(betas))%*%betas%*%ClimeTheta\n",
    "    } else {\n",
    "      ThetaFClime = ClimeTheta - ClimeTheta%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                                  betas%*%ClimeTheta%*%t(betas))%*%betas%*%ClimeTheta\n",
    "    }\n",
    "    \n",
    "    ##########FFs WITHOUT SPARSITY RESTRICTION\n",
    "    prec1 = ginv(cov(epshat))\n",
    "    if (k==1){\n",
    "      Theta1 = prec1 - prec1%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                   betas%*%prec1%*%t(betas))%*%betas%*%prec1\n",
    "    } else {\n",
    "      Theta1 = prec1 - prec1%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                   betas%*%prec1%*%t(betas))%*%betas%*%prec1\n",
    "    }\n",
    "    ########################NODEWISE REGRESSION#########################\n",
    "    ######################################################################\n",
    "    nodewise <- est_ndwcov(set,ic = \"GIC\")\n",
    "    ThetaMB <- nodewise[[2]]\n",
    "    ########################FACTOR NODEWISE REGRESSION#########################\n",
    "    ######################################################################\n",
    "    nodewise_factor <- est_ndwcov(epshat,ic = \"GIC\")\n",
    "    ThetaFMB_eps <- nodewise_factor[[2]]\n",
    "    if (k==1){\n",
    "      ThetaFMB = ThetaFMB_eps - ThetaFMB_eps%*%t(betas)%*%solve( (var(covariate))^(-1)+\n",
    "                                                                   betas%*%ThetaFMB_eps%*%t(betas))%*%betas%*%ThetaFMB_eps\n",
    "    } else {\n",
    "      ThetaFMB = ThetaFMB_eps - ThetaFMB_eps%*%t(betas)%*%solve( solve(cov(covariate))+\n",
    "                                                                   betas%*%ThetaFMB_eps%*%t(betas))%*%betas%*%ThetaFMB_eps\n",
    "    }\n",
    "    \n",
    "    wGL=FindWeights(ThetaFWGL2)\n",
    "    wFGL=FindWeights(ThetaGL) \n",
    "    wLW=FindWeights(LWTheta)\n",
    "    wLW_set=FindWeights(LWTheta_set)\n",
    "    wPOET=FindWeights(ThetaPOET)\n",
    "    wNLW=FindWeights(NLWTheta)\n",
    "    wNLW_set=FindWeights(NLWTheta_set)\n",
    "    wCLIME=FindWeights(ThetaFClime)\n",
    "    wCLIME_set=FindWeights(ThetaFClime_set)\n",
    "    wnotsparse=FindWeights(Theta1)\n",
    "    wMB=FindWeights(ThetaMB)\n",
    "    wFMB=FindWeights(ThetaFMB)\n",
    "    \n",
    "    ###############################################\n",
    "    ##############AR(1) FORECAST#################\n",
    "    myts <- ts(ytrue_ts[,2], start=c(1959,2,1), end=c(2024, 8,1), frequency=12) \n",
    "    \n",
    "    ytrue_ar <- myts[j:(j+R-1)]  \n",
    "    ar1 <- arima(ytrue_ar, order = c(1,0,0), method=\"CSS\") # method=\"ML\" forces the model to be stationary\n",
    "    #BUT it sometimes raises an error that the system is singular, so can choose method=\"CSS\" \n",
    "    pred_ar = y_frac[R]*ar1[[\"coef\"]][[1]]  + ar1[[\"coef\"]][[2]]\n",
    "    FEAR1[j] = y_frac[R +j] - pred_ar\n",
    "    ###############MODEL FORECASTS ARE HERE######\n",
    "    FEFGL[j]=y_frac[R +j]- t(wFGL)%*%Yhat[R +j,]\n",
    "    FEEW[j]=y_frac[R +j]- t(EW)%*%Yhat[R +j,]\n",
    "    FEGL[j]= y_frac[R +j]- t(wGL)%*%Yhat[R +j,]\n",
    "    FELW[j]=y_frac[R +j]- t(wLW)%*%Yhat[R +j,]\n",
    "    FELW_set[j]=y_frac[R +j]- t(wLW_set)%*%Yhat[R +j,]\n",
    "    FEPOET[j]= y_frac[R +j]- t(wPOET)%*%Yhat[R +j,]\n",
    "    FENLW[j]= y_frac[R +j]- t(wNLW)%*%Yhat[R +j,]\n",
    "    FENLW_set[j]= y_frac[R +j]- t(wNLW_set)%*%Yhat[R +j,]\n",
    "    FECLIME[j]= y_frac[R +j]- t(wCLIME)%*%Yhat[R +j,]\n",
    "    FECLIME_set[j]= y_frac[R +j]- t(wCLIME_set)%*%Yhat[R +j,]\n",
    "    FEnotsparse[j]= y_frac[R +j]- t(wnotsparse)%*%Yhat[R +j,]\n",
    "    FEMB[j]=y_frac[R +j]- t(wMB)%*%Yhat[R +j,]\n",
    "    FEFMB[j]= y_frac[R +j]- t(wFMB)%*%Yhat[R +j,]\n",
    "    \n",
    "    #################SFEs ARE HERE##################\n",
    "    SFEAR1[j] = (FEAR1[j])^2\n",
    "    SFEFGL[j]=(y_frac[R +j]- t(wFGL)%*%Yhat[R +j,])^(2)\n",
    "    SFEEW[j]=(y_frac[R +j]- t(EW)%*%Yhat[R +j,])^(2)\n",
    "    SFEGL[j]=(y_frac[R +j]- t(wGL)%*%Yhat[R +j,])^(2)\n",
    "    SFELW[j]=(y_frac[R +j]- t(wLW)%*%Yhat[R +j,])^(2)\n",
    "    SFELW_set[j]=(y_frac[R +j]- t(wLW_set)%*%Yhat[R +j,])^(2)\n",
    "    SFEPOET[j]=(y_frac[R +j]- t(wPOET)%*%Yhat[R +j,])^(2)\n",
    "    SFENLW[j]=(y_frac[R +j]- t(wNLW)%*%Yhat[R +j,])^(2)\n",
    "    SFENLW_set[j]=(y_frac[R +j]- t(wNLW_set)%*%Yhat[R +j,])^(2)\n",
    "    SFECLIME[j]=(y_frac[R +j]- t(wCLIME)%*%Yhat[R +j,])^(2)\n",
    "    SFECLIME_set[j]=(y_frac[R +j]- t(wCLIME_set)%*%Yhat[R +j,])^(2)\n",
    "    SFEnotsparse[j]=(y_frac[R +j]- t(wnotsparse)%*%Yhat[R +j,])^(2)\n",
    "    SFEMB[j]=(y_frac[R +j]- t(wMB)%*%Yhat[R +j,])^(2)\n",
    "    SFEFMB[j]=(y_frac[R +j]- t(wFMB)%*%Yhat[R +j,])^(2)\n",
    "    \n",
    "    \n",
    "    ##################\n",
    "    \n",
    "  }\n",
    "  MSFE1=mean(SFEEW)\n",
    "  MSFE2=mean(SFEFGL)\n",
    "  MSFE3=mean(SFEGL)\n",
    "  MSFE4=mean(SFELW)\n",
    "  MSFE5=mean(SFENLW)\n",
    "  MSFE6=mean(SFEPOET)\n",
    "  MSFE7=mean(SFECLIME)\n",
    "  MSFE8=mean(SFEnotsparse)\n",
    "  MSFE9=mean(SFEMB)\n",
    "  MSFE10=mean(SFEFMB)\n",
    "  MSFE11=mean(SFELW_set)\n",
    "  MSFE12=mean(SFENLW_set)\n",
    "  MSFE13=mean(SFECLIME_set)\n",
    "  MSFE14=mean(SFEAR1)\n",
    "  \n",
    "  \n",
    "  A = NULL\n",
    "  A = rbind(A,c(MSFE1, MSFE2, MSFE3, MSFE4, MSFE5, MSFE6,MSFE7, MSFE8,MSFE9,MSFE10,MSFE11,MSFE12,MSFE13, MSFE14))\n",
    "  write.csv(A,file=\"MSFE_FRED.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
