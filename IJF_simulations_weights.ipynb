{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760e64c8",
   "metadata": {},
   "source": [
    "## Lee TH., Seregina E.: \"Combining Forecasts under Structural Breaks Using Graphical LASSO\"\n",
    "\n",
    "### This Python notebook can be used to reproduce Monte Carlo results for forecast combination weights and precision matrix in Supplementary Appendix Figures E1, E3, E5, E6, E8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f84135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1605d36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pip install regain==0.3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457eb48",
   "metadata": {},
   "source": [
    "#### Please make sure to place \"GL.py\" and \"TVGL.py\" in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448146d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from GL import GraphicalLasso\n",
    "from TVGL2 import TimeGraphicalLasso\n",
    "from regain.datasets import make_dataset\n",
    "from regain.utils import error_norm_time\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import scipy.linalg   # SciPy Linear Algebra Library\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "from scipy.linalg import cholesky\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from numpy.linalg import inv\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############FUNCTIONS#############\n",
    "def portfolios(X,estsigm):\n",
    "    # X = X.to_numpy()\n",
    "    mu = np.mean(X,axis=0).reshape(X.shape[1],1)\n",
    "    p = len(mu) \n",
    "    one = np.ones([p,1])\n",
    "    phi = one.T@estsigm@one\n",
    "    #GMV##\n",
    "    gmv = (estsigm @ one) / phi \n",
    "    return [gmv]  \n",
    "#########################################\n",
    "\n",
    "def CV_theta(penalty, Y, breaks, betas, covariate, alpha_set, beta_set, isig, denominator): #X is returns, Y is residuals, K=k,\n",
    "#################SFEs ARE HERE##################\n",
    "    errTheta=np.zeros([len(alpha_set),len(beta_set)])\n",
    "    for alpha in range(0,len(alpha_set)):\n",
    "        for beta in range(0,len(beta_set)):\n",
    "            if penalty == '':\n",
    "                tvfgl = TimeGraphicalLasso(max_iter=100, alpha = alpha_set[alpha], beta = beta_set[beta]).fit(Y, breaks)\n",
    "            else:    \n",
    "                tvfgl = TimeGraphicalLasso(psi=penalty, max_iter=100, alpha = alpha_set[alpha], beta = beta_set[beta]).fit(Y, breaks)\n",
    "            if k==1:\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "\n",
    "            errTheta[alpha,beta] = math.log2(np.linalg.norm(Thetatvfgl-isig, ord=2)/np.sqrt(denominator))\n",
    "    [alphaopt, betaopt] = [alpha_set[np.where(errTheta == np.min(errTheta))[0]], beta_set[np.where(errTheta == np.min(errTheta))[1]]]      \n",
    "    return np.array([alphaopt,betaopt])\n",
    "\n",
    "\n",
    "def CV_gamma(gamma_set,r, r1, r2, k):\n",
    "    err_gamma=np.zeros([len(gamma_set),1])\n",
    "    err_loo=np.zeros([r2.shape[0],1])    \n",
    "    for gamma in range(0,len(gamma_set)):\n",
    "        for loo in range(0,r2.shape[0]):\n",
    "            # r = F@Lambda[0:kDGP,] + eps\n",
    "            r1_cv = r1*gamma_set[gamma]\n",
    "            r2_cv = np.delete(r2, loo, axis=0)\n",
    "            ##leaving one time -series out\n",
    "            r_cv = np.concatenate((r1_cv, r2_cv), axis=0)\n",
    "\n",
    "            ##estimating factors and loadings with LOO returns           \n",
    "            L, V = np.linalg.eigh(np.dot(r_cv.T, r_cv))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k]  # kx1\n",
    "            Fhat = np.dot(r_cv, lmb)  # Txr (r=1 for PC1)\n",
    "            sum_i = np.zeros([r_cv.shape[1],1])\n",
    "            for i in range(r.shape[1]):\n",
    "                sum_j = np.zeros([r2.shape[0],1])\n",
    "                ##computing sum of squared errors for the post-break period\n",
    "                for j in range(0,r2.shape[0]):\n",
    "                    sum_j[j] = (r2[j,i]-Fhat[j,:]@lmb.T[:,i])**2\n",
    "                sum_i[i] = np.sum(sum_j) \n",
    "            ##collecting SSEs for all LOOs    \n",
    "            err_loo[loo] = np.sum(sum_i)/(r.shape[1]*(r2.shape[0]))   \n",
    "        ##compute average of all LOOs for one gamma                \n",
    "        err_gamma[gamma] = np.sum(err_loo)\n",
    "    return  gamma_set[np.where(err_gamma == np.min(err_gamma))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7958e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PARAMETERS\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "beta_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "sigmaF = 1\n",
    "rho=0.9 #was 0.2 before IJF revision\n",
    "phi = 0.2\n",
    "ite=500\n",
    "# sample_size= np.array([int(round(2**(7),0)),int(round(2**(7.5),0))])\n",
    "###Modifying sample size \n",
    "# sample_size= np.array([int(round(2**(9.5),0))])\n",
    "#initial one (full)\n",
    "sample_size= np.array([int(round(2**(7),0)),int(round(2**(7.5),0)),int(round(2**(8),0)),int(round(2**(8.5),0)),int(round(2**(9),0)), int(round(2**(9.5),0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54806add",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_errWeight_GL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_EW = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_laplacian_load = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_l1_load = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_grouplasso_load = np.zeros((len(sample_size),1))\n",
    "# cum_errWeight_TVFGL_max = np.zeros((len(sample_size),1))\n",
    "# cum_errWeight_TVFGL_load = np.zeros((len(sample_size),1))\n",
    "# cum_errWeight_TVFGL_load_zero = np.zeros((len(sample_size),1))\n",
    "\n",
    "cum_errTheta_GL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_EW = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_laplacian_load = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_l1_load = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_grouplasso_load = np.zeros((len(sample_size),1))\n",
    "# cum_errTheta_TVFGL_max = np.zeros((len(sample_size),1))\n",
    "# cum_errTheta_TVFGL_load = np.zeros((len(sample_size),1))\n",
    "# cum_errTheta_TVFGL_load_zero = np.zeros((len(sample_size),1))\n",
    "\n",
    "mc_errWeight_GL = np.zeros((ite,1))\n",
    "mc_errWeight_FGL = np.zeros((ite,1))\n",
    "mc_errWeight_EW = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_grouplasso = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_laplacian_load = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_l1_load = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_grouplasso_load = np.zeros((ite,1))\n",
    "# mc_errWeight_TVFGL_max = np.zeros((ite,1))\n",
    "# mc_errWeight_TVFGL_load = np.zeros((ite,1))\n",
    "# mc_errWeight_TVFGL_load_zero = np.zeros((ite,1))\n",
    "\n",
    "mc_errTheta_GL = np.zeros((ite,1))\n",
    "mc_errTheta_FGL = np.zeros((ite,1))\n",
    "mc_errTheta_EW = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_grouplasso = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_laplacian_load = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_l1_load = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_grouplasso_load = np.zeros((ite,1))\n",
    "# mc_errTheta_TVFGL_max = np.zeros((ite,1))\n",
    "# mc_errTheta_TVFGL_load = np.zeros((ite,1))\n",
    "# mc_errTheta_TVFGL_load_zero = np.zeros((ite,1))\n",
    "#####################################\n",
    "gamma_n = np.zeros((len(sample_size),1))\n",
    "gamma_reps = np.zeros((ite,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0088ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E1: TIME-VARYING PRECISION + LOADINGS AND DIFFERENT PENALTY FUNCTIONS\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n,'jj =', jj)\n",
    "######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition        \n",
    "        #######GENERATING LOADINGS##############################\n",
    "        ####need to create two Lambda matrices associated with different rhos\n",
    "        ###BEFORE BREAK 1\n",
    "        rho1 = 0.2\n",
    "        O1 = np.zeros((p, p))\n",
    "        np.fill_diagonal(O1, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O1[h:], rho1**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O1[:,h:], rho1**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda1 = cholesky(O1, lower=False)\n",
    "        \n",
    "        ###AFTER BREAK 1\n",
    "        rho2 = 0.6\n",
    "        O2 = np.zeros((p, p))\n",
    "        np.fill_diagonal(O2, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O2[h:], rho2**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O2[:,h:], rho2**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda2 = cholesky(O2, lower=False)\n",
    "    \n",
    "        ####AFTER THE REVISION: ALTERNATIVE WAY OF GENERATING FACTORS\n",
    "        n1 = int(round(n/2))\n",
    "        n2 = n - n1\n",
    "        F1 = np.zeros((n1,kDGP))\n",
    "        F1[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n1,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n1):\n",
    "                F1[t,j] = phi*F1[t-1,j]+sigmaF*v[t,j]\n",
    "                \n",
    "                \n",
    "        F2 = np.zeros((n2,kDGP))\n",
    "        F2[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n2,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n2):\n",
    "                F2[t,j] = phi*F2[t-1,j]+sigmaF*v[t,j]        \n",
    "        \n",
    "        F = np.concatenate((F1, F2), axis=0)\n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        \n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u1 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.4, random_state=None)\n",
    "        Sigma_u1 = inv(Theta_u1)\n",
    "        ##precision for regime 2\n",
    "        Theta_u2 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.6, random_state=None)\n",
    "        Sigma_u2 = inv(Theta_u2)\n",
    "\n",
    "###########AFTER THE REVISION###############                \n",
    "        eps1 = np.zeros((n1,p))\n",
    "        eps2 = np.zeros((n2,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            if jjj <= n1:\n",
    "                breaks[jjj,]=0\n",
    "            else:\n",
    "                breaks[jjj,]=1\n",
    "        for jjj in range(0,n1):\n",
    "            eps1[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "        for jjj in range(0,n2):\n",
    "            eps2[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "      \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        eps = np.concatenate((eps1, eps2), axis=0)\n",
    "        cov_u1 = np.cov(eps1, y=None, rowvar=False) \n",
    "        Theta_u1 = np.linalg.inv(cov_u1)\n",
    "        \n",
    "        cov_u2 = np.cov(eps2, y=None, rowvar=False) \n",
    "        Theta_u2 = np.linalg.inv(cov_u2)\n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r1 = np.zeros((n1,p))\n",
    "        r2 = np.zeros((n2,p))\n",
    "        \n",
    "        r1 = F1@Lambda1[0:kDGP,] + eps1\n",
    "        r2 = F2@Lambda2[0:kDGP,] + eps2\n",
    "        \n",
    "        r = np.concatenate((r1, r2), axis=0)\n",
    "        ###################################\n",
    "        #####AFTER THE REVISION####\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "        \n",
    "        \n",
    "      ###Incorporating info about time-varying factor loadings\n",
    " \n",
    "      ###############################################################\n",
    "        ##############Estimating factors and loadings for time-varying########\n",
    "        gamma_opt = CV_gamma(gamma_set,r, r1, r2, k)\n",
    "        print('gamma_opt =', gamma_opt)\n",
    "        gamma_reps[jj] = gamma_opt\n",
    "        ####modified returns for time-varying loadings only!!!\n",
    "        r_load = r.copy()\n",
    "        for row in range(r_load.shape[0]):\n",
    "            for col in range(r_load.shape[1]):\n",
    "                if row <= n1:\n",
    "                    r_load[row,col]=gamma_opt* r_load[row,col] \n",
    "\n",
    "        L_load, V_load = np.linalg.eigh(np.dot(r_load.T, r_load))\n",
    "        idx_load = L_load.argsort()[::-1]\n",
    "        L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "        V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "        lmb_load = V_load[:, 0:k]  # kx1\n",
    "        # Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        ###According to Su (2017, JoE) if we obtain Fhat\n",
    "        ###as usual they are only consistent for a rotational version\n",
    "        ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "        Fhat_load = r@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "        Y_load = r - Fhat_load@lmb_load.T ##these are the residuals\n",
    "        \n",
    "        covariate_load = Fhat_load\n",
    "        betas_load = lmb_load.T\n",
    "        \n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###laplacian \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "                \n",
    "         ########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "        tuning_laplacian_load = CV_theta(penalty = '',Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1_load = CV_theta(penalty = 'l1', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso_load = CV_theta(penalty = 'l2', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "\n",
    "        ###laplacian       \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "        ###l1       \n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################   \n",
    "        ###group lasso     \n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################   \n",
    "        \n",
    "        \n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian_load = math.log2(np.linalg.norm(theta_TVFGL_laplacian_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1_load = math.log2(np.linalg.norm(theta_TVFGL_l1_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso_load = math.log2(np.linalg.norm(theta_TVFGL_grouplasso_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "        weight_TVFGL_laplacian_load = portfolios(r,theta_TVFGL_laplacian_load)[0]\n",
    "        weight_TVFGL_l1_load = portfolios(r,theta_TVFGL_l1_load)[0]\n",
    "        weight_TVFGL_grouplasso_load = portfolios(r,theta_TVFGL_grouplasso_load)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian_load = math.log2(np.linalg.norm(weight_TVFGL_laplacian_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1_load = math.log2(np.linalg.norm(weight_TVFGL_l1_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso_load = math.log2(np.linalg.norm(weight_TVFGL_grouplasso_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        \n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "        mc_errTheta_TVFGL_laplacian_load[jj] = errTheta_TVFGL_laplacian_load\n",
    "        mc_errTheta_TVFGL_l1_load[jj] = errTheta_TVFGL_l1_load\n",
    "        mc_errTheta_TVFGL_grouplasso_load[jj] = errTheta_TVFGL_grouplasso_load\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "        mc_errWeight_TVFGL_laplacian_load[jj] = errWeight_TVFGL_laplacian_load\n",
    "        mc_errWeight_TVFGL_l1_load[jj] = errWeight_TVFGL_l1_load\n",
    "        mc_errWeight_TVFGL_grouplasso_load[jj] = errWeight_TVFGL_grouplasso_load\n",
    "  ############Precision Matrix#########\n",
    "    gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "    cum_errTheta_TVFGL_laplacian_load[count] = np.mean(mc_errTheta_TVFGL_laplacian_load)\n",
    "    cum_errTheta_TVFGL_l1_load[count] = np.mean(mc_errTheta_TVFGL_l1_load)\n",
    "    cum_errTheta_TVFGL_grouplasso_load[count] = np.mean(mc_errTheta_TVFGL_grouplasso_load)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "    cum_errWeight_TVFGL_laplacian_load[count] = np.mean(mc_errWeight_TVFGL_laplacian_load)\n",
    "    cum_errWeight_TVFGL_l1_load[count] = np.mean(mc_errWeight_TVFGL_l1_load)\n",
    "    cum_errWeight_TVFGL_grouplasso_load[count] = np.mean(mc_errWeight_TVFGL_grouplasso_load)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso,cum_errTheta_TVFGL_laplacian_load,cum_errTheta_TVFGL_l1_load,cum_errTheta_TVFGL_grouplasso_load), axis=1)\n",
    "savetxt('cum_errTheta_break_theta.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso,cum_errWeight_TVFGL_laplacian_load,cum_errWeight_TVFGL_l1_load,cum_errWeight_TVFGL_grouplasso_load), axis=1)\n",
    "savetxt('cum_errWeight_break_theta_and_loadings.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "savetxt('gamma_break_theta_and_loadings.csv', gamma_n, delimiter=',')\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9535237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E3: simulations without any break\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n,'jj =', jj, 'out of =', ite)\n",
    "    ######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition\n",
    "    ###WITHOUT BREAK\n",
    "        O = np.zeros((p, p))\n",
    "        np.fill_diagonal(O, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "    \n",
    "        #######BEFORE THE REVISION: GENERATING FACTORS###############################\n",
    "        F = np.zeros((n,kDGP))\n",
    "        F[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "        \n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        \n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.3, random_state=None)\n",
    "        Sigma_u = inv(Theta_u)\n",
    "        \n",
    "#########BEFORE THE REVISION################\n",
    "        eps = np.zeros((n,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            eps[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u,1)\n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        cov_u = np.cov(eps, y=None, rowvar=False) \n",
    "        Theta_u = np.linalg.inv(cov_u)\n",
    "##################################################\n",
    "    \n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r = np.zeros((n,p))        \n",
    "        r = F@Lambda[0:kDGP,] + eps\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "\n",
    "        ###############################################################################\n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        \n",
    "        \n",
    "#         tuning = CV_theta(Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        print(tuning_laplacian.T)\n",
    "        ########laplacian\n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############max norm\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'linf', max_iter=100, alpha = tuning_max[0][0], beta = tuning_max[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        \n",
    "#         errTheta_TVFGL_load = math.log2(np.linalg.norm(theta_TVFGL_load-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_load_zero = math.log2(np.linalg.norm(theta_TVFGL_load_zero-isig, ord=2)/np.sqrt(denominator))\n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "        weight_TVFGL_max = portfolios(r,theta_TVFGL_max)[0]\n",
    "#         weight_TVFGL_load = portfolios(r,theta_TVFGL_load)[0]\n",
    "#         weight_TVFGL_load_zero = portfolios(r,theta_TVFGL_load_zero)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load = math.log2(np.linalg.norm(weight_TVFGL_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load_zero = math.log2(np.linalg.norm(weight_TVFGL_load_zero-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_max = math.log2(np.linalg.norm(weight_TVFGL_max-weight_true, ord=1)/np.sqrt(denominator))\n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "        mc_errTheta_TVFGL_max[jj] = errTheta_TVFGL_max\n",
    "#         mc_errTheta_TVFGL_load[jj] = errTheta_TVFGL_load\n",
    "#         mc_errTheta_TVFGL_load_zero[jj] = errTheta_TVFGL_load_zero\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "        mc_errWeight_TVFGL_max[jj] = errWeight_TVFGL_max\n",
    "#         mc_errWeight_TVFGL_load[jj] = errWeight_TVFGL_load\n",
    "#         mc_errWeight_TVFGL_load_zero[jj] = errWeight_TVFGL_load_zero\n",
    "  ############Precision Matrix#########\n",
    "    gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "    cum_errTheta_TVFGL_max[count] = np.mean(mc_errTheta_TVFGL_max)\n",
    "#     cum_errTheta_TVFGL_load[count] = np.mean(mc_errTheta_TVFGL_load)\n",
    "#     cum_errTheta_TVFGL_load_zero[count] = np.mean(mc_errTheta_TVFGL_load_zero)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "    cum_errWeight_TVFGL_max[count] = np.mean(mc_errWeight_TVFGL_max)\n",
    "#     cum_errWeight_TVFGL_load[count] = np.mean(mc_errWeight_TVFGL_load)\n",
    "#     cum_errWeight_TVFGL_load_zero[count] = np.mean(mc_errWeight_TVFGL_load_zero)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso,cum_errTheta_TVFGL_max), axis=1)\n",
    "savetxt('cum_errTheta_nobreak.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso,cum_errWeight_TVFGL_max), axis=1)\n",
    "savetxt('cum_errWeight_nobreak.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "savetxt('gamma_nobreak.csv', gamma_n, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1af00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E5: TIME-VARYING PRECISION (fixed loadings) AND DIFFERENT PENALTY FUNCTIONS\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n,'jj =', jj)\n",
    "    ######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition\n",
    "    ###WITHOUT BREAK\n",
    "        O = np.zeros((p, p))\n",
    "        np.fill_diagonal(O, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "    \n",
    "        #######BEFORE THE REVISION: GENERATING FACTORS###############################\n",
    "        F = np.zeros((n,kDGP))\n",
    "        F[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "        \n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        n1 = int(round(n/2))\n",
    "        n2 = n - n1\n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u1 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.4, random_state=None)\n",
    "        Sigma_u1 = inv(Theta_u1)\n",
    "        ##precision for regime 2\n",
    "        Theta_u2 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.6, random_state=None)\n",
    "        Sigma_u2 = inv(Theta_u2)\n",
    "        \n",
    "\n",
    "###########AFTER THE REVISION###############                \n",
    "        eps1 = np.zeros((n1,p))\n",
    "        eps2 = np.zeros((n2,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            if jjj <= n1:\n",
    "                breaks[jjj,]=0\n",
    "            else:\n",
    "                breaks[jjj,]=1\n",
    "        for jjj in range(0,n1):\n",
    "            eps1[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "        for jjj in range(0,n2):\n",
    "            eps2[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u2,1)\n",
    "      \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        eps = np.concatenate((eps1, eps2), axis=0)\n",
    "        cov_u1 = np.cov(eps1, y=None, rowvar=False) \n",
    "        Theta_u1 = np.linalg.inv(cov_u1)\n",
    "        \n",
    "        cov_u2 = np.cov(eps2, y=None, rowvar=False) \n",
    "        Theta_u2 = np.linalg.inv(cov_u2)\n",
    "        \n",
    "    \n",
    "        #################GENERATE RETURNS#################\n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r = np.zeros((n,p))        \n",
    "        r = F@Lambda[0:kDGP,] + eps\n",
    "\n",
    "        ###################################\n",
    "        ######BEFORE THE REVISION\n",
    "        # r = F@Lambda[0:kDGP,] + eps\n",
    "        # isig = Theta_u - Theta_u@Lambda[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda[0:kDGP,]@Theta_u@Lambda[0:kDGP,].T)@Lambda[0:kDGP,]@Theta_u\n",
    "        \n",
    "        \n",
    "        #####AFTER THE REVISION####\n",
    "        ##ON SECOND THOUGHT: how about just taking the inverse of returns?\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "        ###two different population precision matrices before and after the break\n",
    "        # isig1 = Theta_u1 - Theta_u1@Lambda1[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda1[0:kDGP,]@Theta_u1@Lambda1[0:kDGP,].T)@Lambda1[0:kDGP,]@Theta_u1\n",
    "        # isig2 = Theta_u2 - Theta_u2@Lambda2[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda2[0:kDGP,]@Theta_u2@Lambda2[0:kDGP,].T)@Lambda2[0:kDGP,]@Theta_u2\n",
    "        \n",
    "      ###############################################################\n",
    "       \n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        \n",
    "        \n",
    "#         tuning = CV_theta(Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###laplacian \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "#         #############max norm\n",
    "#         tvfgl = TimeGraphicalLasso(psi = 'linf', max_iter=100, alpha = tuning_max[0][0], beta = tuning_max[1][0]).fit(Y, breaks)\n",
    "#         if k==1:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#         else:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "#         weight_TVFGL_max = portfolios(r,theta_TVFGL_max)[0]\n",
    "#         weight_TVFGL_load = portfolios(r,theta_TVFGL_load)[0]\n",
    "#         weight_TVFGL_load_zero = portfolios(r,theta_TVFGL_load_zero)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load = math.log2(np.linalg.norm(weight_TVFGL_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load_zero = math.log2(np.linalg.norm(weight_TVFGL_load_zero-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_max = math.log2(np.linalg.norm(weight_TVFGL_max-weight_true, ord=1)/np.sqrt(denominator))\n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "#         mc_errTheta_TVFGL_max[jj] = errTheta_TVFGL_max\n",
    "#         mc_errTheta_TVFGL_load[jj] = errTheta_TVFGL_load\n",
    "#         mc_errTheta_TVFGL_load_zero[jj] = errTheta_TVFGL_load_zero\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "#         mc_errWeight_TVFGL_max[jj] = errWeight_TVFGL_max\n",
    "#         mc_errWeight_TVFGL_load[jj] = errWeight_TVFGL_load\n",
    "#         mc_errWeight_TVFGL_load_zero[jj] = errWeight_TVFGL_load_zero\n",
    "  ############Precision Matrix#########\n",
    "    gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "#     cum_errTheta_TVFGL_max[count] = np.mean(mc_errTheta_TVFGL_max)\n",
    "#     cum_errTheta_TVFGL_load[count] = np.mean(mc_errTheta_TVFGL_load)\n",
    "#     cum_errTheta_TVFGL_load_zero[count] = np.mean(mc_errTheta_TVFGL_load_zero)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "#     cum_errWeight_TVFGL_max[count] = np.mean(mc_errWeight_TVFGL_max)\n",
    "#     cum_errWeight_TVFGL_load[count] = np.mean(mc_errWeight_TVFGL_load)\n",
    "#     cum_errWeight_TVFGL_load_zero[count] = np.mean(mc_errWeight_TVFGL_load_zero)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errTheta_break_theta.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errWeight_break_theta.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "savetxt('gamma_break_theta.csv', gamma_n, delimiter=',')\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########Appendix Figure E6: FIXED LOADINGS AND TWO BREAKS IN IDIOSYNCRATIC PRECISION: TIME-VARYING PRECISION (fixed loadings) AND DIFFERENT PENALTY FUNCTIONS\n",
    "###INCLUDES THE CASE WITH FIXED LOADINGS AND TWO BREAKS IN IDIOSYNCRATIC PRECISION\n",
    "\n",
    "###PARAMETERS\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "beta_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "sigmaF = 1\n",
    "rho=0.2\n",
    "phi = 0.2\n",
    "ite=500\n",
    "# sample_size= np.array([int(round(2**(7),0)),int(round(2**(7.5),0))])\n",
    "###Modifying sample size \n",
    "# sample_size= np.array([int(round(2**(9.5),0))])\n",
    "#initial one (full)\n",
    "sample_size= np.array([int(round(2**(7),0)),int(round(2**(7.5),0)),int(round(2**(8),0)),int(round(2**(8.5),0)),int(round(2**(9),0)), int(round(2**(9.5),0))])\n",
    "\n",
    "cum_errWeight_GL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_EW = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "\n",
    "\n",
    "cum_errTheta_GL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_EW = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "\n",
    "\n",
    "mc_errWeight_GL = np.zeros((ite,1))\n",
    "mc_errWeight_FGL = np.zeros((ite,1))\n",
    "mc_errWeight_EW = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_grouplasso = np.zeros((ite,1))\n",
    "\n",
    "\n",
    "mc_errTheta_GL = np.zeros((ite,1))\n",
    "mc_errTheta_FGL = np.zeros((ite,1))\n",
    "mc_errTheta_EW = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_grouplasso = np.zeros((ite,1))\n",
    "\n",
    "#####################################\n",
    "gamma_n = np.zeros((len(sample_size),1))\n",
    "gamma_reps = np.zeros((ite,1))\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n, 'jj =', jj, 'out of', ite)\n",
    "    ######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition\n",
    "    ###WITHOUT BREAK\n",
    "        O = np.zeros((p, p))\n",
    "        np.fill_diagonal(O, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "    \n",
    "        #######BEFORE THE REVISION: GENERATING FACTORS###############################\n",
    "        F = np.zeros((n,kDGP))\n",
    "        F[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "        \n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        ##break points\n",
    "        t1 = int(round(n/4))\n",
    "        t2 = int(round(3*n/4))\n",
    "        ##number of observations in the breaks        \n",
    "        n1 = t1\n",
    "        n2 = t2-t1\n",
    "        n3 = n-n2-n1\n",
    "        \n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u1 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.2, random_state=None)\n",
    "        Sigma_u1 = inv(Theta_u1)\n",
    "        ##precision for regime 2\n",
    "        Theta_u2 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.4, random_state=None)\n",
    "        Sigma_u2 = inv(Theta_u2)\n",
    "        ##precision for regime 3\n",
    "        Theta_u3 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.6, random_state=None)\n",
    "        Sigma_u3 = inv(Theta_u3)\n",
    "\n",
    "###########AFTER THE REVISION###############                \n",
    "        eps1 = np.zeros((n1,p))\n",
    "        eps2 = np.zeros((n2,p))\n",
    "        eps3 = np.zeros((n3,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            if jjj <= t1:\n",
    "                breaks[jjj,]=0\n",
    "            if t1 < jjj <= t2:\n",
    "                breaks[jjj,]=1 \n",
    "            if jjj > t2:\n",
    "                breaks[jjj,]=2\n",
    "        for jjj in range(0,n1):\n",
    "            eps1[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "        for jjj in range(0,n2):\n",
    "            eps2[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u2,1)\n",
    "        for jjj in range(0,n3):\n",
    "            eps3[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u3,1)\n",
    "        \n",
    "      \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        eps = np.concatenate((eps1, eps2, eps3), axis=0)\n",
    "        cov_u1 = np.cov(eps1, y=None, rowvar=False) \n",
    "        Theta_u1 = np.linalg.inv(cov_u1)\n",
    "        \n",
    "        cov_u2 = np.cov(eps2, y=None, rowvar=False) \n",
    "        Theta_u2 = np.linalg.inv(cov_u2)\n",
    "        \n",
    "        cov_u3 = np.cov(eps3, y=None, rowvar=False) \n",
    "        Theta_u3 = np.linalg.inv(cov_u3)\n",
    "        \n",
    "    \n",
    "        #################GENERATE RETURNS#################\n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r = np.zeros((n,p))        \n",
    "        r = F@Lambda[0:kDGP,] + eps\n",
    "\n",
    "        ###################################\n",
    "        ######BEFORE THE REVISION\n",
    "        # r = F@Lambda[0:kDGP,] + eps\n",
    "        # isig = Theta_u - Theta_u@Lambda[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda[0:kDGP,]@Theta_u@Lambda[0:kDGP,].T)@Lambda[0:kDGP,]@Theta_u\n",
    "        \n",
    "        \n",
    "        #####AFTER THE REVISION####\n",
    "        ##ON SECOND THOUGHT: how about just taking the inverse of returns?\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "        ###two different population precision matrices before and after the break\n",
    "        # isig1 = Theta_u1 - Theta_u1@Lambda1[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda1[0:kDGP,]@Theta_u1@Lambda1[0:kDGP,].T)@Lambda1[0:kDGP,]@Theta_u1\n",
    "        # isig2 = Theta_u2 - Theta_u2@Lambda2[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda2[0:kDGP,]@Theta_u2@Lambda2[0:kDGP,].T)@Lambda2[0:kDGP,]@Theta_u2\n",
    "        \n",
    "      ###############################################################\n",
    "       \n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        \n",
    "        \n",
    "#         tuning = CV_theta(Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###laplacian \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "#         #############max norm\n",
    "#         tvfgl = TimeGraphicalLasso(psi = 'linf', max_iter=100, alpha = tuning_max[0][0], beta = tuning_max[1][0]).fit(Y, breaks)\n",
    "#         if k==1:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#         else:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "#         weight_TVFGL_max = portfolios(r,theta_TVFGL_max)[0]\n",
    "#         weight_TVFGL_load = portfolios(r,theta_TVFGL_load)[0]\n",
    "#         weight_TVFGL_load_zero = portfolios(r,theta_TVFGL_load_zero)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load = math.log2(np.linalg.norm(weight_TVFGL_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load_zero = math.log2(np.linalg.norm(weight_TVFGL_load_zero-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_max = math.log2(np.linalg.norm(weight_TVFGL_max-weight_true, ord=1)/np.sqrt(denominator))\n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "#         mc_errTheta_TVFGL_max[jj] = errTheta_TVFGL_max\n",
    "#         mc_errTheta_TVFGL_load[jj] = errTheta_TVFGL_load\n",
    "#         mc_errTheta_TVFGL_load_zero[jj] = errTheta_TVFGL_load_zero\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "#         mc_errWeight_TVFGL_max[jj] = errWeight_TVFGL_max\n",
    "#         mc_errWeight_TVFGL_load[jj] = errWeight_TVFGL_load\n",
    "#         mc_errWeight_TVFGL_load_zero[jj] = errWeight_TVFGL_load_zero\n",
    "  ############Precision Matrix#########\n",
    "    gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "#     cum_errTheta_TVFGL_max[count] = np.mean(mc_errTheta_TVFGL_max)\n",
    "#     cum_errTheta_TVFGL_load[count] = np.mean(mc_errTheta_TVFGL_load)\n",
    "#     cum_errTheta_TVFGL_load_zero[count] = np.mean(mc_errTheta_TVFGL_load_zero)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "#     cum_errWeight_TVFGL_max[count] = np.mean(mc_errWeight_TVFGL_max)\n",
    "#     cum_errWeight_TVFGL_load[count] = np.mean(mc_errWeight_TVFGL_load)\n",
    "#     cum_errWeight_TVFGL_load_zero[count] = np.mean(mc_errWeight_TVFGL_load_zero)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errTheta_2breaks_theta.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errWeight_2breaks_theta.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "# savetxt('gamma_2breaks_theta.csv', gamma_n, delimiter=',')\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80661738",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_errWeight_GL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_EW = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errWeight_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "\n",
    "cum_errTheta_GL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_FGL = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_EW = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_errTheta_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "\n",
    "mc_errWeight_GL = np.zeros((ite,1))\n",
    "mc_errWeight_FGL = np.zeros((ite,1))\n",
    "mc_errWeight_EW = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errWeight_TVFGL_grouplasso = np.zeros((ite,1))\n",
    "\n",
    "mc_errTheta_GL = np.zeros((ite,1))\n",
    "mc_errTheta_FGL = np.zeros((ite,1))\n",
    "mc_errTheta_EW = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_laplacian = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_l1 = np.zeros((ite,1))\n",
    "mc_errTheta_TVFGL_grouplasso = np.zeros((ite,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2eb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E8: TIME-VARYING PRECISION (fixed loadings): exploring different break magnitudes\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n, 'jj =', jj, 'out of', ite)\n",
    "    ######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition\n",
    "    ###WITHOUT BREAK\n",
    "        O = np.zeros((p, p))\n",
    "        np.fill_diagonal(O, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "    \n",
    "        #######BEFORE THE REVISION: GENERATING FACTORS###############################\n",
    "        F = np.zeros((n,kDGP))\n",
    "        F[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "        \n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        n1 = int(round(n/2))\n",
    "        n2 = n - n1\n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u1 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.4, random_state=None)\n",
    "        Sigma_u1 = inv(Theta_u1)\n",
    "        ##precision for regime 2\n",
    "        Theta_u2 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.45, random_state=None)\n",
    "        Sigma_u2 = inv(Theta_u2)\n",
    "        \n",
    "\n",
    "###########AFTER THE REVISION###############                \n",
    "        eps1 = np.zeros((n1,p))\n",
    "        eps2 = np.zeros((n2,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            if jjj <= n1:\n",
    "                breaks[jjj,]=0\n",
    "            else:\n",
    "                breaks[jjj,]=1\n",
    "        for jjj in range(0,n1):\n",
    "            eps1[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "        for jjj in range(0,n2):\n",
    "            eps2[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u2,1)\n",
    "      \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        eps = np.concatenate((eps1, eps2), axis=0)\n",
    "        cov_u1 = np.cov(eps1, y=None, rowvar=False) \n",
    "        Theta_u1 = np.linalg.inv(cov_u1)\n",
    "        \n",
    "        cov_u2 = np.cov(eps2, y=None, rowvar=False) \n",
    "        Theta_u2 = np.linalg.inv(cov_u2)\n",
    "        \n",
    "    \n",
    "        #################GENERATE RETURNS#################\n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r = np.zeros((n,p))        \n",
    "        r = F@Lambda[0:kDGP,] + eps\n",
    "\n",
    "        ###################################\n",
    "        ######BEFORE THE REVISION\n",
    "        # r = F@Lambda[0:kDGP,] + eps\n",
    "        # isig = Theta_u - Theta_u@Lambda[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda[0:kDGP,]@Theta_u@Lambda[0:kDGP,].T)@Lambda[0:kDGP,]@Theta_u\n",
    "        \n",
    "        \n",
    "        #####AFTER THE REVISION####\n",
    "        ##ON SECOND THOUGHT: how about just taking the inverse of returns?\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "        ###two different population precision matrices before and after the break\n",
    "        # isig1 = Theta_u1 - Theta_u1@Lambda1[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda1[0:kDGP,]@Theta_u1@Lambda1[0:kDGP,].T)@Lambda1[0:kDGP,]@Theta_u1\n",
    "        # isig2 = Theta_u2 - Theta_u2@Lambda2[0:kDGP,].T@np.linalg.inv( np.linalg.inv(covf)+Lambda2[0:kDGP,]@Theta_u2@Lambda2[0:kDGP,].T)@Lambda2[0:kDGP,]@Theta_u2\n",
    "        \n",
    "      ###############################################################\n",
    "       \n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        \n",
    "        \n",
    "#         tuning = CV_theta(Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###laplacian \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "#         #############max norm\n",
    "#         tvfgl = TimeGraphicalLasso(psi = 'linf', max_iter=100, alpha = tuning_max[0][0], beta = tuning_max[1][0]).fit(Y, breaks)\n",
    "#         if k==1:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#         else:\n",
    "#             theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "#         weight_TVFGL_max = portfolios(r,theta_TVFGL_max)[0]\n",
    "#         weight_TVFGL_load = portfolios(r,theta_TVFGL_load)[0]\n",
    "#         weight_TVFGL_load_zero = portfolios(r,theta_TVFGL_load_zero)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load = math.log2(np.linalg.norm(weight_TVFGL_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_load_zero = math.log2(np.linalg.norm(weight_TVFGL_load_zero-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "#         errWeight_TVFGL_max = math.log2(np.linalg.norm(weight_TVFGL_max-weight_true, ord=1)/np.sqrt(denominator))\n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "#         mc_errTheta_TVFGL_max[jj] = errTheta_TVFGL_max\n",
    "#         mc_errTheta_TVFGL_load[jj] = errTheta_TVFGL_load\n",
    "#         mc_errTheta_TVFGL_load_zero[jj] = errTheta_TVFGL_load_zero\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "#         mc_errWeight_TVFGL_max[jj] = errWeight_TVFGL_max\n",
    "#         mc_errWeight_TVFGL_load[jj] = errWeight_TVFGL_load\n",
    "#         mc_errWeight_TVFGL_load_zero[jj] = errWeight_TVFGL_load_zero\n",
    "  ############Precision Matrix#########\n",
    "#     gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "#     cum_errTheta_TVFGL_max[count] = np.mean(mc_errTheta_TVFGL_max)\n",
    "#     cum_errTheta_TVFGL_load[count] = np.mean(mc_errTheta_TVFGL_load)\n",
    "#     cum_errTheta_TVFGL_load_zero[count] = np.mean(mc_errTheta_TVFGL_load_zero)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "#     cum_errWeight_TVFGL_max[count] = np.mean(mc_errWeight_TVFGL_max)\n",
    "#     cum_errWeight_TVFGL_load[count] = np.mean(mc_errWeight_TVFGL_load)\n",
    "#     cum_errWeight_TVFGL_load_zero[count] = np.mean(mc_errWeight_TVFGL_load_zero)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errTheta_breaksmall_theta.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso), axis=1)\n",
    "savetxt('cum_errWeight_breaksmall_theta.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "# savetxt('gamma_break_theta.csv', gamma_n, delimiter=',')\n",
    "      \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E1: TIME-VARYING PRECISION (fixed loadings) AND DIFFERENT PENALTY FUNCTIONS\n",
    "count=-1\n",
    "for n in sample_size:\n",
    "    count = count + 1\n",
    "    p = int(round(n**(0.85),0) )\n",
    "    #p=round((n[i])^(1.05))# HIGH DIMENSIONAL\n",
    "    # p=round(3*(n[i])^(0.85))# HIGH DIMENSIONAL\n",
    "    kDGP = math.ceil(2*(math.log2(p))**(1/2))\n",
    "    k=kDGP\n",
    "    kpoet = round(kDGP,0) \n",
    "    for jj in range(ite):\n",
    "        print('n =', n,'jj =', jj)\n",
    "######################################\n",
    "    ##########Dynamic Factor DGP##########\n",
    "    ######################################   \n",
    "    ###creating Toeplitz matrix and its Cholesky decomposition        \n",
    "        #######GENERATING LOADINGS##############################\n",
    "        ####need to create two Lambda matrices associated with different rhos\n",
    "        ###BEFORE BREAK 1\n",
    "        rho1 = 0.2\n",
    "        O1 = np.zeros((p, p))\n",
    "        np.fill_diagonal(O1, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O1[h:], rho1**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O1[:,h:], rho1**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda1 = cholesky(O1, lower=False)\n",
    "        \n",
    "        ###AFTER BREAK 1\n",
    "        rho2 = 0.6\n",
    "        O2 = np.zeros((p, p))\n",
    "        np.fill_diagonal(O2, np.ones(p))     \n",
    "        for h in range(1,p):\n",
    "            np.fill_diagonal(O2[h:], rho2**np.repeat(h, p-h))\n",
    "            np.fill_diagonal(O2[:,h:], rho2**np.repeat(h, p-h))\n",
    "        \n",
    "        Lambda2 = cholesky(O2, lower=False)\n",
    "    \n",
    "        ####AFTER THE REVISION: ALTERNATIVE WAY OF GENERATING FACTORS\n",
    "        n1 = int(round(n/2))\n",
    "        n2 = n - n1\n",
    "        F1 = np.zeros((n1,kDGP))\n",
    "        F1[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n1,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n1):\n",
    "                F1[t,j] = phi*F1[t-1,j]+sigmaF*v[t,j]\n",
    "                \n",
    "                \n",
    "        F2 = np.zeros((n2,kDGP))\n",
    "        F2[0,] = sigmaF*np.random.randn(1,kDGP)\n",
    "        v=np.random.randn(n2,kDGP)\n",
    "        for j in range(0,kDGP):\n",
    "            for t in range(1,n2):\n",
    "                F2[t,j] = phi*F2[t-1,j]+sigmaF*v[t,j]        \n",
    "        \n",
    "        F = np.concatenate((F1, F2), axis=0)\n",
    "        covf = np.cov(F, y=None, rowvar=False) #If rowvar is True (default), then each row represents a variable, with observations in the columns                     \n",
    "        \n",
    "        \n",
    "        #################GENERATE EPS##################\n",
    "        probability = 1- 500/((n)**(0.7)*(p)) #The probability that a coefficient is zero\n",
    "        ##precision for regime 1\n",
    "        Theta_u1 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.4, random_state=None)\n",
    "        Sigma_u1 = inv(Theta_u1)\n",
    "        ##precision for regime 2\n",
    "        Theta_u2 = sklearn.datasets.make_sparse_spd_matrix(dim=p, alpha=probability, norm_diag=False, smallest_coef=0.1, largest_coef=0.6, random_state=None)\n",
    "        Sigma_u2 = inv(Theta_u2)\n",
    "\n",
    "###########AFTER THE REVISION###############                \n",
    "        eps1 = np.zeros((n1,p))\n",
    "        eps2 = np.zeros((n2,p))\n",
    "        breaks = np.zeros((n,1))\n",
    "        mue = np.zeros((p,1))\n",
    "        for jjj in range(0,n):\n",
    "            if jjj <= n1:\n",
    "                breaks[jjj,]=0\n",
    "            else:\n",
    "                breaks[jjj,]=1\n",
    "        for jjj in range(0,n1):\n",
    "            eps1[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "        for jjj in range(0,n2):\n",
    "            eps2[jjj,]=np.random.multivariate_normal(mue.ravel(),Sigma_u1,1)\n",
    "      \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "        eps = np.concatenate((eps1, eps2), axis=0)\n",
    "        cov_u1 = np.cov(eps1, y=None, rowvar=False) \n",
    "        Theta_u1 = np.linalg.inv(cov_u1)\n",
    "        \n",
    "        cov_u2 = np.cov(eps2, y=None, rowvar=False) \n",
    "        Theta_u2 = np.linalg.inv(cov_u2)\n",
    "        \n",
    "        #########AFTER THE REVISION\n",
    "        r1 = np.zeros((n1,p))\n",
    "        r2 = np.zeros((n2,p))\n",
    "        \n",
    "        r1 = F1@Lambda1[0:kDGP,] + eps1\n",
    "        r2 = F2@Lambda2[0:kDGP,] + eps2\n",
    "        \n",
    "        r = np.concatenate((r1, r2), axis=0)\n",
    "        ###################################\n",
    "        #####AFTER THE REVISION####\n",
    "        icov = np.cov(r, y=None, rowvar=False) \n",
    "        isig = np.linalg.inv(icov)\n",
    "        \n",
    "        \n",
    "      ###Incorporating info about time-varying factor loadings\n",
    " \n",
    "      ###############################################################\n",
    "        ##############Estimating factors and loadings for time-varying########\n",
    "        gamma_opt = CV_gamma(gamma_set,r, r1, r2, k)\n",
    "        print('gamma_opt =', gamma_opt)\n",
    "        gamma_reps[jj] = gamma_opt\n",
    "        ####modified returns for time-varying loadings only!!!\n",
    "        r_load = r.copy()\n",
    "        for row in range(r_load.shape[0]):\n",
    "            for col in range(r_load.shape[1]):\n",
    "                if row <= n1:\n",
    "                    r_load[row,col]=gamma_opt* r_load[row,col] \n",
    "\n",
    "        L_load, V_load = np.linalg.eigh(np.dot(r_load.T, r_load))\n",
    "        idx_load = L_load.argsort()[::-1]\n",
    "        L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "        V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "        lmb_load = V_load[:, 0:k]  # kx1\n",
    "        # Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        ###According to Su (2017, JoE) if we obtain Fhat\n",
    "        ###as usual they are only consistent for a rotational version\n",
    "        ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "        Fhat_load = r@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "        Y_load = r - Fhat_load@lmb_load.T ##these are the residuals\n",
    "        \n",
    "        covariate_load = Fhat_load\n",
    "        betas_load = lmb_load.T\n",
    "        \n",
    "        \n",
    "        ##############Estimating USUAL factors and loadings (gamma=1)########\n",
    "        L, V = np.linalg.eigh(np.dot(r.T, r))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k]  # kx1\n",
    "        Fhat = np.dot(r, lmb)  # Txr (r=1 for PC1)\n",
    "        Y = r - Fhat@lmb.T ##these are the residuals\n",
    "        \n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "\n",
    "        ############Estimating precision matrix and combination weights using competing methods######\n",
    "        ######## GLASSO###########\n",
    "        GL = GraphicalLassoCV().fit(r)\n",
    "        theta_GL = GL.get_precision()\n",
    "        \n",
    "        ########Factor GLASSO#######\n",
    "        FGL = GraphicalLassoCV().fit(Y)\n",
    "        theta_FGL_error = FGL.get_precision()\n",
    "        \n",
    "        if k==1:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "        else:\n",
    "            theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "        ########Time-Varying TVFGL (gamma=1)#########\n",
    "        denominator = p\n",
    "        \n",
    "        tuning_laplacian = CV_theta(penalty = '',Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1 = CV_theta(penalty = 'l1', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso = CV_theta(penalty = 'l2', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y,breaks = breaks, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###laplacian \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############l1\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "        #############group lasso\n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, breaks)\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "                \n",
    "         ########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "        tuning_laplacian_load = CV_theta(penalty = '',Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)##laplacian (ridge) is defauls and was used at the beginning\n",
    "        tuning_l1_load = CV_theta(penalty = 'l1', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "        tuning_grouplasso_load = CV_theta(penalty = 'l2', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "#         tuning_max = CV_theta(penalty = 'linf', Y=Y_load,breaks = breaks, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set, isig=isig, denominator=denominator)\n",
    "      \n",
    "        print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "\n",
    "        ###laplacian       \n",
    "        tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "        ###l1       \n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################   \n",
    "        ###group lasso     \n",
    "        tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y_load, breaks)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "        if k==1:\n",
    "            theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################   \n",
    "        \n",
    "        \n",
    "        \n",
    "        #################EQUALLY WEIGHTED########################\n",
    "        ev = np.linalg.eig(np.cov(r, y=None, rowvar=False))\n",
    "        eigenvalues = ev[0]\n",
    "        mu=np.mean(eigenvalues)   \n",
    "        CovshrIdent = np.zeros((p, p))\n",
    "        np.fill_diagonal(CovshrIdent, np.repeat(mu, p)) \n",
    "        theta_EW=np.linalg.inv(CovshrIdent)\n",
    "        \n",
    "        \n",
    "        ##################################################\n",
    "        ######Estimation errors for Precision Matrix######\n",
    "        ##################################################   \n",
    "        errTheta_GL = math.log2(np.linalg.norm(theta_GL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_FGL = math.log2(np.linalg.norm(theta_FGL-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_EW = math.log2(np.linalg.norm(theta_EW-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian = math.log2(np.linalg.norm(theta_TVFGL_laplacian-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1 = math.log2(np.linalg.norm(theta_TVFGL_l1-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso = math.log2(np.linalg.norm(theta_TVFGL_grouplasso-isig, ord=2)/np.sqrt(denominator))\n",
    "#         errTheta_TVFGL_max = math.log2(np.linalg.norm(theta_TVFGL_max-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_laplacian_load = math.log2(np.linalg.norm(theta_TVFGL_laplacian_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_l1_load = math.log2(np.linalg.norm(theta_TVFGL_l1_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        errTheta_TVFGL_grouplasso_load = math.log2(np.linalg.norm(theta_TVFGL_grouplasso_load-isig, ord=2)/np.sqrt(denominator))\n",
    "        ##################################################\n",
    "        ######Estimation errors for Portfolio Weights######\n",
    "        ##################################################\n",
    "        weight_true = portfolios(r,isig)[0]\n",
    "        \n",
    "        weight_GL = portfolios(r,theta_GL)[0]\n",
    "        weight_FGL = portfolios(r,theta_FGL)[0]\n",
    "        weight_EW = portfolios(r,theta_EW)[0]\n",
    "        weight_TVFGL_laplacian = portfolios(r,theta_TVFGL_laplacian)[0]\n",
    "        weight_TVFGL_l1 = portfolios(r,theta_TVFGL_l1)[0]\n",
    "        weight_TVFGL_grouplasso = portfolios(r,theta_TVFGL_grouplasso)[0]\n",
    "        weight_TVFGL_laplacian_load = portfolios(r,theta_TVFGL_laplacian_load)[0]\n",
    "        weight_TVFGL_l1_load = portfolios(r,theta_TVFGL_l1_load)[0]\n",
    "        weight_TVFGL_grouplasso_load = portfolios(r,theta_TVFGL_grouplasso_load)[0]\n",
    "        ############Global Minimum Variance (GMV)#########  \n",
    "        errWeight_GL = math.log2(np.linalg.norm(weight_GL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_FGL = math.log2(np.linalg.norm(weight_FGL-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_EW = math.log2(np.linalg.norm(weight_EW-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian = math.log2(np.linalg.norm(weight_TVFGL_laplacian-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1 = math.log2(np.linalg.norm(weight_TVFGL_l1-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso = math.log2(np.linalg.norm(weight_TVFGL_grouplasso-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_laplacian_load = math.log2(np.linalg.norm(weight_TVFGL_laplacian_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_l1_load = math.log2(np.linalg.norm(weight_TVFGL_l1_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        errWeight_TVFGL_grouplasso_load = math.log2(np.linalg.norm(weight_TVFGL_grouplasso_load-weight_true, ord=1)/np.sqrt(denominator))\n",
    "        \n",
    "    ############Precision Matrix#########  \n",
    "        mc_errTheta_GL[jj] = errTheta_GL    \n",
    "        mc_errTheta_FGL[jj] = errTheta_FGL\n",
    "        mc_errTheta_EW[jj] = errTheta_EW\n",
    "        mc_errTheta_TVFGL_laplacian[jj] = errTheta_TVFGL_laplacian\n",
    "        mc_errTheta_TVFGL_l1[jj] = errTheta_TVFGL_l1\n",
    "        mc_errTheta_TVFGL_grouplasso[jj] = errTheta_TVFGL_grouplasso\n",
    "        mc_errTheta_TVFGL_laplacian_load[jj] = errTheta_TVFGL_laplacian_load\n",
    "        mc_errTheta_TVFGL_l1_load[jj] = errTheta_TVFGL_l1_load\n",
    "        mc_errTheta_TVFGL_grouplasso_load[jj] = errTheta_TVFGL_grouplasso_load\n",
    "        \n",
    "    ############Global Minimum Variance (GMV)#########   \n",
    "        mc_errWeight_GL[jj] = errWeight_GL    \n",
    "        mc_errWeight_FGL[jj] = errWeight_FGL\n",
    "        mc_errWeight_EW[jj] = errWeight_EW\n",
    "        mc_errWeight_TVFGL_laplacian[jj] = errWeight_TVFGL_laplacian\n",
    "        mc_errWeight_TVFGL_l1[jj] = errWeight_TVFGL_l1\n",
    "        mc_errWeight_TVFGL_grouplasso[jj] = errWeight_TVFGL_grouplasso\n",
    "        mc_errWeight_TVFGL_laplacian_load[jj] = errWeight_TVFGL_laplacian_load\n",
    "        mc_errWeight_TVFGL_l1_load[jj] = errWeight_TVFGL_l1_load\n",
    "        mc_errWeight_TVFGL_grouplasso_load[jj] = errWeight_TVFGL_grouplasso_load\n",
    "  ############Precision Matrix#########\n",
    "    gamma_n[count] = np.mean(gamma_reps)\n",
    "    \n",
    "    cum_errTheta_GL[count] = np.mean(mc_errTheta_GL)\n",
    "    cum_errTheta_FGL[count] = np.mean(mc_errTheta_FGL)\n",
    "    cum_errTheta_EW[count] = np.mean(mc_errTheta_EW)\n",
    "    cum_errTheta_TVFGL_laplacian[count] = np.mean(mc_errTheta_TVFGL_laplacian)\n",
    "    cum_errTheta_TVFGL_l1[count] = np.mean(mc_errTheta_TVFGL_l1)\n",
    "    cum_errTheta_TVFGL_grouplasso[count] = np.mean(mc_errTheta_TVFGL_grouplasso)\n",
    "    cum_errTheta_TVFGL_laplacian_load[count] = np.mean(mc_errTheta_TVFGL_laplacian_load)\n",
    "    cum_errTheta_TVFGL_l1_load[count] = np.mean(mc_errTheta_TVFGL_l1_load)\n",
    "    cum_errTheta_TVFGL_grouplasso_load[count] = np.mean(mc_errTheta_TVFGL_grouplasso_load)\n",
    "    \n",
    "    ############Global Minimum Variance (GMV)#########\n",
    "    cum_errWeight_GL[count] = np.mean(mc_errWeight_GL)\n",
    "    cum_errWeight_FGL[count] = np.mean(mc_errWeight_FGL)\n",
    "    cum_errWeight_EW[count] = np.mean(mc_errWeight_EW)\n",
    "    cum_errWeight_TVFGL_laplacian[count] = np.mean(mc_errWeight_TVFGL_laplacian)\n",
    "    cum_errWeight_TVFGL_l1[count] = np.mean(mc_errWeight_TVFGL_l1)\n",
    "    cum_errWeight_TVFGL_grouplasso[count] = np.mean(mc_errWeight_TVFGL_grouplasso)\n",
    "    cum_errWeight_TVFGL_laplacian_load[count] = np.mean(mc_errWeight_TVFGL_laplacian_load)\n",
    "    cum_errWeight_TVFGL_l1_load[count] = np.mean(mc_errWeight_TVFGL_l1_load)\n",
    "    cum_errWeight_TVFGL_grouplasso_load[count] = np.mean(mc_errWeight_TVFGL_grouplasso_load)\n",
    "    \n",
    "cum_errTheta = np.concatenate((cum_errTheta_FGL,cum_errTheta_GL,cum_errTheta_EW,cum_errTheta_TVFGL_laplacian,cum_errTheta_TVFGL_l1,cum_errTheta_TVFGL_grouplasso,cum_errTheta_TVFGL_laplacian_load,cum_errTheta_TVFGL_l1_load,cum_errTheta_TVFGL_grouplasso_load), axis=1)\n",
    "savetxt('cum_errTheta_break_theta.csv', cum_errTheta, delimiter=',')\n",
    "\n",
    "cum_errWeight = np.concatenate((cum_errWeight_FGL,cum_errWeight_GL,cum_errWeight_EW,cum_errWeight_TVFGL_laplacian,cum_errWeight_TVFGL_l1,cum_errWeight_TVFGL_grouplasso,cum_errWeight_TVFGL_laplacian_load,cum_errWeight_TVFGL_l1_load,cum_errWeight_TVFGL_grouplasso_load), axis=1)\n",
    "savetxt('cum_errWeight_break_theta_and_loadings.csv', cum_errWeight, delimiter=',')\n",
    "\n",
    "savetxt('gamma_break_theta_and_loadings.csv', gamma_n, delimiter=',')\n",
    "      \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
