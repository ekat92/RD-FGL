{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa70f1d",
   "metadata": {},
   "source": [
    "## Lee TH., Seregina E.: \"Combining Forecasts under Structural Breaks Using Graphical LASSO\"\n",
    "\n",
    "### This Python notebook can be used to reproduce the values for RD-FGL time and state breaks in Table 1 and Table 2 for both empirical applications\n",
    "\n",
    "#### (Please refer to the R notebook to reproduce all other competing methods in both tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c695cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install regain if not already installed\n",
    "%pip install regain==0.3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873f7d1",
   "metadata": {},
   "source": [
    "#### Please make sure to place \"GL.py\" and \"TVGL.py\" in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d7fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "from __future__ import division\n",
    "from GL import GraphicalLasso\n",
    "from TVGL import TimeGraphicalLasso\n",
    "from regain.datasets import make_dataset\n",
    "from regain.utils import error_norm_time\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import scipy.linalg   # SciPy Linear Algebra Library\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################FUNCTIONS FOR EMPIRICAL APPLICATION#####################\n",
    "\n",
    "def portfolios(X,estsigm):\n",
    "    X = X.to_numpy()\n",
    "    mu = np.mean(X,axis=0).reshape(X.shape[1],1)\n",
    "    p = len(mu) \n",
    "    one = np.ones([p,1])\n",
    "    phi = one.T@estsigm@one\n",
    "    #GMV##\n",
    "    gmv = (estsigm @ one) / phi \n",
    "    return [gmv]  \n",
    "\n",
    "def CVlasso(X,Y, y2, k1, q, window, forecasters, truers, betas, covariate, alpha_set, beta_set): #X is returns, Y is residuals, K=k,\n",
    "    inX = X[0:(window-q)]\n",
    "    inY = Y[0:(window-q)]\n",
    "    iny2 = y2[0:(window-q)]\n",
    "    #################SFEs ARE HERE##################\n",
    "    meanSFE=np.zeros([len(alpha_set),len(beta_set)])\n",
    "    for alpha in range(0,len(alpha_set)):\n",
    "        for beta in range(0,len(beta_set)):\n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = alpha_set[alpha], beta = beta_set[beta]).fit(inY, iny2)\n",
    "#         if k1==1:\n",
    "#             Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#         else:\n",
    "#             Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "        \n",
    "            if k1==1:\n",
    "                bracket = (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "                bracket = bracket.astype(np.float64)\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                bracket = np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "                bracket = bracket.astype(np.float64)\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv(bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "    ###############################################################\n",
    "\n",
    "            portfolio_tvfgl = portfolios(inX, Thetatvfgl) #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "            weight_global = portfolio_tvfgl[0].T\n",
    "            competing = forecasters[(window-q):]\n",
    "            true_y = truers.iloc[(window-q):]\n",
    "            # competing = competing.to_numpy()\n",
    "            SFE = []\n",
    "            w1 = weight_global.T\n",
    "            for kappa in range(competing.shape[0]):\n",
    "                FE=w1.T@competing.iloc[kappa,:]\n",
    "    #################SFEs ARE HERE##################\n",
    "                SFE1=(true_y.iloc[kappa,:] - FE)**2\n",
    "                SFE.append(SFE1)\n",
    "\n",
    "            meanSFE[alpha,beta] = np.mean(SFE)   \n",
    "            meanSFE = np.ma.array(meanSFE, mask=np.isnan(meanSFE)) #NEW (in case any na values are generated)\n",
    "   \n",
    "    same = []\n",
    "    meanSFE_0 = []\n",
    "    for d in range(0,(len(iny2)-1)):\n",
    "        if iny2[d] ==iny2[d+1]:\n",
    "            same = 0\n",
    "        else:\n",
    "            same = 1\n",
    "    if same == 1:     \n",
    "        [alphaopt1, betaopt1] = [alpha_set[np.where(meanSFE == np.min(meanSFE))[0]], beta_set[np.where(meanSFE == np.min(meanSFE))[1]]]\n",
    "    else:\n",
    "        meanSFE_0 = meanSFE[:,1]\n",
    "      # betaopt1 = np.asarray(betaopt1)\n",
    "        [alphaopt1, betaopt1] = [alpha_set[np.where(meanSFE_0 == np.min(meanSFE_0))[0]], np.ravel(np.asarray(beta_set[np.where(meanSFE == np.min(meanSFE))[1]][0]))]\n",
    "#     if alphaopt1.shape[0]>1:\n",
    "#         alphaopt1 = np.asarray([alphaopt1[10]])\n",
    "#     if betaopt1.shape[0]>1:\n",
    "#         betaopt1 = np.asarray([betaopt1[10]])\n",
    "    return np.array([alphaopt1,betaopt1])\n",
    "\n",
    "\n",
    "def CV_gamma(gamma_set,r, r1_cv, r2_cv, k):          \n",
    "    err_gamma=np.zeros([len(gamma_set),1])\n",
    "    err_loo=np.zeros([r2_cv.shape[0],1])    \n",
    "    for gamma in range(0,len(gamma_set)):\n",
    "        for loo in range(0,r2_cv.shape[0]):\n",
    "            # r = F@Lambda[0:kDGP,] + eps\n",
    "            r1_upd = r1_cv*gamma_set[gamma]\n",
    "            r2_upd = np.delete(r2_cv, loo, axis=0)\n",
    "            ##leaving one time -series out\n",
    "            r_cv = np.concatenate((r1_upd, r2_upd), axis=0)\n",
    "\n",
    "            ##estimating factors and loadings with LOO returns           \n",
    "            L, V = np.linalg.eigh(np.dot(r_cv.T, r_cv))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k]  # kx1\n",
    "            Fhat = np.dot(r_cv, lmb)  # Txr (r=1 for PC1)\n",
    "            sum_i = np.zeros([r_cv.shape[1],1])\n",
    "            for i in range(r.shape[1]):\n",
    "                sum_j = np.zeros([r2_cv.shape[0],1])\n",
    "                ##computing sum of squared errors for the post-break period\n",
    "                for j in range(0,r2_cv.shape[0]):\n",
    "                    sum_j[j] = (r2_cv[j,i]-Fhat[j,:]@lmb.T[:,i])**2\n",
    "                sum_i[i] = np.sum(sum_j) \n",
    "            ##collecting SSEs for all LOOs    \n",
    "            err_loo[loo] = np.sum(sum_i)/(r.shape[1]*(r2_cv.shape[0]))   \n",
    "        ##compute average of all LOOs for one gamma                \n",
    "        err_gamma[gamma] = np.sum(err_loo)\n",
    "    return  gamma_set[np.where(err_gamma == np.min(err_gamma))[0]]\n",
    "\n",
    "\n",
    "def CV_break(j, t1_set,t2_set, trying, set1, window, forecasters, truers, k1):       \n",
    "    err_break_loadings=np.zeros([len(t1_set),len(t2_set)])\n",
    "    err_break_precision=np.zeros([len(t1_set),len(t2_set)])\n",
    "    count1 = -1\n",
    "    for t1 in t1_set:\n",
    "        count1 += 1\n",
    "        count2 = -1\n",
    "        for t2 in t2_set:\n",
    "            count2 += 1\n",
    "            # print('t2 =', t2, 'count2 =', count2)\n",
    "            breaks = np.zeros((trying.shape[0],1))\n",
    "            for jjj in range(0,trying.shape[0]):\n",
    "                if jjj <= t1:\n",
    "                    breaks[jjj,]=0\n",
    "                elif t1 < jjj <= t2:\n",
    "                    breaks[jjj,]=1\n",
    "                else:\n",
    "                    breaks[jjj,]=2\n",
    "          \n",
    "            breaks = breaks.astype(int)\n",
    "            breaks = np.ravel(breaks)\n",
    "            err1 = trying.iloc[0:t1,]\n",
    "            err11 = trying.iloc[t1:,]\n",
    "            err2 = trying.iloc[0:t2,]\n",
    "            err22 = trying.iloc[t2:,]\n",
    "                          \n",
    "            yset = breaks[(j+1):(j+window),].astype(int)\n",
    "            y2 = yset\n",
    "            y2 = y2.astype(int)\n",
    "            y2 = np.ravel(y2)  #otherwise tvfgl function will complain and ask to reshape\n",
    "          ###############################################################    \n",
    "    \n",
    "            set2 = set1.to_numpy()\n",
    "#             set2 = StandardScaler().fit(set2).transform(set2)\n",
    "            \n",
    "            if t1 < (j+window) < t2 and j < t1:\n",
    "                r1_cv = err1.iloc[j:t1,:]\n",
    "                r11_cv = err11.iloc[0:(j+window-t1),:]\n",
    "                r1_cv = r1_cv.to_numpy()\n",
    "                r11_cv = r11_cv.to_numpy()\n",
    "                gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k1)\n",
    "            elif (j+window) > t2 and t1 < j < t2:\n",
    "                r2_cv = err2.iloc[j:t2,:]\n",
    "                r22_cv = err22.iloc[0:(j+window-t2),:]\n",
    "                r2_cv = r2_cv.to_numpy()\n",
    "                r22_cv = r22_cv.to_numpy()\n",
    "                gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k1)\n",
    "            elif (j+window) > t2 and j < t1:\n",
    "                r1_cv = err1.iloc[j:t1,:]\n",
    "                r11_cv = err11.iloc[0:(j+window-t1),:]\n",
    "                r1_cv = r1_cv.to_numpy()\n",
    "                r11_cv = r11_cv.to_numpy()\n",
    "                gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k1)\n",
    "                r2_cv = err2.iloc[j:t2,:]\n",
    "                r22_cv = err22.iloc[0:(j+window-t2),:]\n",
    "                r2_cv = r2_cv.to_numpy()\n",
    "                r22_cv = r22_cv.to_numpy()\n",
    "                gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k1)\n",
    "            else:\n",
    "                gamma_opt = 1\n",
    "        \n",
    "            ####modified returns for time-varying loadings only!!!\n",
    "            set2_load = set2.copy()\n",
    "            for row in range(set2_load.shape[0]):\n",
    "                for col in range(set2_load.shape[1]):\n",
    "                    if row < (t1-j) and t1 < (j+window) < t2 and j < t1:\n",
    "                        set2_load[row,col]=gamma_opt* set2_load[row,col] \n",
    "                    elif row < (t2-j) and (j+window) > t2 and t1 < j < t2:\n",
    "                        set2_load[row,col]=gamma_opt* set2_load[row,col] \n",
    "                    elif (j+window) > t2 and j < t1:\n",
    "                        if row < (t1-j):\n",
    "                            set2_load[row,col]=gamma_opt1* set2_load[row,col] \n",
    "                        elif (t1-j) < row < (t2-j):\n",
    "                            set2_load[row,col]=gamma_opt2* set2_load[row,col] \n",
    "                        \n",
    "        \n",
    "            L_load, V_load = np.linalg.eigh(np.dot(set2_load.T, set2_load))\n",
    "            idx_load = L_load.argsort()[::-1]\n",
    "            L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "            V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "            lmb = V_load[:, 0:k1]  # kx1\n",
    "        \n",
    "            ###According to Su (2017, JoE) if we obtain Fhat\n",
    "            ###as usual they are only consistent for a rotational version\n",
    "            ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "            Fhat = set2@lmb@np.linalg.inv(lmb.T@lmb)\n",
    "            Y = set1 - Fhat@lmb.T ##these are the residuals\n",
    "            \n",
    "            sum_i = np.zeros([set1.shape[1],1])\n",
    "            for i in range(set1.shape[1]):\n",
    "                sum_j = np.zeros([set1.shape[0],1])\n",
    "                ##computing sum of squared errors for the post-break period\n",
    "                for jj in range(0,set1.shape[0]):\n",
    "                    sum_j[jj] = (set1.iloc[jj,i]-Fhat[jj,:]@lmb.T[:,i])**2\n",
    "                sum_i[i] = np.sum(sum_j) \n",
    "            err_break_loadings[count1, count2] = np.sum(sum_i)/(set1.shape[1]*(set1.shape[0]))   \n",
    "            \n",
    "            covariate = Fhat\n",
    "            betas = lmb.T\n",
    "            \n",
    "            #q=10 for GDP, q=5 for unemployment and CPI   \n",
    "            \n",
    "            tuning = CVlasso(X=set1,Y=Y,y2=y2,k1=k1, q=q, window=window, forecasters = forecasters, truers = truers, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            # tuning = CVlasso(X=set1,Y=Y,y2=y2, q=10, window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set,j=j, k1=k1)\n",
    "            tvfgl = TimeGraphicalLasso(max_iter=50, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y, y2)\n",
    "                #no tuning \n",
    "            # tvfgl = TimeGraphicalLasso(max_iter=100, alpha = alpha_set[1], beta = beta_set[1]).fit(Y, y2)\n",
    "#             if k1==1:\n",
    "#                 Thetatvfgl = tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@lmb@np.linalg.inv( (np.var(Fhat))**(-1)\n",
    "#                + lmb.T@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@lmb)@lmb.T@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "#             else:\n",
    "#                 Thetatvfgl = tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@lmb@np.linalg.inv( np.linalg.inv(np.cov(Fhat.T))\n",
    "#                + lmb.T@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@lmb)@lmb.T@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "            \n",
    "            if k1==1:\n",
    "                bracket = (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "                bracket = bracket.astype(np.float64)\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                bracket = np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "                bracket = bracket.astype(np.float64)\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv(bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "###############################################################\n",
    "            \n",
    "            portfolio_tvfgl = portfolios(set1, Thetatvfgl) #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "            weightTVFGL_global = portfolio_tvfgl[0].T\n",
    "           #######MODEL FORECASTS ARE HERE######\n",
    "            FETVFGL=y_frac.iloc[j,:] - weightTVFGL_global@Yhat.iloc[j,:]\n",
    "        #################SFEs ARE HERE##################\n",
    "            err_break_precision[count1, count2]=float((FETVFGL)**2 )\n",
    "        \n",
    "#         err_break_loadings = np.ma.array(err_break_loadings, mask=np.isnan(err_break_loadings)) #NEW (in case any na values are generated)\n",
    "            err_break_precision = np.ma.array(err_break_precision, mask=np.isnan(err_break_precision)) #NEW (in case any na values are generated)\n",
    "\n",
    "    [topt1_load, topt1_prec] = [t1_set[np.where(err_break_loadings == np.min(err_break_loadings))[0]][0], t1_set[np.where(err_break_precision == np.min(err_break_precision))[0][0]]]\n",
    "    [topt2_load, topt2_prec] = [t2_set[np.where(err_break_loadings == np.min(err_break_loadings))[1]][0], t2_set[np.where(err_break_precision == np.min(err_break_precision))[1][0]]]    \n",
    "    return np.array([topt1_load,topt1_prec, topt2_load,topt2_prec])\n",
    " ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTING THE SERIES\n",
    "## Please refer to README.txt for detailed data loading/description instructions\n",
    "#(to avoid confusion, we kept the names of the imported files the same for both applications.\n",
    "#So just make sure you insert the csv files that correspond to your application/series of interest)\n",
    "\n",
    "###for h=1 (for h>1 csv names have respective addition to the horizon, i.e., yhat2, forERR2)\n",
    "#importing series\n",
    "#first, predictors\n",
    "Yhat = pd.read_csv (r'yhat.csv')\n",
    "Yhat = Yhat.drop(Yhat.columns[[0]], axis=1)\n",
    "data = pd.read_csv (r'forERR.csv')\n",
    "data = data.drop(data.columns[[0]], axis=1)\n",
    "forERR = data\n",
    "trying = forERR\n",
    "# #second, actual series\n",
    "y_frac = pd.read_csv (r'ytrue.csv')\n",
    "y_frac = y_frac.drop(y_frac.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f8082",
   "metadata": {},
   "source": [
    "### ECB SPF State Breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############(STATE BREAKS)#################################################\n",
    "########PARAMETERS FOR ECB SPF################################################\n",
    "#(use ONLY FOR STATE-DEPENDENT BREAK, bc for TIME breaks the code estimates break locations)\n",
    "breaks = pd.read_csv (r'breaks.csv')\n",
    "\n",
    "#for a quick check please use a single value for gamma, alpha, and beta\n",
    "#the ranges below lead to increased computation time\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0.7,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3]).astype(float)\n",
    "beta_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3]).astype(float)\n",
    "\n",
    "iterations = range(30,55,10) #this is the size of the rolling window R in Table 1\n",
    "########################################\n",
    "\n",
    "MSFE_tvfgl=np.zeros((len(iterations),1))\n",
    "MSFE_tvfgl_load=np.zeros((len(iterations),1))\n",
    "\n",
    "count = -1\n",
    "h=1\n",
    "lamb = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ECB SPF APPLICATION (STATE BREAKS)\n",
    "\n",
    "for l in iterations:\n",
    "# PRESS TAB selecting all lines after this if uncomment line above\n",
    "    count = count + 1\n",
    "    T=trying.shape[0]\n",
    "    # l=50\n",
    "    window = l #12/31/2020 window is R\n",
    "    m2 =T-window  #Forecasting observations\n",
    "    ####FORECAST ERRORS MATRICES####\n",
    "    FETVFGL= np.zeros(((m2-h+1),1))\n",
    "    FETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    #####SFEs####\n",
    "    SFETVFGL= np.zeros(((m2-h+1),1))\n",
    "    SFETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    for j in range(0, (m2-h+1)):  \n",
    "        print('m2,j =', m2, ',', j)\n",
    "        set1 = trying.copy()\n",
    "        set1 = set1.iloc[j:(j+window),:] \n",
    "        set1.columns = range(trying.shape[1])\n",
    "        set1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        tv_mean_matrix=np.zeros((set1.shape[0]-1,set1.shape[1]))\n",
    "        for i in range(0,set1.shape[1]):\n",
    "            data = set1.iloc[:,i]\n",
    "            # Fit the AR(1) model\n",
    "            model = sm.tsa.ARIMA(data, order=(1, 0, 0))\n",
    "            results = model.fit()\n",
    "            tv_mean = results.params[0] + results.params[1]*set1.iloc[1:(set1.shape[0]),i]\n",
    "            tv_mean_matrix[:,i] = tv_mean\n",
    "\n",
    "        set1_demeaned = set1.iloc[1:,:]-tv_mean_matrix\n",
    "        ##################################################################\n",
    "\n",
    "        set2 = set1_demeaned.copy()\n",
    "        set2_nodown = set2.copy() #when only precision is time-varying, not loadings --> no downweighting\n",
    "        #         for dd in range(0,(window-1)): ##downweighting (alternative way)\n",
    "        #             set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-1-dd)\n",
    "        for dd in range(0,(window-1)): ##downweighting\n",
    "            set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-2) #used to be set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-1)\n",
    "        forecasters = Yhat.iloc[(j+1):(j+window),:]\n",
    "        truers = y_frac.iloc[(j+1):(j+window),:]\n",
    "        \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "\n",
    "        yset = breaks[(j+1):(j+window),].astype(int)\n",
    "        y2 = yset\n",
    "        y2 = y2.astype(int)\n",
    "        y2 = np.ravel(y2)  #otherwise tvfgl function will complain and ask to reshape\n",
    "    ###############################################################\n",
    "        #please just use the average value of gamma_opt = 0.8 for a quick check\n",
    "        gamma_opt = 0.8\n",
    "#         t1_loadings = t1_precision = 34\n",
    "#         t2_loadings = t2_precision = 81\n",
    "    ### CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "#         if t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "#             r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "#             r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "#             r1_cv = r1_cv.to_numpy()\n",
    "#             r11_cv = r11_cv.to_numpy()\n",
    "#             gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "#         elif (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "#             r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "#             r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "#             r2_cv = r2_cv.to_numpy()\n",
    "#             r22_cv = r22_cv.to_numpy()\n",
    "#             gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "#         elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "#             r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "#             r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "#             r1_cv = r1_cv.to_numpy()\n",
    "#             r11_cv = r11_cv.to_numpy()\n",
    "#             gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt1)\n",
    "#             r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "#             r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "#             r2_cv = r2_cv.to_numpy()\n",
    "#             r22_cv = r22_cv.to_numpy()\n",
    "#             gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt2)\n",
    "#         else:\n",
    "#             gamma_opt = 1\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "    ## END OF CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "    ##################################################################     \n",
    "        k1=2\n",
    "\n",
    "        ###############################################################################\n",
    "        ###############################################################################        \n",
    "        L, V = np.linalg.eigh(np.dot(set2.T, set2))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k1]  # kx1\n",
    "        Fhat = np.dot(set2, lmb)  # Txr (r=1 for PC1)\n",
    "\n",
    "        Y = set1_demeaned - Fhat@lmb.T ##these are the residuals\n",
    "\n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "        \n",
    "        ##########################################################              \n",
    "       \n",
    "        q=10 #for GDP, q=5 for unemployment and CPI   for ECB SPF\n",
    "        ###############################################################################################################\n",
    "        ########Time-Varying TVFGL#########        \n",
    "        tuning = CVlasso(X=set1,Y=Y,y2=y2,k1=k1, q=q, window=window, forecasters = forecasters, truers = truers, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set)\n",
    "        print(tuning.T)\n",
    "        tvfgl = TimeGraphicalLasso(max_iter=50, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y, y2)\n",
    "        if k1==1:\n",
    "            bracket = (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            bracket = np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv(bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "    ###############################################################     \n",
    "    ###############################################################                \n",
    "        portfolio_tvfgl = portfolios(set1_demeaned, theta_TVFGL)\n",
    "        \n",
    "        mu = set1.mean(axis=0) #subtracting mean of errors bc factors and loadings\n",
    "        #used to get weights were computed for demeaned data\n",
    "        #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "        weightTVFGL = portfolio_tvfgl[0].T\n",
    "       #######MODEL FORECASTS ARE HERE######\n",
    "        FETVFGL[j]=y_frac.iloc[window+j,:] - weightTVFGL@Yhat.iloc[window+j,:] #- weightTVFGL@mu\n",
    "    #################SFEs ARE HERE##################\n",
    "        SFETVFGL[j]=(FETVFGL[j])**2\n",
    "    #################### \n",
    "    FE[count,] = FETVFGL.reshape(-1,)\n",
    "    MSFE_tvfgl[count]=np.nanmean(SFETVFGL)\n",
    "    print('MSFE_tvfgl =', MSFE_tvfgl[count])\n",
    "    \n",
    "#This csv saves the MSFEs for RD-FGL for all R in iterations (R=30,40,50) as in Table 1,\n",
    "#to get the competing MSFE in Table 1 please use \"IJF_empirical_competing.ipynb\" which is written in R\n",
    "#(since most packages for the competing methods (like CLIME, LW, Nodewise regr'n, POET etc) were issued by\n",
    "#the original authors in R)\n",
    "savetxt('RDFGL_MSFE_ECB_state_breaks.csv', MSFE_tvfgl, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d61f9",
   "metadata": {},
   "source": [
    "### ECB SPF Time breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c355721",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############(TIME BREAKS)################################################\n",
    "########PARAMETERS FOR ECB SPF################################################\n",
    "\n",
    "#1) ONLY REQUIRED FOR TIME BREAKS (don't use for STATE BREAKS)\n",
    "#uncomment t1_set and t2_set that corresponds to the series of interest\n",
    "\n",
    "\n",
    "t1_set = np.arange(34,41,1)  #GDP break candidates\n",
    "t2_set = np.arange(81,89,1) #GDP break candidates\n",
    "\n",
    "# t1_set = np.arange(32,39,1)  #CPI break candidates\n",
    "# t2_set = np.arange(83,93,1) #CPI break candidates\n",
    "\n",
    "# t1_set = np.arange(42,50,1)  #UNEMP break candidates\n",
    "# t2_set = np.arange(80,86,1) #UNEMP break candidates\n",
    "\n",
    "#2) for a quick check please use a single value for gamma, alpha, and beta\n",
    "#the ranges below lead to increased computation time\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0.7,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3]).astype(float)\n",
    "beta_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3]).astype(float)\n",
    "\n",
    "iterations = range(30,55,10) #this is the size of the rolling window R in Table 1\n",
    "########################################\n",
    "\n",
    "MSFE_tvfgl=np.zeros((len(iterations),1))\n",
    "MSFE_tvfgl_load=np.zeros((len(iterations),1))\n",
    "\n",
    "count = -1\n",
    "h=1\n",
    "lamb = 0.98\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ECB SPF APPLICATION (TIME BREAKS)\n",
    "\n",
    "for l in iterations:\n",
    "# PRESS TAB selecting all lines after this if uncomment line above\n",
    "    count = count + 1\n",
    "    T=trying.shape[0]\n",
    "    # l=50\n",
    "    window = l #12/31/2020 window is R\n",
    "    m2 =T-window  #Forecasting observations\n",
    "    ####FORECAST ERRORS MATRICES####\n",
    "    FETVFGL= np.zeros(((m2-h+1),1))\n",
    "    FETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    #####SFEs####\n",
    "    SFETVFGL= np.zeros(((m2-h+1),1))\n",
    "    SFETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    for j in range(0, (m2-h+1)):  \n",
    "        print('m2,j =', m2, ',', j)\n",
    "        set1 = trying.copy()\n",
    "        set1 = set1.iloc[j:(j+window),:] \n",
    "        set1.columns = range(trying.shape[1])\n",
    "        set1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        tv_mean_matrix=np.zeros((set1.shape[0]-1,set1.shape[1]))\n",
    "        for i in range(0,set1.shape[1]):\n",
    "            data = set1.iloc[:,i]\n",
    "            # Fit the AR(1) model\n",
    "            model = sm.tsa.ARIMA(data, order=(1, 0, 0))\n",
    "            results = model.fit()\n",
    "            tv_mean = results.params[0] + results.params[1]*set1.iloc[1:(set1.shape[0]),i]\n",
    "            tv_mean_matrix[:,i] = tv_mean\n",
    "\n",
    "        set1_demeaned = set1.iloc[1:,:]-tv_mean_matrix\n",
    "        ##################################################################\n",
    "\n",
    "        set2 = set1_demeaned.copy()\n",
    "        set2_nodown = set2.copy() #when only precision is time-varying, not loadings --> no downweighting\n",
    "        #         for dd in range(0,(window-1)): ##downweighting (alternative way)\n",
    "        #             set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-1-dd)\n",
    "        for dd in range(0,(window-1)): ##downweighting\n",
    "            set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-2) #used to be set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-1)\n",
    "        forecasters = Yhat.iloc[(j+1):(j+window),:]\n",
    "        truers = y_frac.iloc[(j+1):(j+window),:]\n",
    "        \n",
    "        #IF USING KNOWN BREAKS please insert the values below and ignore CV_break function\n",
    "        t1_loadings = t1_precision = 34 #INSERT YOUR KNOWN BRAKE(S)\n",
    "        t2_loadings = t2_precision = 81 #INSERT YOUR KNOWN BRAKE(S)\n",
    "\n",
    "        #IF USING UNKNOWN breaks please make sure you specified t_1 and t_2 rangers in the PARAMETERS section\n",
    "        #and proceed using the CV_break search tool for breaks below\n",
    "\n",
    "#         t_opt =  CV_break(j=j, t1_set = t1_set,t2_set = t2_set, trying=trying, set1=set1_demeaned, window=window, forecasters=forecasters, truers=truers, k1=1)\n",
    "\n",
    "#         t1_loadings = t_opt[0]\n",
    "#         t1_precision = t_opt[1]\n",
    "#         t2_loadings = t_opt[2]\n",
    "#         t2_precision = t_opt[3]\n",
    "        \n",
    "        breaks = np.zeros((trying.shape[0],1))\n",
    "        for jjj in range(0,trying.shape[0]):\n",
    "            if jjj <= t1_precision:\n",
    "                breaks[jjj,]=0\n",
    "            elif t1_precision < jjj <= t2_precision:\n",
    "                breaks[jjj,]=1\n",
    "            else:\n",
    "                breaks[jjj,]=2\n",
    "        \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "\n",
    "        err1 = trying.iloc[0:t1_loadings,]\n",
    "        err11 = trying.iloc[t1_loadings:,]\n",
    "        err2 = trying.iloc[0:t2_loadings,]\n",
    "        err22 = trying.iloc[t2_loadings:,]\n",
    "\n",
    "        yset = breaks[(j+1):(j+window),].astype(int)\n",
    "        y2 = yset\n",
    "        y2 = y2.astype(int)\n",
    "        y2 = np.ravel(y2)  #otherwise tvfgl function will complain and ask to reshape\n",
    "    ###############################################################\n",
    "# UNLOCK THE BLOCK BELOW IF USING TIME BREAKS, LEAVE COMMENTED OUT OTHERWISE#####\n",
    "    ### CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "        if t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "            r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "            r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "            r1_cv = r1_cv.to_numpy()\n",
    "            r11_cv = r11_cv.to_numpy()\n",
    "            gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "        elif (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "            r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "            r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "            r2_cv = r2_cv.to_numpy()\n",
    "            r22_cv = r22_cv.to_numpy()\n",
    "            gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "        elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "            r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "            r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "            r1_cv = r1_cv.to_numpy()\n",
    "            r11_cv = r11_cv.to_numpy()\n",
    "            gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt1)\n",
    "            r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "            r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "            r2_cv = r2_cv.to_numpy()\n",
    "            r22_cv = r22_cv.to_numpy()\n",
    "            gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt2)\n",
    "        else:\n",
    "            gamma_opt = 1\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "    ## END OF CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "    ##################################################################\n",
    "\n",
    "        ####modified returns for time-varying loadings only!!!\n",
    "        set2_load = set1_demeaned.copy()\n",
    "        for row in range(set2_load.shape[0]):\n",
    "            for col in range(set2_load.shape[1]):\n",
    "                if row < (t1_loadings-j) and t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "                    set2_load.iloc[row,col]=gamma_opt* set2_load.iloc[row,col] \n",
    "                elif row < (t2_loadings-j) and (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "                    set2_load.iloc[row,col]=gamma_opt* set2_load.iloc[row,col] \n",
    "                elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "                    if row < (t1_loadings-j):\n",
    "                        set2_load.iloc[row,col]=gamma_opt1* set2_load.iloc[row,col] \n",
    "                    elif (t1_loadings-j) < row < (t2_loadings-j):\n",
    "                        set2_load.iloc[row,col]=gamma_opt2* set2_load.iloc[row,col] \n",
    "            #########################################################################################################################\n",
    "  #END OF UNLOCK THE BLOCK BELOW IF USING TIME BREAKS, LEAVE COMMENTED OUT OTHERWISE#####      \n",
    "        k1=2\n",
    "\n",
    "        L_load, V_load = np.linalg.eigh(np.dot(set2_load.T, set2_load))\n",
    "        idx_load = L_load.argsort()[::-1]\n",
    "        L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "        V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "        lmb_load = V_load[:, 0:k1]  # kx1\n",
    "\n",
    "        ###According to Su (2017, JoE) if we obtain Fhat\n",
    "        ###as usual they are only consistent for a rotational version\n",
    "        ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "        Fhat_load = set2_load@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "        Y_load = set1_demeaned - Fhat_load@lmb_load.T ##these are the residuals\n",
    "\n",
    "        covariate_load = Fhat_load\n",
    "        betas_load = lmb_load.T  \n",
    "        \n",
    "        ##########################################################              \n",
    "       \n",
    "        q=10 #for GDP, q=5 for unemployment and CPI   for ECB SPF\n",
    "        ###############################################################################################################\n",
    "\n",
    "    ###############################################################     \n",
    "    ###############################################################\n",
    "     ########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "        tuning = CVlasso(X=set2_load,Y=Y_load,k1=k1, y2=y2, q=q, window=window, forecasters = forecasters, truers = truers, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "        print(tuning.T)\n",
    "        tvfgl = TimeGraphicalLasso(max_iter=50, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y_load, y2)\n",
    "        if k1==1:\n",
    "            bracket = (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( bracket)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            bracket = np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv(bracket)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################           \n",
    "        \n",
    "        portfolio_tvfgl_load = portfolios(set1_demeaned, theta_TVFGL_load)\n",
    "        \n",
    "        mu = set1.mean(axis=0) #subtracting mean of errors bc factors and loadings\n",
    "        #used to get weights were computed for demeaned data\n",
    "        #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "        weightTVFGL_load = portfolio_tvfgl_load[0].T\n",
    "       #######MODEL FORECASTS ARE HERE######\n",
    "        FETVFGL_load[j]=y_frac.iloc[window+j,:] - weightTVFGL_load@Yhat.iloc[window+j,:]#- weightTVFGL_load@mu\n",
    "    #################SFEs ARE HERE##################\n",
    "        SFETVFGL_load[j]=(FETVFGL_load[j])**2\n",
    "    #################### \n",
    "    FE_load[count,] = FETVFGL_load.reshape(-1,)\n",
    "    MSFE_tvfgl_load[count]=np.nanmean(SFETVFGL_load)\n",
    "    print( 'MSFE_tvfgl_load =', MSFE_tvfgl_load[count])\n",
    "    \n",
    "#This csv saves the MSFEs for RD-FGL for all R in iterations (R=30,40,50) as in Table 1,\n",
    "#to get the competing MSFE in Table 1 please use \"IJF_empirical_competing.ipynb\" which is written in R\n",
    "#(since most packages for the competing methods (like CLIME, LW, Nodewise regr'n, POET etc) were issued by\n",
    "#the original authors in R)\n",
    "savetxt('RDFGL_MSFE_ECB_time_break.csv', MSFE_tvfgl_load, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b5c7c",
   "metadata": {},
   "source": [
    "### FRED MD State breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e93597",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############(STATE BREAKS)################################################\n",
    "########PARAMETERS FOR FRED-MD################################################\n",
    "#(use ONLY FOR STATE-DEPENDENT BREAK, bc for TIME breaks the code estimates break locations)\n",
    "breaks = pd.read_csv (r'breaks.csv')\n",
    "#####FRED-MD CANDIDATES##########\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0.7,1.05,0.05)  \n",
    "\n",
    "alpha_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3, 5]).astype(float)\n",
    "beta_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3, 5]).astype(float)\n",
    "\n",
    "###FRED-MD\n",
    "iterations = range(400,450,100)\n",
    "########################################\n",
    "T=trying.shape[0]\n",
    "# l=50\n",
    "window = iterations[0] #12/31/2020 window is R\n",
    "m2 =T-window  #Forecasting observations\n",
    "#########################################\n",
    "\n",
    "MSFE_tvfgl=np.zeros((len(iterations),1))\n",
    "MSFE_tvfgl_load=np.zeros((len(iterations),1))\n",
    "\n",
    "count = -1\n",
    "h=1\n",
    "lamb = 0.98\n",
    "q=150 #for tuning in fred md\n",
    "\n",
    "FE= np.zeros((len(iterations),(m2-h+1)))\n",
    "FE_load= np.zeros((len(iterations),(m2-h+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FRED MD APPLICATION (STATE BREAKS)\n",
    "\n",
    "for l in iterations:\n",
    "# PRESS TAB selecting all lines after this if uncomment line above\n",
    "    count = count + 1\n",
    "    T=trying.shape[0]\n",
    "    # l=50\n",
    "    window = l #12/31/2020 window is R\n",
    "    m2 =T-window  #Forecasting observations\n",
    "    ####FORECAST ERRORS MATRICES####\n",
    "    FETVFGL= np.zeros(((m2-h+1),1))\n",
    "    FETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    #####SFEs####\n",
    "    SFETVFGL= np.zeros(((m2-h+1),1))\n",
    "    SFETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    for j in range(0, (m2-h+1)):  \n",
    "        print('m2,j =', m2, ',', j)\n",
    "        set1 = trying.copy()\n",
    "        set1 = set1.iloc[j:(j+window),:] \n",
    "        set1.columns = range(trying.shape[1])\n",
    "        set1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        tv_mean_matrix=np.zeros((set1.shape[0]-1,set1.shape[1]))\n",
    "        for i in range(0,set1.shape[1]):\n",
    "            data = set1.iloc[:,i]\n",
    "            # Fit the AR(1) model\n",
    "            model = sm.tsa.ARIMA(data, order=(1, 0, 0))\n",
    "            results = model.fit()\n",
    "            tv_mean = results.params[0] + results.params[1]*set1.iloc[1:(set1.shape[0]),i]\n",
    "            tv_mean_matrix[:,i] = tv_mean\n",
    "\n",
    "        set1_demeaned = set1.iloc[1:,:]-tv_mean_matrix\n",
    "        ##################################################################\n",
    "\n",
    "        set2 = set1_demeaned.copy()\n",
    "        set2_nodown = set2.copy() #when only precision is time-varying, not loadings --> no downweighting\n",
    "        #         for dd in range(0,(window-1)): ##downweighting (alternative way)\n",
    "        #             set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-1-dd)\n",
    "        for dd in range(0,(window-1)): ##downweighting\n",
    "            set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-2) #used to be set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-1)\n",
    "        forecasters = Yhat.iloc[(j+1):(j+window),:]\n",
    "        truers = y_frac.iloc[(j+1):(j+window),:]\n",
    "        \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "\n",
    "        yset = breaks[(j+1):(j+window),].astype(int)\n",
    "        y2 = yset\n",
    "        y2 = y2.astype(int)\n",
    "        y2 = np.ravel(y2)  #otherwise tvfgl function will complain and ask to reshape\n",
    "    ###############################################################\n",
    "        #please just use the average value of gamma_opt = 0.8 for a quick check\n",
    "        gamma_opt = 0.8\n",
    "#         t1_loadings = t1_precision = 34\n",
    "#         t2_loadings = t2_precision = 81\n",
    "    ### CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "#         if t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "#             r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "#             r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "#             r1_cv = r1_cv.to_numpy()\n",
    "#             r11_cv = r11_cv.to_numpy()\n",
    "#             gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "#         elif (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "#             r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "#             r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "#             r2_cv = r2_cv.to_numpy()\n",
    "#             r22_cv = r22_cv.to_numpy()\n",
    "#             gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "#         elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "#             r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "#             r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "#             r1_cv = r1_cv.to_numpy()\n",
    "#             r11_cv = r11_cv.to_numpy()\n",
    "#             gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt1)\n",
    "#             r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "#             r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "#             r2_cv = r2_cv.to_numpy()\n",
    "#             r22_cv = r22_cv.to_numpy()\n",
    "#             gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "#             print('gamma_opt =', gamma_opt2)\n",
    "#         else:\n",
    "#             gamma_opt = 1\n",
    "#             print('gamma_opt =', gamma_opt)\n",
    "    ## END OF CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "    ##################################################################     \n",
    "        k1=2\n",
    "\n",
    "        ###############################################################################\n",
    "        ###############################################################################        \n",
    "        L, V = np.linalg.eigh(np.dot(set2.T, set2))\n",
    "        idx = L.argsort()[::-1]\n",
    "        L = L[idx]  # eigenvalues, Nx1\n",
    "        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "        lmb = V[:, 0:k1]  # kx1\n",
    "        Fhat = np.dot(set2, lmb)  # Txr (r=1 for PC1)\n",
    "\n",
    "        Y = set1_demeaned - Fhat@lmb.T ##these are the residuals\n",
    "\n",
    "        covariate = Fhat\n",
    "        betas = lmb.T\n",
    "        \n",
    "        ##########################################################              \n",
    "       \n",
    "        q=150 #for FRED MD\n",
    "        ###############################################################################################################\n",
    "        ########Time-Varying TVFGL#########        \n",
    "        tuning = CVlasso(X=set1,Y=Y,y2=y2,k1=k1, q=q, window=window, forecasters = forecasters, truers = truers, betas = betas, covariate=covariate, alpha_set=alpha_set, beta_set=beta_set)\n",
    "        print(tuning.T)\n",
    "        tvfgl = TimeGraphicalLasso(max_iter=50, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y, y2)\n",
    "        if k1==1:\n",
    "            bracket = (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            bracket = np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv(bracket)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "    ###############################################################     \n",
    "    ###############################################################                \n",
    "        portfolio_tvfgl = portfolios(set1_demeaned, theta_TVFGL)\n",
    "        \n",
    "        mu = set1.mean(axis=0) #subtracting mean of errors bc factors and loadings\n",
    "        #used to get weights were computed for demeaned data\n",
    "        #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "        weightTVFGL = portfolio_tvfgl[0].T\n",
    "       #######MODEL FORECASTS ARE HERE######\n",
    "        FETVFGL[j]=y_frac.iloc[window+j,:] - weightTVFGL@Yhat.iloc[window+j,:] #- weightTVFGL@mu\n",
    "    #################SFEs ARE HERE##################\n",
    "        SFETVFGL[j]=(FETVFGL[j])**2\n",
    "    #################### \n",
    "    FE[count,] = FETVFGL.reshape(-1,)\n",
    "    MSFE_tvfgl[count]=np.nanmean(SFETVFGL)\n",
    "    print('MSFE_tvfgl =', MSFE_tvfgl[count])\n",
    "    \n",
    "#This csv saves the MSFEs for RD-FGL in Table 2\n",
    "#to get the competing MSFE in Table 2 please use \"IJF_empirical_competing.ipynb\" which is written in R\n",
    "#(since most packages for the competing methods (like CLIME, LW, Nodewise regr'n, POET etc) were issued by\n",
    "#the original authors in R)\n",
    "savetxt('RDFGL_MSFE_FRED_state_breaks.csv', MSFE_tvfgl, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447af0f",
   "metadata": {},
   "source": [
    "### FRED MD Time breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2176a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############(TIME BREAKS)################################################\n",
    "########PARAMETERS FOR FRED-MD################################################\n",
    "\n",
    "#####FRED-MD CANDIDATES##########\n",
    "#1) ONLY REQUIRED FOR TIME BREAKS (don't use for STATE BREAKS)\n",
    "#uncomment t1_set and t2_set that corresponds to the series of interest\n",
    "\n",
    "#using the ranges below substantially increases computational time\n",
    "#so we include the breaks identified from our results:\n",
    "#INDPROD: t1 = 353, t2 = 494\n",
    "#CPI: t1 = 320, t2 = 433\n",
    "#PCEPI: t1 = 353, t2 = 495\n",
    "#UNEMP: t1 = 348, t2 = 492\n",
    "\n",
    "t1_set = np.arange(350,361,1)  #INDPROD break candidates \n",
    "t2_set = np.arange(490,501,1) #INDPROD break candidates\n",
    "\n",
    "# t1_set = np.arange(315,350,1)  #CPI break candidates \n",
    "# t2_set = np.arange(425,460,1) #CPI break candidates \n",
    "\n",
    "# t1_set = np.arange(345,361,1)  #PCEPI break candidates\n",
    "# t2_set = np.arange(490,501,1) #PCEPI break candidates \n",
    "\n",
    "# t1_set = np.arange(340,361,1)  #UNEMP break candidates \n",
    "# t2_set = np.arange(490,501,1) #UNEMP break candidates \n",
    "\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0.7,1.05,0.05)  \n",
    "\n",
    "alpha_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3, 5]).astype(float)\n",
    "beta_set = np.array([0, 0.1, 0.25, 0.5, 0.7, 1, 3, 5]).astype(float)\n",
    "\n",
    "###FRED-MD\n",
    "iterations = range(400,450,100)\n",
    "########################################\n",
    "T=trying.shape[0]\n",
    "# l=50\n",
    "window = iterations[0] #12/31/2020 window is R\n",
    "m2 =T-window  #Forecasting observations\n",
    "#########################################\n",
    "\n",
    "MSFE_tvfgl=np.zeros((len(iterations),1))\n",
    "MSFE_tvfgl_load=np.zeros((len(iterations),1))\n",
    "\n",
    "count = -1\n",
    "h=1\n",
    "lamb = 0.98\n",
    "q=150 #for tuning in fred md\n",
    "\n",
    "FE= np.zeros((len(iterations),(m2-h+1)))\n",
    "FE_load= np.zeros((len(iterations),(m2-h+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FRED MD APPLICATION (TIME BREAKS)\n",
    "\n",
    "for l in iterations:\n",
    "# PRESS TAB selecting all lines after this if uncomment line above\n",
    "    count = count + 1\n",
    "    T=trying.shape[0]\n",
    "    # l=50\n",
    "    window = l #12/31/2020 window is R\n",
    "    m2 =T-window  #Forecasting observations\n",
    "    ####FORECAST ERRORS MATRICES####\n",
    "    FETVFGL= np.zeros(((m2-h+1),1))\n",
    "    FETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    #####SFEs####\n",
    "    SFETVFGL= np.zeros(((m2-h+1),1))\n",
    "    SFETVFGL_load= np.zeros(((m2-h+1),1))\n",
    "    for j in range(0, (m2-h+1)):  \n",
    "        print('m2,j =', m2, ',', j)\n",
    "        set1 = trying.copy()\n",
    "        set1 = set1.iloc[j:(j+window),:] \n",
    "        set1.columns = range(trying.shape[1])\n",
    "        set1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        tv_mean_matrix=np.zeros((set1.shape[0]-1,set1.shape[1]))\n",
    "        for i in range(0,set1.shape[1]):\n",
    "            data = set1.iloc[:,i]\n",
    "            # Fit the AR(1) model\n",
    "            model = sm.tsa.ARIMA(data, order=(1, 0, 0))\n",
    "            results = model.fit()\n",
    "            tv_mean = results.params[0] + results.params[1]*set1.iloc[1:(set1.shape[0]),i]\n",
    "            tv_mean_matrix[:,i] = tv_mean\n",
    "\n",
    "        set1_demeaned = set1.iloc[1:,:]-tv_mean_matrix\n",
    "        ##################################################################\n",
    "\n",
    "        set2 = set1_demeaned.copy()\n",
    "        set2_nodown = set2.copy() #when only precision is time-varying, not loadings --> no downweighting\n",
    "        #         for dd in range(0,(window-1)): ##downweighting (alternative way)\n",
    "        #             set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-1-dd)\n",
    "        for dd in range(0,(window-1)): ##downweighting\n",
    "            set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-2) #used to be set2.iloc[dd,:] = set2.iloc[dd,:]*lamb**(window-dd-1)\n",
    "        forecasters = Yhat.iloc[(j+1):(j+window),:]\n",
    "        truers = y_frac.iloc[(j+1):(j+window),:]\n",
    "        \n",
    "        #IF USING KNOWN BREAKS please insert the values below and ignore CV_break function\n",
    "        t1_loadings = t1_precision = 353 #INSERT YOUR KNOWN BRAKE(S)\n",
    "        t2_loadings = t2_precision = 494 #INSERT YOUR KNOWN BRAKE(S)\n",
    "\n",
    "        #IF USING UNKNOWN breaks please make sure you specified t_1 and t_2 rangers in the PARAMETERS section\n",
    "        #and proceed using the CV_break search tool for breaks below\n",
    "\n",
    "#         t_opt =  CV_break(j=j, t1_set = t1_set,t2_set = t2_set, trying=trying, set1=set1_demeaned, window=window, forecasters=forecasters, truers=truers, k1=1)\n",
    "\n",
    "#         t1_loadings = t_opt[0]\n",
    "#         t1_precision = t_opt[1]\n",
    "#         t2_loadings = t_opt[2]\n",
    "#         t2_precision = t_opt[3]\n",
    "        \n",
    "        breaks = np.zeros((trying.shape[0],1))\n",
    "        for jjj in range(0,trying.shape[0]):\n",
    "            if jjj <= t1_precision:\n",
    "                breaks[jjj,]=0\n",
    "            elif t1_precision < jjj <= t2_precision:\n",
    "                breaks[jjj,]=1\n",
    "            else:\n",
    "                breaks[jjj,]=2\n",
    "        \n",
    "        breaks = breaks.astype(int)\n",
    "        breaks = np.ravel(breaks)\n",
    "\n",
    "        err1 = trying.iloc[0:t1_loadings,]\n",
    "        err11 = trying.iloc[t1_loadings:,]\n",
    "        err2 = trying.iloc[0:t2_loadings,]\n",
    "        err22 = trying.iloc[t2_loadings:,]\n",
    "\n",
    "        yset = breaks[(j+1):(j+window),].astype(int)\n",
    "        y2 = yset\n",
    "        y2 = y2.astype(int)\n",
    "        y2 = np.ravel(y2)  #otherwise tvfgl function will complain and ask to reshape\n",
    "    ###############################################################\n",
    "# UNLOCK THE BLOCK BELOW IF USING TIME BREAKS, LEAVE COMMENTED OUT OTHERWISE#####\n",
    "    ### CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "        if t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "            r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "            r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "            r1_cv = r1_cv.to_numpy()\n",
    "            r11_cv = r11_cv.to_numpy()\n",
    "            gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "        elif (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "            r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "            r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "            r2_cv = r2_cv.to_numpy()\n",
    "            r22_cv = r22_cv.to_numpy()\n",
    "            gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "        elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "            r1_cv = err1.iloc[j:t1_loadings,:]\n",
    "            r11_cv = err11.iloc[0:(j+window-t1_loadings),:]\n",
    "            r1_cv = r1_cv.to_numpy()\n",
    "            r11_cv = r11_cv.to_numpy()\n",
    "            gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt1)\n",
    "            r2_cv = err2.iloc[j:t2_loadings,:]\n",
    "            r22_cv = err22.iloc[0:(j+window-t2_loadings),:]\n",
    "            r2_cv = r2_cv.to_numpy()\n",
    "            r22_cv = r22_cv.to_numpy()\n",
    "            gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k=1)\n",
    "            print('gamma_opt =', gamma_opt2)\n",
    "        else:\n",
    "            gamma_opt = 1\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "    ## END OF CROSS-VALIDATED VALUE OF GAMMA #####\n",
    "    ##################################################################\n",
    "\n",
    "        ####modified returns for time-varying loadings only!!!\n",
    "        set2_load = set1_demeaned.copy()\n",
    "        for row in range(set2_load.shape[0]):\n",
    "            for col in range(set2_load.shape[1]):\n",
    "                if row < (t1_loadings-j) and t1_loadings < (j+window) < t2_loadings and j < t1_loadings:\n",
    "                    set2_load.iloc[row,col]=gamma_opt* set2_load.iloc[row,col] \n",
    "                elif row < (t2_loadings-j) and (j+window) > t2_loadings and t1_loadings < j < t2_loadings:\n",
    "                    set2_load.iloc[row,col]=gamma_opt* set2_load.iloc[row,col] \n",
    "                elif (j+window) > t2_loadings and j < t1_loadings:\n",
    "                    if row < (t1_loadings-j):\n",
    "                        set2_load.iloc[row,col]=gamma_opt1* set2_load.iloc[row,col] \n",
    "                    elif (t1_loadings-j) < row < (t2_loadings-j):\n",
    "                        set2_load.iloc[row,col]=gamma_opt2* set2_load.iloc[row,col] \n",
    "            #########################################################################################################################\n",
    "  #END OF UNLOCK THE BLOCK BELOW IF USING TIME BREAKS, LEAVE COMMENTED OUT OTHERWISE#####      \n",
    "        k1=2\n",
    "\n",
    "        L_load, V_load = np.linalg.eigh(np.dot(set2_load.T, set2_load))\n",
    "        idx_load = L_load.argsort()[::-1]\n",
    "        L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "        V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "        lmb_load = V_load[:, 0:k1]  # kx1\n",
    "\n",
    "        ###According to Su (2017, JoE) if we obtain Fhat\n",
    "        ###as usual they are only consistent for a rotational version\n",
    "        ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "        Fhat_load = set2_load@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "        Y_load = set1_demeaned - Fhat_load@lmb_load.T ##these are the residuals\n",
    "\n",
    "        covariate_load = Fhat_load\n",
    "        betas_load = lmb_load.T  \n",
    "        \n",
    "        ##########################################################              \n",
    "       \n",
    "        q=150 #for FRED MD\n",
    "        ###############################################################################################################\n",
    "\n",
    "    ###############################################################     \n",
    "    ###############################################################\n",
    "     ########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "        tuning = CVlasso(X=set2_load,Y=Y_load,k1=k1, y2=y2, q=q, window=window, forecasters = forecasters, truers = truers, betas = betas_load, covariate=covariate_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "        print(tuning.T)\n",
    "        tvfgl = TimeGraphicalLasso(max_iter=50, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y_load, y2)\n",
    "        if k1==1:\n",
    "            bracket = (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( bracket)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "        else:\n",
    "            bracket = np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T\n",
    "            bracket = bracket.astype(np.float64)\n",
    "            theta_TVFGL_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv(bracket)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     ###############################################################           \n",
    "        \n",
    "        portfolio_tvfgl_load = portfolios(set1_demeaned, theta_TVFGL_load)\n",
    "        \n",
    "        mu = set1.mean(axis=0) #subtracting mean of errors bc factors and loadings\n",
    "        #used to get weights were computed for demeaned data\n",
    "        #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "        weightTVFGL_load = portfolio_tvfgl_load[0].T\n",
    "       #######MODEL FORECASTS ARE HERE######\n",
    "        FETVFGL_load[j]=y_frac.iloc[window+j,:] - weightTVFGL_load@Yhat.iloc[window+j,:]#- weightTVFGL_load@mu\n",
    "    #################SFEs ARE HERE##################\n",
    "        SFETVFGL_load[j]=(FETVFGL_load[j])**2\n",
    "    #################### \n",
    "    FE_load[count,] = FETVFGL_load.reshape(-1,)\n",
    "    MSFE_tvfgl_load[count]=np.nanmean(SFETVFGL_load)\n",
    "    print( 'MSFE_tvfgl_load =', MSFE_tvfgl_load[count])\n",
    "    \n",
    "#This csv saves the MSFEs for RD-FGL in Table 2\n",
    "#to get the competing MSFE in Table 2 please use \"IJF_empirical_competing.ipynb\" which is written in R\n",
    "#(since most packages for the competing methods (like CLIME, LW, Nodewise regr'n, POET etc) were issued by\n",
    "#the original authors in R)\n",
    "savetxt('RDFGL_MSFE_FRED_time_break.csv', MSFE_tvfgl_load, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
