{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fea329",
   "metadata": {},
   "source": [
    "## Lee TH., Seregina E.: \"Combining Forecasts under Structural Breaks Using Graphical LASSO\"\n",
    "\n",
    "### This Python notebook can be used to reproduce Monte Carlo results for MSFE in Supplementary Appendix Figures E2, E4,  E7, E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236dfff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install regain==0.3.9\n",
    "# %pip install numpy\n",
    "# %pip install scipy\n",
    "# %pip install scikit-learn\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5173e57",
   "metadata": {},
   "source": [
    "#### Please make sure to place \"GL.py\" and \"TVGL.py\" in the same directory as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from GL import GraphicalLasso\n",
    "# from TVGL2 import TimeGraphicalLasso\n",
    "from TVGL import TimeGraphicalLasso\n",
    "from regain.datasets import make_dataset\n",
    "from regain.utils import error_norm_time\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import scipy.linalg   # SciPy Linear Algebra Library\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "from scipy.linalg import cholesky\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from numpy.linalg import inv\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############FUNCTIONS#############\n",
    "def portfolios(X,estsigm):\n",
    "    X = X.to_numpy()\n",
    "    mu = np.mean(X,axis=0).reshape(X.shape[1],1)\n",
    "    p = len(mu) \n",
    "    one = np.ones([p,1])\n",
    "    phi = one.T@estsigm@one\n",
    "    #GMV##\n",
    "    gmv = (estsigm @ one) / phi \n",
    "    return [gmv]  \n",
    "###################################################################\n",
    "\n",
    "def MakeAR(y,lag):\n",
    "    x = np.ones((y.shape[0]-lag, 1))\n",
    "    if lag !=(-1):\n",
    "        for l in range(0,lag+1):\n",
    "            x=np.concatenate([x,y[(lag-l):(len(y) - l)]], axis=1)\n",
    "        else:\n",
    "            x=x\n",
    "    return [x]   \n",
    "####################################################################\n",
    "def CVlasso(penalty, X,Y, y2, k1, q, window, forecasters, truers, Fhat, lmb, alpha_set, beta_set): #X is returns, Y is residuals, K=k,\n",
    "    inX = X[0:(window-q)]\n",
    "    inY = Y[0:(window-q)]\n",
    "    iny2 = y2[0:(window-q)]\n",
    "    #################SFEs ARE HERE##################\n",
    "    meanSFE=np.zeros([len(alpha_set),len(beta_set)])\n",
    "    for alpha in range(0,len(alpha_set)):\n",
    "        for beta in range(0,len(beta_set)):\n",
    "            if penalty == '':\n",
    "                tvfgl = TimeGraphicalLasso(max_iter=100, alpha = alpha_set[alpha], beta = beta_set[beta]).fit(inY, iny2)\n",
    "            else:    \n",
    "                tvfgl = TimeGraphicalLasso(psi=penalty, max_iter=100, alpha = alpha_set[alpha], beta = beta_set[beta]).fit(inY, iny2)\n",
    "            if k1==1:\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                Thetatvfgl=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "\n",
    "            portfolio_tvfgl = portfolios(inX, Thetatvfgl) #IMPORTANT: use non-standardized returns when computing portfolio weights!!!\n",
    "            weight_global = portfolio_tvfgl[0].T\n",
    "            competing = forecasters[(window-q):]\n",
    "            true_y = truers.iloc[(window-q):]\n",
    "            # competing = competing.to_numpy()\n",
    "            SFE = []\n",
    "            w1 = weight_global.T\n",
    "            for kappa in range(competing.shape[0]):\n",
    "                FE=w1.T@competing.iloc[kappa,:]\n",
    "        #################SFEs ARE HERE##################\n",
    "                SFE1=(true_y.iloc[kappa,:] - FE)**2\n",
    "                SFE.append(SFE1)\n",
    "\n",
    "            meanSFE[alpha,beta] = np.mean(SFE)    \n",
    "        same = []\n",
    "        meanSFE_0 = []\n",
    "    for d in range(0,(len(iny2)-1)):\n",
    "        if iny2[d] ==iny2[d+1]:\n",
    "            same = 0\n",
    "        else:\n",
    "            same = 1\n",
    "        if same == 1:     \n",
    "            [alphaopt1, betaopt1] = [alpha_set[np.where(meanSFE == np.nanmin(meanSFE))[0]], beta_set[np.where(meanSFE == np.nanmin(meanSFE))[1]]]\n",
    "        else:\n",
    "            meanSFE_0 = meanSFE[:,1]\n",
    "        # betaopt1 = np.asarray(betaopt1)\n",
    "            [alphaopt1, betaopt1] = [alpha_set[np.where(meanSFE_0 == np.nanmin(meanSFE_0))[0]], np.ravel(np.asarray(beta_set[np.where(meanSFE == np.nanmin(meanSFE))[1]][0]))]\n",
    "        return np.array([alphaopt1,betaopt1])\n",
    "    \n",
    "\n",
    "def CV_gamma(gamma_set,r, r1_cv, r2_cv, k):          \n",
    "    err_gamma=np.zeros([len(gamma_set),1])\n",
    "    err_loo=np.zeros([r2_cv.shape[0],1])    \n",
    "    for gamma in range(0,len(gamma_set)):\n",
    "        for loo in range(0,r2_cv.shape[0]):\n",
    "            # r = F@Lambda[0:kDGP,] + eps\n",
    "            r1_upd = r1_cv*gamma_set[gamma]\n",
    "            r2_upd = np.delete(r2_cv, loo, axis=0)\n",
    "            ##leaving one time -series out\n",
    "            r_cv = np.concatenate((r1_upd, r2_upd), axis=0)\n",
    "\n",
    "            ##estimating factors and loadings with LOO returns           \n",
    "            L, V = np.linalg.eigh(np.dot(r_cv.T, r_cv))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k]  # kx1\n",
    "            Fhat = np.dot(r_cv, lmb)  # Txr (r=1 for PC1)\n",
    "            sum_i = np.zeros([r_cv.shape[1],1])\n",
    "            for i in range(r.shape[1]):\n",
    "                sum_j = np.zeros([r2_cv.shape[0],1])\n",
    "                ##computing sum of squared errors for the post-break period\n",
    "                for j in range(0,r2_cv.shape[0]):\n",
    "                    sum_j[j] = (r2_cv[j,i]-Fhat[j,:]@lmb.T[:,i])**2\n",
    "                sum_i[i] = np.sum(sum_j) \n",
    "            ##collecting SSEs for all LOOs    \n",
    "            err_loo[loo] = np.sum(sum_i)/(r.shape[1]*(r2_cv.shape[0]))   \n",
    "        ##compute average of all LOOs for one gamma                \n",
    "        err_gamma[gamma] = np.sum(err_loo)\n",
    "    return  gamma_set[np.where(err_gamma == np.min(err_gamma))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########PARAMETERS################################################\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "beta_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "##################################################################\n",
    "c1 = 0.75\n",
    "c2 = 0.9\n",
    "r = 5 #Factors in DGP\n",
    "sigmaF = 1\n",
    "sigmaX = 1\n",
    "sigmaY = sigmaX\n",
    "p1 = 8 #Number of AR(l) models\n",
    "r2 = 3 #Estimated factors. Used to be 2\n",
    "r3 =5 #Factors in modeling Forecast Errors\n",
    "s = p1*(1+r2) #Forecasters\n",
    "rho=0.9 #in regime 1 ## USED TO BE 0.2, in the paper figure 3 says rho=0.9, but it was 0.2\n",
    "rho2 = 0.8 #in regime 2 ##rho2 is not used for defining regimes, not sure why its here\n",
    "phi = 0.8\n",
    "N=100\n",
    "reps = 500\n",
    "#####################################################################\n",
    "# sample_size=range(400,1250,200)\n",
    "sample_size=range(800,1250,200)\n",
    "# sample_size=range(1000,1250,200)\n",
    "####Try\n",
    "# N=100\n",
    "# sample_size=range(400,650,200)\n",
    "\n",
    "#####PLACEHOLDERS\n",
    "##########Matrices Placeholders######\n",
    "###for h=1\n",
    "cum_GL = np.zeros((len(sample_size),1))\n",
    "cum_FGL = np.zeros((len(sample_size),1))\n",
    "cum_EW = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_laplacian_load = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_l1_load = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_grouplasso_load = np.zeros((len(sample_size),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4be63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####Appendix Figure E2: BREAK IN BOTH PRECISION AND LOADINGS##################\n",
    "count=-1\n",
    "# count=1 #if interrupted and continue to run\n",
    "for T in sample_size:\n",
    "    count = count + 1\n",
    "    m2 = int(round(2*T/3)) #Forecasting observations\n",
    "    m1=T-m2 \n",
    "    window = int(round(m2/2))\n",
    "    T1 = m1 + int(round(window/2))\n",
    "    ###for h=1\n",
    "    error_EW =  np.zeros((reps+1,1))\n",
    "    error_GL =  np.zeros((reps+1,1))\n",
    "    error_FGL =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_laplacian =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_l1 =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_grouplasso =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_laplacian_load =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_l1_load =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_grouplasso_load =  np.zeros((reps+1,1))\n",
    "    \n",
    "    \n",
    "    ###Incorporating break in theta through break in c2####\n",
    "   \n",
    "    #######################################################\n",
    "    for z in range(reps+1):  \n",
    "        e = np.random.randn(T,1)      \n",
    "        theta = np.zeros((T,1))  \n",
    "        breaks_full = np.zeros((T,1))\n",
    "        for w in range(T):\n",
    "            if w <= T1:\n",
    "                c2 = 0.3  \n",
    "                theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "                breaks_full[w,]=0\n",
    "            else:\n",
    "                c2 = 0.4  ###for normal break was 0.9\n",
    "                theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "                breaks_full[w,]=1\n",
    "        breaks_full = breaks_full.astype(int)\n",
    "        breaks_full = np.ravel(breaks_full)\n",
    "        \n",
    "\n",
    "        #######################################################\n",
    "        y1 = np.zeros((T,1)) \n",
    "        for g in range(T):\n",
    "            y1[g] = theta[0:(g+1)].T@np.flip(e[0:(g+1)])\n",
    "         \n",
    "        \n",
    "        ###################################################\n",
    "        #creating Toeplitz matrix and its Cholesky decomposition\n",
    "        ####For regime 1\n",
    "        O = np.zeros((N, N))\n",
    "        np.fill_diagonal(O, np.ones(N))     \n",
    "        for h in range(1,N):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, N-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, N-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "        ######################################\n",
    "        F = np.zeros((T,r))\n",
    "        F[0,] = sigmaF*np.random.randn(1,r)\n",
    "        v=np.random.randn(T,r)\n",
    "        for j in range(0,r):\n",
    "            for t in range(1,T):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "                \n",
    "        ##################################################        \n",
    "        ###############NO BREAKS##########################\n",
    "        X = F@Lambda[0:r,] + sigmaX*np.random.randn(T,N)\n",
    "        ##################################################\n",
    "        alpha = np.random.randn(r,1)+1\n",
    "        y2 = np.zeros((T,1))\n",
    "        y2[1:T]= F[0:(T-1),]@alpha +0*sigmaY*np.random.randn((T-1),1)\n",
    "        y=y1+y2\n",
    "        \n",
    "        Yhat = np.zeros((m2,s))\n",
    "       \n",
    "        \n",
    "        for col in range(0,p1):  # Col=1 when no lags\n",
    "            for k in range(0,r2+1): # Number of factors\n",
    "                for row in range(0,m2):\n",
    "                    xx = MakeAR(y[(row):(m1-1+row)], (col-1))[0]\n",
    "                    if col==0 and k!=0:\n",
    "                        xx = np.ones(((m1-1),1))\n",
    "\n",
    "                    if k==0:\n",
    "                        xx=xx\n",
    "                        coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1+row)]\n",
    "                    else:\n",
    "                        data = X[(row):(m1-1+row),]\n",
    "                        L, V = np.linalg.eigh(np.dot(data.T, data))\n",
    "                        idx = L.argsort()[::-1]\n",
    "                        L = L[idx]  # eigenvalues, Nx1\n",
    "                        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "                        lmb = V[:, 0:k]  # kx1\n",
    "                        Fhat = np.dot(data, lmb)\n",
    "                        if col==0:\n",
    "                            Fhat = Fhat[(col):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "                        else:\n",
    "                            Fhat = Fhat[(col-1):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "\n",
    "                        if col==0:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col+1):(m1 +row)]\n",
    "                        else:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1 +row)]   \n",
    "                    if col == 0: # 0 lags \n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = coef #if col=1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]), Fhat[Fhat.shape[0]-1,]], axis=0)@coef #if col=0 and k>0          \n",
    "                    else:         # >=1 lags\n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)]))], axis=0)@coef                    \n",
    "                            # Yhat[row,((r2+1)*(col)+k)] = np.array([1,np.flip(y[(m1 +row-col+1):(m1 +row+1)])])@coef #if col>1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])), Fhat[Fhat.shape[0]-1,]], axis=0)@coef \n",
    "                            # USED TO BE np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])) PLUS instead of MINUS for some reason\n",
    " ##################################################################################333\n",
    "        \n",
    "        forERR=np.full((Yhat.shape[0], Yhat.shape[1]), y[(m1):T]) - Yhat\n",
    "               \n",
    "        y =  pd.DataFrame(y)\n",
    "        ###for h=1\n",
    "        trying = forERR\n",
    "        Yhat = pd.DataFrame(Yhat)\n",
    "        forERR = pd.DataFrame(forERR)\n",
    "        y_oos = pd.DataFrame(y[(m1):T])\n",
    "        breaks = breaks_full[(m1):T]\n",
    "        \n",
    "        ###############################################################\n",
    "        ####FORECAST ERRORS MATRICES####\n",
    "        ###for h=1\n",
    "        FEEW= np.zeros((m2-window,1))\n",
    "        FEGL= np.zeros((m2-window,1))\n",
    "        FEFGL= np.zeros((m2-window,1))\n",
    "        FETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "        FETVFGL_l1= np.zeros((m2-window,1))\n",
    "        FETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "        \n",
    "        FETVFGL_laplacian_load= np.zeros((m2-window,1))\n",
    "        FETVFGL_l1_load= np.zeros((m2-window,1))\n",
    "        FETVFGL_grouplasso_load= np.zeros((m2-window,1))\n",
    "        \n",
    "        #####SFEs####\n",
    "        SFEEW= np.zeros((m2-window,1))\n",
    "        SFEGL= np.zeros((m2-window,1))\n",
    "        SFEFGL= np.zeros((m2-window,1))        \n",
    "        SFETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "        SFETVFGL_l1= np.zeros((m2-window,1))\n",
    "        SFETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "        \n",
    "        SFETVFGL_laplacian_load= np.zeros((m2-window,1))\n",
    "        SFETVFGL_l1_load= np.zeros((m2-window,1))\n",
    "        SFETVFGL_grouplasso_load= np.zeros((m2-window,1))\n",
    "        \n",
    "        for j in range(0, m2-window):\n",
    "            print('T =', T, 'z =', z, 'out of', reps, 'j =', j, 'out of', m2-window)\n",
    "            ###for h=1\n",
    "            set1 = pd.DataFrame(trying)\n",
    "            set1 = set1.iloc[j:(j+window),:]\n",
    "            ###these r1 and r2 below are for time-varying\n",
    "            err1 = pd.DataFrame(trying[0:T1,])\n",
    "            err2 = pd.DataFrame(trying[T1:,])\n",
    "            #####for time-varying######\n",
    "            forecasters = Yhat.iloc[j:(j+window),:]\n",
    "            truers = y_oos.iloc[j:(j+window),:]\n",
    "            y2 = breaks[j:(j+window),].astype(int)\n",
    "            y2 = y2.astype(int)\n",
    "            \n",
    "            #############################\n",
    "            ###Estimating factors and loadings here\n",
    "            k1=r2\n",
    "            ###for h=1    \n",
    "            ###the part below w/ gamma_opt should be valid for all h's\n",
    "            if (j+window) > T1 and j <= T1:\n",
    "                r1_cv = err1.iloc[j:T1,:]\n",
    "                r2_cv = err2.iloc[0:(j+window-T1),:]\n",
    "                r1_cv = r1_cv.to_numpy()\n",
    "                r2_cv = r2_cv.to_numpy()\n",
    "                gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r2_cv, k)\n",
    "            else:\n",
    "                gamma_opt = 1\n",
    "            print('gamma_opt =', gamma_opt)\n",
    "           \n",
    "            set2 = set1.to_numpy()\n",
    "            set2 = StandardScaler().fit(set2).transform(set2)\n",
    "            ####modified returns for time-varying loadings only!!!\n",
    "            set2_load = set2.copy()\n",
    "            for row in range(set2_load.shape[0]):\n",
    "                for col in range(set2_load.shape[1]):\n",
    "                    if row < (T1-j) and (j+window) > T1 and j <= T1:\n",
    "                        set2_load[row,col]=gamma_opt* set2_load[row,col] \n",
    "\n",
    "            L_load, V_load = np.linalg.eigh(np.dot(set2_load.T, set2_load))\n",
    "            idx_load = L_load.argsort()[::-1]\n",
    "            L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "            V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "            lmb_load = V_load[:, 0:k1]  # kx1\n",
    "      \n",
    "            ###According to Su (2017, JoE) if we obtain Fhat\n",
    "            ###as usual they are only consistent for a rotational version\n",
    "            ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "            Fhat_load = set2@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "            Y_load = set1 - Fhat_load@lmb_load.T ##these are the residuals\n",
    "            \n",
    "            covariate_load = Fhat_load\n",
    "            betas_load = lmb_load.T\n",
    "            \n",
    "            ###################using only post-break data (gamma= 0, assuming that there are at least 30 post-breaks observations)\n",
    "            set2_load_zero = set2.copy()\n",
    "            for row in range(set2_load_zero.shape[0]):\n",
    "                for col in range(set2_load_zero.shape[1]):\n",
    "                    if row < (T1-j) and (j+window-T1) > 30 and j <= T1:\n",
    "                        set2_load_zero[row,col]=gamma_opt_zero* set2_load_zero[row,col] \n",
    "\n",
    "            L_load_zero, V_load_zero = np.linalg.eigh(np.dot(set2_load_zero.T, set2_load_zero))\n",
    "            idx_load_zero = L_load_zero.argsort()[::-1]\n",
    "            L_load_zero = L_load_zero[idx_load_zero]  # eigenvalues, Nx1\n",
    "            V_load_zero = V_load_zero[:, idx_load_zero]  # eigenvectors columns, NxN\n",
    "            lmb_load_zero = V_load_zero[:, 0:k1]  # kx1\n",
    "      \n",
    "            ###According to Su (2017, JoE) if we obtain Fhat\n",
    "            ###as usual they are only consistent for a rotational version\n",
    "            ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "            Fhat_load_zero = set2@lmb_load_zero@np.linalg.inv(lmb_load_zero.T@lmb_load_zero)\n",
    "            Y_load_zero = set1 - Fhat_load_zero@lmb_load_zero.T ##these are the residuals\n",
    "            \n",
    "            covariate_load_zero = Fhat_load_zero\n",
    "            betas_load_zero = lmb_load_zero.T\n",
    "            ###############################################################################\n",
    "            ##########NOT time-varying for h=1 here\n",
    "            ###############################################################################\n",
    "            L, V = np.linalg.eigh(np.dot(set2.T, set2))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k1]  # kx1\n",
    "            Fhat = np.dot(set2, lmb)  # Txr (r=1 for PC1)\n",
    "            Y = set1 - Fhat@lmb.T \n",
    "            Y = Y.to_numpy()\n",
    "            \n",
    "            covariate = Fhat\n",
    "            betas = lmb.T\n",
    "            \n",
    " ###############################################################################################################################                    \n",
    "            ###for h=1\n",
    "            ######## GLASSO###########\n",
    "            GL = GraphicalLassoCV().fit(set1)\n",
    "            theta_GL = GL.get_precision()\n",
    "            \n",
    "            ########Factor GLASSO#######\n",
    "            FGL = GraphicalLassoCV().fit(Y)\n",
    "            theta_FGL_error = FGL.get_precision()\n",
    "            \n",
    "            if k1==1:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            else:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "            ########Time-Varying TVFGL(only precision time-varying i.e. gamma=1)#########   \n",
    "            tuning_laplacian = CVlasso(penalty = '', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)##laplacian (ridge) is defauls and was used at the beginning\n",
    "            tuning_l1 = CVlasso(penalty = 'l1', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            tuning_grouplasso = CVlasso(penalty = 'l2', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)                       \n",
    "            ###laplacian       \n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "            ###l1       \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "            ###group lasso     \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         \n",
    "            print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###############################################################   \n",
    "    ############################################################### \n",
    "    #########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "    ###############################################################\n",
    "            tuning_laplacian_load = CVlasso(penalty = '', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)##laplacian (ridge) is defauls and was used at the beginning\n",
    "            tuning_l1_load = CVlasso(penalty = 'l1', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            tuning_grouplasso_load = CVlasso(penalty = 'l2', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            \n",
    "            print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "            ###laplacian      \n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian_load[0][0], beta = tuning_laplacian_load[1][0]).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "\n",
    "            ###l1  \n",
    "            ##sometimes tuning for l1 won't converge so added these:\n",
    "            if len(tuning_l1_load[0]) == 0:\n",
    "                alpha_l1_load = 0\n",
    "            else:\n",
    "                alpha_l1_load = tuning_l1_load[0][0]\n",
    "\n",
    "            if len(tuning_l1_load[1]) == 0:\n",
    "                beta_l1_load = 0\n",
    "            else:\n",
    "                beta_l1_load = tuning_l1_load[1][0]\n",
    "            ##################################################\n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = alpha_l1_load, beta = beta_l1_load).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "            ###group lasso     \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso_load[0][0], beta = tuning_grouplasso_load[1][0]).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "           ###########Weights###################\n",
    "            weight_EW = np.repeat(1/s,s)\n",
    "            weight_GL = portfolios(set1,theta_GL)[0]\n",
    "            weight_FGL = portfolios(set1,theta_FGL)[0]       \n",
    "            weight_TVFGL_laplacian = portfolios(set1,theta_TVFGL_laplacian )[0]\n",
    "            weight_TVFGL_l1 = portfolios(set1,theta_TVFGL_l1)[0]\n",
    "            weight_TVFGL_grouplasso = portfolios(set1,theta_TVFGL_grouplasso)[0]\n",
    "            weight_TVFGL_laplacian_load = portfolios(set1,theta_TVFGL_laplacian_load )[0]\n",
    "            weight_TVFGL_l1_load = portfolios(set1,theta_TVFGL_l1_load)[0]\n",
    "            weight_TVFGL_grouplasso_load = portfolios(set1,theta_TVFGL_grouplasso_load)[0]\n",
    "            \n",
    "                      \n",
    "            #########################################################################################################\n",
    "           #######MODEL FORECASTS ARE HERE######\n",
    "            FEEW[j]=y_oos.iloc[window +j,:] - weight_EW.T@Yhat.iloc[window +j,:]\n",
    "            FEGL[j]=y_oos.iloc[window +j,:] - weight_GL.T@Yhat.iloc[window +j,:]\n",
    "            FEFGL[j]=y_oos.iloc[window +j,:] - weight_FGL.T@Yhat.iloc[window +j,:]\n",
    "            FETVFGL_laplacian[j]=y_oos.iloc[window +j,:] - weight_TVFGL_laplacian.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_l1[j]=y_oos.iloc[window +j,:] - weight_TVFGL_l1.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_grouplasso[j]=y_oos.iloc[window +j,:] - weight_TVFGL_grouplasso.T@Yhat.iloc[window +j,:] \n",
    "            \n",
    "            FETVFGL_laplacian_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_laplacian_load.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_l1_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_l1_load.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_grouplasso_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_grouplasso_load.T@Yhat.iloc[window +j,:]\n",
    "            \n",
    "            #################SFEs ARE HERE##################\n",
    "            ###for h=1\n",
    "            SFEEW[j]=(FEEW[j])**2\n",
    "            SFEGL[j]=(FEGL[j])**2\n",
    "            SFEFGL[j]=(FEFGL[j])**2\n",
    "            SFETVFGL_laplacian[j]=(FETVFGL_laplacian[j])**2\n",
    "            SFETVFGL_l1[j]=(FETVFGL_l1[j])**2\n",
    "            SFETVFGL_grouplasso[j]=(FETVFGL_grouplasso[j])**2\n",
    "            SFETVFGL_laplacian_load[j]=(FETVFGL_laplacian_load[j])**2\n",
    "            SFETVFGL_l1_load[j]=(FETVFGL_l1_load[j])**2\n",
    "            SFETVFGL_grouplasso_load[j]=(FETVFGL_grouplasso_load[j])**2\n",
    "\n",
    "            ####################   \n",
    "        ###for h=1\n",
    "        MSFE_EW = np.mean(SFEEW)\n",
    "        MSFE_GL = np.mean(SFEGL)\n",
    "        MSFE_FGL = np.mean(SFEFGL)\n",
    "        MSFE_TVFGL_laplacian = np.mean(SFETVFGL_laplacian)\n",
    "        MSFE_TVFGL_l1 = np.mean(SFETVFGL_l1)\n",
    "        MSFE_TVFGL_grouplasso = np.mean(SFETVFGL_grouplasso)\n",
    "        MSFE_TVFGL_laplacian_load = np.mean(SFETVFGL_laplacian_load)\n",
    "        MSFE_TVFGL_l1_load = np.mean(SFETVFGL_l1_load)\n",
    "        MSFE_TVFGL_grouplasso_load = np.mean(SFETVFGL_grouplasso_load)\n",
    "       \n",
    "        print('MSFE_EW =', MSFE_EW, 'MSFE_GL =', MSFE_GL, 'MSFE_FGL =', MSFE_FGL,'MSFE_TVFGL_laplacian =', MSFE_TVFGL_laplacian,\n",
    "             'MSFE_TVFGL_l1 =', MSFE_TVFGL_l1, 'MSFE_TVFGL_grouplasso =', MSFE_TVFGL_grouplasso,\n",
    "             'MSFE_TVFGL_laplacian_load =', MSFE_TVFGL_laplacian_load,\n",
    "             'MSFE_TVFGL_l1_load =', MSFE_TVFGL_l1_load, 'MSFE_TVFGL_grouplasso_load =', MSFE_TVFGL_grouplasso_load)\n",
    "\n",
    "        ##########################################################\n",
    "        ###for h=1\n",
    "        error_EW[z] = MSFE_EW\n",
    "        error_GL[z] = MSFE_GL\n",
    "        error_FGL[z] = MSFE_FGL\n",
    "        error_TVFGL_laplacian[z] = MSFE_TVFGL_laplacian\n",
    "        error_TVFGL_l1[z] = MSFE_TVFGL_l1\n",
    "        error_TVFGL_grouplasso[z] = MSFE_TVFGL_grouplasso\n",
    "        \n",
    "        error_TVFGL_laplacian_load[z] = MSFE_TVFGL_laplacian_load\n",
    "        error_TVFGL_l1_load[z] = MSFE_TVFGL_l1_load\n",
    "        error_TVFGL_grouplasso_load[z] = MSFE_TVFGL_grouplasso_load\n",
    "\n",
    "       \n",
    "    #####################  \n",
    "    \n",
    "    ###for h=1\n",
    "    cum_EW[count] = np.mean(error_EW)\n",
    "    cum_GL[count] = np.mean(error_GL)\n",
    "    cum_FGL[count] = np.mean(error_FGL)\n",
    "    cum_TVFGL_laplacian[count] = np.mean(error_TVFGL_laplacian)\n",
    "    cum_TVFGL_l1[count] = np.mean(error_TVFGL_l1)\n",
    "    cum_TVFGL_grouplasso[count] = np.mean(error_TVFGL_grouplasso)\n",
    "    \n",
    "    cum_TVFGL_laplacian_load[count] = np.mean(error_TVFGL_laplacian_load)\n",
    "    cum_TVFGL_l1_load[count] = np.mean(error_TVFGL_l1_load)\n",
    "    cum_TVFGL_grouplasso_load[count] = np.mean(error_TVFGL_grouplasso_load)\n",
    "    \n",
    "       \n",
    "cum_h1 = np.concatenate((cum_EW,cum_GL,cum_FGL,cum_TVFGL_laplacian, cum_TVFGL_l1,cum_TVFGL_grouplasso,cum_TVFGL_laplacian_load,\n",
    "                         cum_TVFGL_l1_load,cum_TVFGL_grouplasso_load), axis=1)\n",
    "    \n",
    "# savetxt('cum_h1_smallbreak_c1is075_cont.csv', cum_h1, delimiter=',') #before IJF revision\n",
    "savetxt('cum_h1_rhois09_c1is075_cont.csv', cum_h1, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733876d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Appendix Figure E4: NO BREAK##################\n",
    "count=-1\n",
    "for T in sample_size:\n",
    "    print('T =', T)\n",
    "    count = count + 1\n",
    "    m2 = int(round(2*T/3)) #Forecasting observations\n",
    "    m1=T-m2 \n",
    "    window = int(round(m2/2))\n",
    "#     T1 = m1 + int(round(window/2))\n",
    "    ###for h=1\n",
    "    error_EW =  np.zeros((reps+1,1))\n",
    "    error_GL =  np.zeros((reps+1,1))\n",
    "    error_FGL =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_laplacian =  np.zeros((reps+1,1))\n",
    "#     error_TVFGL_l1 =  np.zeros((reps+1,1))\n",
    "#     error_TVFGL_grouplasso =  np.zeros((reps+1,1))\n",
    "#     error_TVFGL_max =  np.zeros((reps+1,1))\n",
    "    \n",
    "    \n",
    "    ###Incorporating break in theta through break in c2####\n",
    "   \n",
    "    #######################################################\n",
    "    for z in range(reps+1):      \n",
    "       ########No break in c2###############################\n",
    "        e = np.random.randn(T,1)      \n",
    "        theta = np.zeros((T,1))  \n",
    "        breaks_full = np.zeros((T,1))\n",
    "        for w in range(T):\n",
    "            theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "        \n",
    "        #######################################################\n",
    "        y1 = np.zeros((T,1)) \n",
    "        for g in range(T):\n",
    "            y1[g] = theta[0:(g+1)].T@np.flip(e[0:(g+1)])\n",
    "                 \n",
    "        ###################################################\n",
    "        #creating Toeplitz matrix and its Cholesky decomposition\n",
    "        ####For regime 1\n",
    "        O = np.zeros((N, N))\n",
    "        np.fill_diagonal(O, np.ones(N))     \n",
    "        for h in range(1,N):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, N-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, N-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "        ######################################\n",
    "        F = np.zeros((T,r))\n",
    "        F[0,] = sigmaF*np.random.randn(1,r)\n",
    "        v=np.random.randn(T,r)\n",
    "        for j in range(0,r):\n",
    "            for t in range(1,T):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "            \n",
    "        ##################################################        \n",
    "        ###############NO BREAKS##########################\n",
    "        X = F@Lambda[0:r,] + sigmaX*np.random.randn(T,N)\n",
    "        ##################################################\n",
    "        alpha = np.random.randn(r,1)+1\n",
    "        y2 = np.zeros((T,1))\n",
    "        y2[1:T]= F[0:(T-1),]@alpha +0*sigmaY*np.random.randn((T-1),1)\n",
    "        y=y1+y2\n",
    "        \n",
    "        Yhat = np.zeros((m2,s))\n",
    "       \n",
    "        \n",
    "        for col in range(0,p1):  # Col=1 when no lags\n",
    "            for k in range(0,r2+1): # Number of factors\n",
    "                for row in range(0,m2):\n",
    "                    xx = MakeAR(y[(row):(m1-1+row)], (col-1))[0]\n",
    "                    if col==0 and k!=0:\n",
    "                        xx = np.ones(((m1-1),1))\n",
    "\n",
    "                    if k==0:\n",
    "                        xx=xx\n",
    "                        coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1+row)]\n",
    "                    else:\n",
    "                        data = X[(row):(m1-1+row),]\n",
    "                        L, V = np.linalg.eigh(np.dot(data.T, data))\n",
    "                        idx = L.argsort()[::-1]\n",
    "                        L = L[idx]  # eigenvalues, Nx1\n",
    "                        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "                        lmb = V[:, 0:k]  # kx1\n",
    "                        Fhat = np.dot(data, lmb)\n",
    "                        if col==0:\n",
    "                            Fhat = Fhat[(col):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "                        else:\n",
    "                            Fhat = Fhat[(col-1):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "\n",
    "                        if col==0:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col+1):(m1 +row)]\n",
    "                        else:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1 +row)]   \n",
    "                    if col == 0: # 0 lags \n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = coef #if col=1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]), Fhat[Fhat.shape[0]-1,]], axis=0)@coef #if col=0 and k>0          \n",
    "                    else:         # >=1 lags\n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)]))], axis=0)@coef                    \n",
    "                            # Yhat[row,((r2+1)*(col)+k)] = np.array([1,np.flip(y[(m1 +row-col+1):(m1 +row+1)])])@coef #if col>1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])), Fhat[Fhat.shape[0]-1,]], axis=0)@coef \n",
    "                            # USED TO BE np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])) PLUS instead of MINUS for some reason\n",
    " ##################################################################################333\n",
    "        \n",
    "        forERR=np.full((Yhat.shape[0], Yhat.shape[1]), y[(m1):T]) - Yhat\n",
    "               \n",
    "        y =  pd.DataFrame(y)\n",
    "        ###for h=1\n",
    "        trying = forERR\n",
    "        Yhat = pd.DataFrame(Yhat)\n",
    "        forERR = pd.DataFrame(forERR)\n",
    "        y_oos = pd.DataFrame(y[(m1):T])\n",
    "        breaks = breaks_full[(m1):T]\n",
    "        \n",
    "        ###############################################################\n",
    "        ####FORECAST ERRORS MATRICES####\n",
    "        ###for h=1\n",
    "        FEEW= np.zeros((m2-window,1))\n",
    "        FEGL= np.zeros((m2-window,1))\n",
    "        FEFGL= np.zeros((m2-window,1))\n",
    "        FETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "#         FETVFGL_l1= np.zeros((m2-window,1))\n",
    "#         FETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "#         FETVFGL_max= np.zeros((m2-window,1))\n",
    "        \n",
    "        #####SFEs####\n",
    "        SFEEW= np.zeros((m2-window,1))\n",
    "        SFEGL= np.zeros((m2-window,1))\n",
    "        SFEFGL= np.zeros((m2-window,1))        \n",
    "        SFETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "#         SFETVFGL_l1= np.zeros((m2-window,1))\n",
    "#         SFETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "#         SFETVFGL_max= np.zeros((m2-window,1))\n",
    "        \n",
    "        for j in range(0, m2-window):  \n",
    "            print('T =', T, 'z =', z, 'j =', j)\n",
    "            ###for h=1\n",
    "            set1 = pd.DataFrame(trying)\n",
    "            set1 = set1.iloc[j:(j+window),:]\n",
    "    \n",
    "            #####for time-varying######\n",
    "            forecasters = Yhat.iloc[j:(j+window),:]\n",
    "            truers = y_oos.iloc[j:(j+window),:]\n",
    "            y2 = breaks[j:(j+window),].astype(int)\n",
    "            y2 = y2.astype(int)\n",
    "            \n",
    " \n",
    "            #############################\n",
    "            ###Estimating factors and loadings here\n",
    "            k1=r2\n",
    "            set2 = set1.to_numpy()\n",
    "            set2 = StandardScaler().fit(set2).transform(set2)\n",
    "            ###############################################################################\n",
    "            ##########NOT time-varying for h=1 here\n",
    "            ###############################################################################\n",
    "            L, V = np.linalg.eigh(np.dot(set2.T, set2))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k1]  # kx1\n",
    "            Fhat = np.dot(set2, lmb)  # Txr (r=1 for PC1)\n",
    "            Y = set1 - Fhat@lmb.T \n",
    "            Y = Y.to_numpy()\n",
    "            \n",
    "            covariate = Fhat\n",
    "            betas = lmb.T\n",
    " ###############################################################################################################################                    \n",
    "            ###for h=1\n",
    "            ######## GLASSO###########\n",
    "            GL = GraphicalLassoCV().fit(set1)\n",
    "            theta_GL = GL.get_precision()\n",
    "            \n",
    "            ########Factor GLASSO#######\n",
    "            FGL = GraphicalLassoCV().fit(Y)\n",
    "            theta_FGL_error = FGL.get_precision()\n",
    "            \n",
    "            if k1==1:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            else:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "            ########Time-Varying TVFGL(only precision time-varying i.e. gamma=1)#########   \n",
    "            tuning_laplacian = CVlasso(penalty = '', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)##laplacian (ridge) is defauls and was used at the beginning\n",
    "#             tuning_l1 = CVlasso(penalty = 'l1', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)\n",
    "#             tuning_grouplasso = CVlasso(penalty = 'l2', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)\n",
    "#             tuning_max = CVlasso(penalty = 'linf', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)\n",
    "      \n",
    "            print(tuning_laplacian.T)           \n",
    "#             tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning[0][0], beta = tuning[1][0]).fit(Y, y2)\n",
    "#             if k==1:\n",
    "#                 theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#             else:\n",
    "#                 theta_TVFGL=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "           \n",
    "            ###laplacian       \n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "#             ###l1       \n",
    "#             tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "#             if k1==1:\n",
    "#                 theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#             else:\n",
    "#                 theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "#          ###############################################################   \n",
    "#             ###group lasso     \n",
    "#             tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "#             if k1==1:\n",
    "#                 theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#             else:\n",
    "#                 theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "#          ###############################################################   \n",
    "#             ###max    \n",
    "#             tvfgl = TimeGraphicalLasso(psi = 'linf', max_iter=100, alpha = tuning_max[0][0], beta = tuning_max[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "#             if k1==1:\n",
    "#                 theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "#             else:\n",
    "#                 theta_TVFGL_max=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "#          ############################################################### \n",
    "        ###############################################################\n",
    "\n",
    "           ###########Weights###################\n",
    "            weight_EW = np.repeat(1/s,s)\n",
    "            weight_GL = portfolios(set1,theta_GL)[0]\n",
    "            weight_FGL = portfolios(set1,theta_FGL)[0]       \n",
    "            weight_TVFGL_laplacian = portfolios(set1,theta_TVFGL_laplacian )[0]\n",
    "#             weight_TVFGL_l1 = portfolios(set1,theta_TVFGL_l1)[0]\n",
    "#             weight_TVFGL_grouplasso = portfolios(set1,theta_TVFGL_grouplasso)[0]\n",
    "#             weight_TVFGL_max = portfolios(set1,theta_TVFGL_max)[0]\n",
    "            \n",
    "                      \n",
    "            #########################################################################################################\n",
    "           #######MODEL FORECASTS ARE HERE######\n",
    "            FEEW[j]=y_oos.iloc[window +j,:] - weight_EW.T@Yhat.iloc[window +j,:]\n",
    "            FEGL[j]=y_oos.iloc[window +j,:] - weight_GL.T@Yhat.iloc[window +j,:]\n",
    "            FEFGL[j]=y_oos.iloc[window +j,:] - weight_FGL.T@Yhat.iloc[window +j,:]\n",
    "            FETVFGL_laplacian[j]=y_oos.iloc[window +j,:] - weight_TVFGL_laplacian.T@Yhat.iloc[window +j,:] \n",
    "#             FETVFGL_l1[j]=y_oos.iloc[window +j,:] - weight_TVFGL_l1.T@Yhat.iloc[window +j,:] \n",
    "#             FETVFGL_grouplasso[j]=y_oos.iloc[window +j,:] - weight_TVFGL_grouplasso.T@Yhat.iloc[window +j,:] \n",
    "#             FETVFGL_max[j]=y_oos.iloc[window +j,:] - weight_TVFGL_max.T@Yhat.iloc[window +j,:] \n",
    "            \n",
    "            #################SFEs ARE HERE##################\n",
    "            ###for h=1\n",
    "            SFEEW[j]=(FEEW[j])**2\n",
    "            SFEGL[j]=(FEGL[j])**2\n",
    "            SFEFGL[j]=(FEFGL[j])**2\n",
    "            SFETVFGL_laplacian[j]=(FETVFGL_laplacian[j])**2\n",
    "#             SFETVFGL_l1[j]=(FETVFGL_l1[j])**2\n",
    "#             SFETVFGL_grouplasso[j]=(FETVFGL_grouplasso[j])**2\n",
    "#             SFETVFGL_max[j]=(FETVFGL_max[j])**2\n",
    "\n",
    "            ####################   \n",
    "        ###for h=1\n",
    "        MSFE_EW = np.mean(SFEEW)\n",
    "        MSFE_GL = np.mean(SFEGL)\n",
    "        MSFE_FGL = np.mean(SFEFGL)\n",
    "        MSFE_TVFGL_laplacian = np.mean(SFETVFGL_laplacian)\n",
    "#         MSFE_TVFGL_l1 = np.mean(SFETVFGL_l1)\n",
    "#         MSFE_TVFGL_grouplasso = np.mean(SFETVFGL_grouplasso)\n",
    "#         MSFE_TVFGL_max = np.mean(SFETVFGL_max)\n",
    "\n",
    "       \n",
    "        print('MSFE_EW =', MSFE_EW, 'MSFE_GL =', MSFE_GL, 'MSFE_FGL =', MSFE_FGL,'MSFE_TVFGL_laplacian =', MSFE_TVFGL_laplacian)\n",
    "\n",
    "        ##########################################################\n",
    "        ###for h=1\n",
    "        error_EW[z] = MSFE_EW\n",
    "        error_GL[z] = MSFE_GL\n",
    "        error_FGL[z] = MSFE_FGL\n",
    "        error_TVFGL_laplacian[z] = MSFE_TVFGL_laplacian\n",
    "#         error_TVFGL_l1[z] = MSFE_TVFGL_l1\n",
    "#         error_TVFGL_grouplasso[z] = MSFE_TVFGL_grouplasso\n",
    "#         error_TVFGL_max[z] = MSFE_TVFGL_max\n",
    "       \n",
    "    #####################  \n",
    "    \n",
    "    ###for h=1\n",
    "    cum_EW[count] = np.mean(error_EW)\n",
    "    cum_GL[count] = np.mean(error_GL)\n",
    "    cum_FGL[count] = np.mean(error_FGL)\n",
    "    cum_TVFGL_laplacian[count] = np.mean(error_TVFGL_laplacian)\n",
    "#     cum_TVFGL_l1[count] = np.mean(error_TVFGL_l1)\n",
    "#     cum_TVFGL_grouplasso[count] = np.mean(error_TVFGL_grouplasso)\n",
    "#     cum_TVFGL_max[count] = np.mean(error_TVFGL_max)\n",
    "    \n",
    "       \n",
    "cum_h1 = np.concatenate((cum_EW,cum_GL,cum_FGL,cum_TVFGL_laplacian), axis=1)\n",
    "    \n",
    "savetxt('cum_h1_nobreak_c1is0.csv', cum_h1, delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeafc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Appendix Figure E7: TWO BREAKS IN BOTH PRECISION AND LOADINGS##################\n",
    "########PARAMETERS################################################\n",
    "gamma_opt_zero = 0\n",
    "gamma_set = np.arange(0,1.05,0.05)  \n",
    "alpha_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "beta_set = np.array([0, 0.25, 0.5, 1, 10, 30]).astype(float)\n",
    "##################################################################\n",
    "c1 = 0.75\n",
    "c2 = 0.9\n",
    "r = 5 #Factors in DGP\n",
    "sigmaF = 1\n",
    "sigmaX = 1\n",
    "sigmaY = sigmaX\n",
    "p1 = 8 #Number of AR(l) models\n",
    "r2 = 3 #Estimated factors. Used to be 2\n",
    "r3 =5 #Factors in modeling Forecast Errors\n",
    "s = p1*(1+r2) #Forecasters\n",
    "rho=0.2 #in regime 1\n",
    "rho2 = 0.8 #in regime 2\n",
    "phi = 0.8\n",
    "N=100\n",
    "reps = 500\n",
    "#####################################################################\n",
    "sample_size=range(400,1250,200)\n",
    "\n",
    "#####PLACEHOLDERS\n",
    "##########Matrices Placeholders######\n",
    "###for h=1\n",
    "cum_GL = np.zeros((len(sample_size),1))\n",
    "cum_FGL = np.zeros((len(sample_size),1))\n",
    "cum_EW = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_laplacian = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_l1 = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_grouplasso = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_laplacian_load = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_l1_load = np.zeros((len(sample_size),1))\n",
    "cum_TVFGL_grouplasso_load = np.zeros((len(sample_size),1))\n",
    "count=-1\n",
    "for T in sample_size:\n",
    "    count = count + 1\n",
    "    m2 = int(round(2*T/3)) #Forecasting observations\n",
    "    m1=T-m2 \n",
    "    window = int(round(3*m2/4))\n",
    "    T1 = m1 + int(round(window/4))\n",
    "    T2 = m1 + int(round(3*window/4))\n",
    "    \n",
    "    ###for h=1\n",
    "    error_EW =  np.zeros((reps+1,1))\n",
    "    error_GL =  np.zeros((reps+1,1))\n",
    "    error_FGL =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_laplacian =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_l1 =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_grouplasso =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_laplacian_load =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_l1_load =  np.zeros((reps+1,1))\n",
    "    error_TVFGL_grouplasso_load =  np.zeros((reps+1,1))\n",
    "    \n",
    "    \n",
    "    ###Incorporating break in theta through break in c2####\n",
    "   \n",
    "    #######################################################\n",
    "    for z in range(reps+1):  \n",
    "       ########No break in c2###############################\n",
    "        e = np.random.randn(T,1)      \n",
    "        theta = np.zeros((T,1))  \n",
    "        breaks_full = np.zeros((T,1))\n",
    "        for w in range(T):\n",
    "            if w <= T1:\n",
    "                c2 = 0.3\n",
    "                theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "                breaks_full[w,]=0\n",
    "            if T1 < w <= T2:\n",
    "                c2 = 0.6\n",
    "                theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "                breaks_full[w,]=1\n",
    "            if w > T2:\n",
    "                c2 = 0.9\n",
    "                theta[w] = ((w+1)**c1)*(c2**(w))\n",
    "                breaks_full[w,]=2\n",
    "                \n",
    "                \n",
    "        breaks_full = breaks_full.astype(int)\n",
    "        breaks_full = np.ravel(breaks_full)\n",
    "        \n",
    "\n",
    "        #######################################################\n",
    "        y1 = np.zeros((T,1)) \n",
    "        for g in range(T):\n",
    "            y1[g] = theta[0:(g+1)].T@np.flip(e[0:(g+1)])\n",
    "         \n",
    "        \n",
    "        ###################################################\n",
    "        #creating Toeplitz matrix and its Cholesky decomposition\n",
    "        ####For regime 1\n",
    "        O = np.zeros((N, N))\n",
    "        np.fill_diagonal(O, np.ones(N))     \n",
    "        for h in range(1,N):\n",
    "            np.fill_diagonal(O[h:], rho**np.repeat(h, N-h))\n",
    "            np.fill_diagonal(O[:,h:], rho**np.repeat(h, N-h))\n",
    "        \n",
    "        Lambda = cholesky(O, lower=False)\n",
    "        \n",
    "        ######################################\n",
    "        F = np.zeros((T,r))\n",
    "        F[0,] = sigmaF*np.random.randn(1,r)\n",
    "        v=np.random.randn(T,r)\n",
    "        for j in range(0,r):\n",
    "            for t in range(1,T):\n",
    "                F[t,j] = phi*F[t-1,j]+sigmaF*v[t,j]\n",
    "                \n",
    "        ##################################################        \n",
    "        ###############NO BREAKS##########################\n",
    "        X = F@Lambda[0:r,] + sigmaX*np.random.randn(T,N)\n",
    "        ##################################################\n",
    "        alpha = np.random.randn(r,1)+1\n",
    "        y2 = np.zeros((T,1))\n",
    "        y2[1:T]= F[0:(T-1),]@alpha +0*sigmaY*np.random.randn((T-1),1)\n",
    "        y=y1+y2\n",
    "        \n",
    "        Yhat = np.zeros((m2,s))\n",
    "       \n",
    "        \n",
    "        for col in range(0,p1):  # Col=1 when no lags\n",
    "            for k in range(0,r2+1): # Number of factors\n",
    "                for row in range(0,m2):\n",
    "                    xx = MakeAR(y[(row):(m1-1+row)], (col-1))[0]\n",
    "                    if col==0 and k!=0:\n",
    "                        xx = np.ones(((m1-1),1))\n",
    "\n",
    "                    if k==0:\n",
    "                        xx=xx\n",
    "                        coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1+row)]\n",
    "                    else:\n",
    "                        data = X[(row):(m1-1+row),]\n",
    "                        L, V = np.linalg.eigh(np.dot(data.T, data))\n",
    "                        idx = L.argsort()[::-1]\n",
    "                        L = L[idx]  # eigenvalues, Nx1\n",
    "                        V = V[:, idx]  # eigenvectors columns, NxN\n",
    "                        lmb = V[:, 0:k]  # kx1\n",
    "                        Fhat = np.dot(data, lmb)\n",
    "                        if col==0:\n",
    "                            Fhat = Fhat[(col):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "                        else:\n",
    "                            Fhat = Fhat[(col-1):(m1 -1),]\n",
    "                            xx = np.concatenate([xx,Fhat], axis=1)\n",
    "\n",
    "                        if col==0:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col+1):(m1 +row)]\n",
    "                        else:\n",
    "                            coef = np.linalg.inv(xx.T@xx)@xx.T@y[(row+col):(m1 +row)]   \n",
    "                    if col == 0: # 0 lags \n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = coef #if col=1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]), Fhat[Fhat.shape[0]-1,]], axis=0)@coef #if col=0 and k>0          \n",
    "                    else:         # >=1 lags\n",
    "                        if k==0:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)]))], axis=0)@coef                    \n",
    "                            # Yhat[row,((r2+1)*(col)+k)] = np.array([1,np.flip(y[(m1 +row-col+1):(m1 +row+1)])])@coef #if col>1 and k=0\n",
    "                        else:\n",
    "                            Yhat[row,((r2+1)*(col)+k)] = np.concatenate([np.array([1]),np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])), Fhat[Fhat.shape[0]-1,]], axis=0)@coef \n",
    "                            # USED TO BE np.ravel(np.flip(y[(m1 +row-col+1):(m1 +row+1)])) PLUS instead of MINUS for some reason\n",
    " ##################################################################################333\n",
    "        \n",
    "        forERR=np.full((Yhat.shape[0], Yhat.shape[1]), y[(m1):T]) - Yhat\n",
    "               \n",
    "        y =  pd.DataFrame(y)\n",
    "        ###for h=1\n",
    "        trying = forERR\n",
    "        Yhat = pd.DataFrame(Yhat)\n",
    "        forERR = pd.DataFrame(forERR)\n",
    "        y_oos = pd.DataFrame(y[(m1):T])\n",
    "        breaks = breaks_full[(m1):T]\n",
    "        \n",
    "        ###############################################################\n",
    "        ####FORECAST ERRORS MATRICES####\n",
    "        ###for h=1\n",
    "        FEEW= np.zeros((m2-window,1))\n",
    "        FEGL= np.zeros((m2-window,1))\n",
    "        FEFGL= np.zeros((m2-window,1))\n",
    "        FETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "        FETVFGL_l1= np.zeros((m2-window,1))\n",
    "        FETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "        \n",
    "        FETVFGL_laplacian_load= np.zeros((m2-window,1))\n",
    "        FETVFGL_l1_load= np.zeros((m2-window,1))\n",
    "        FETVFGL_grouplasso_load= np.zeros((m2-window,1))\n",
    "        \n",
    "        #####SFEs####\n",
    "        SFEEW= np.zeros((m2-window,1))\n",
    "        SFEGL= np.zeros((m2-window,1))\n",
    "        SFEFGL= np.zeros((m2-window,1))        \n",
    "        SFETVFGL_laplacian= np.zeros((m2-window,1))\n",
    "        SFETVFGL_l1= np.zeros((m2-window,1))\n",
    "        SFETVFGL_grouplasso= np.zeros((m2-window,1))\n",
    "        \n",
    "        SFETVFGL_laplacian_load= np.zeros((m2-window,1))\n",
    "        SFETVFGL_l1_load= np.zeros((m2-window,1))\n",
    "        SFETVFGL_grouplasso_load= np.zeros((m2-window,1))\n",
    "        \n",
    "        for j in range(0, m2-window):\n",
    "            print('T =', T, 'z =', z, 'out of', reps, 'j =', j, 'out of', m2-window)\n",
    "            ###for h=1\n",
    "            set1 = pd.DataFrame(trying)\n",
    "            set1 = set1.iloc[j:(j+window),:]\n",
    "            ###these r1 and r2 below are for time-varying\n",
    "            err1 = pd.DataFrame(trying[0:T1,])\n",
    "            err11 = pd.DataFrame(trying[T1:,])\n",
    "            err2 = pd.DataFrame(trying[0:T2,])\n",
    "            err22 = pd.DataFrame(trying[T2:,])\n",
    "\n",
    "            #####for time-varying######\n",
    "            forecasters = Yhat.iloc[j:(j+window),:]\n",
    "            truers = y_oos.iloc[j:(j+window),:]\n",
    "            y2 = breaks[j:(j+window),].astype(int)\n",
    "            y2 = y2.astype(int)\n",
    "            \n",
    "            #############################\n",
    "            ###Estimating factors and loadings here\n",
    "            k1=r2\n",
    "            ###for h=1    \n",
    "            ###the part below w/ gamma_opt should be valid for all h's\n",
    "            if T1 < (j+window) < T2 and j < T1:\n",
    "                r1_cv = err1.iloc[j:T1,:]\n",
    "                r11_cv = err11.iloc[0:(j+window-T1),:]\n",
    "                r1_cv = r1_cv.to_numpy()\n",
    "                r11_cv = r11_cv.to_numpy()\n",
    "                gamma_opt = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k1)\n",
    "            elif (j+window) > T2 and T1 < j < T2:\n",
    "                r2_cv = err2.iloc[j:T2,:]\n",
    "                r22_cv = err22.iloc[0:(j+window-T2),:]\n",
    "                r2_cv = r2_cv.to_numpy()\n",
    "                r22_cv = r22_cv.to_numpy()\n",
    "                gamma_opt = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k1)\n",
    "            elif (j+window) > T2 and j < T1:\n",
    "                r1_cv = err1.iloc[j:T1,:]\n",
    "                r11_cv = err11.iloc[0:(j+window-T1),:]\n",
    "                r1_cv = r1_cv.to_numpy()\n",
    "                r11_cv = r11_cv.to_numpy()\n",
    "                gamma_opt1 = CV_gamma(gamma_set,set1, r1_cv, r11_cv, k1)\n",
    "                r2_cv = err2.iloc[j:T2,:]\n",
    "                r22_cv = err22.iloc[0:(j+window-T2),:]\n",
    "                r2_cv = r2_cv.to_numpy()\n",
    "                r22_cv = r22_cv.to_numpy()\n",
    "                gamma_opt2 = CV_gamma(gamma_set,set1, r2_cv, r22_cv, k1)\n",
    "            else:\n",
    "                gamma_opt = 1\n",
    "            \n",
    "            print('gamma_opt =', gamma_opt)\n",
    "           \n",
    "            set2 = set1.to_numpy()\n",
    "            set2 = StandardScaler().fit(set2).transform(set2)\n",
    "            ####modified returns for time-varying loadings only!!!\n",
    "            set2_load = set2.copy()\n",
    "            for row in range(set2_load.shape[0]):\n",
    "                for col in range(set2_load.shape[1]):\n",
    "                    if row < (T1-j) and T1 < (j+window) < T2 and j < T1:\n",
    "                        set2_load[row,col]=gamma_opt* set2_load[row,col] \n",
    "                    elif row < (T2-j) and (j+window) > T2 and T1 < j < T2:\n",
    "                        set2_load[row,col]=gamma_opt* set2_load[row,col] \n",
    "                    elif (j+window) > T2 and j < T1:\n",
    "                        if row < (T1-j):\n",
    "                            set2_load[row,col]=gamma_opt1* set2_load[row,col] \n",
    "                        elif (T1-j) < row < (T2-j):\n",
    "                            set2_load[row,col]=gamma_opt2* set2_load[row,col] \n",
    "            \n",
    "\n",
    "            L_load, V_load = np.linalg.eigh(np.dot(set2_load.T, set2_load))\n",
    "            idx_load = L_load.argsort()[::-1]\n",
    "            L_load = L_load[idx_load]  # eigenvalues, Nx1\n",
    "            V_load = V_load[:, idx_load]  # eigenvectors columns, NxN\n",
    "            lmb_load = V_load[:, 0:k1]  # kx1\n",
    "      \n",
    "            ###According to Su (2017, JoE) if we obtain Fhat\n",
    "            ###as usual they are only consistent for a rotational version\n",
    "            ###hence, to get a consistent estimator use a two-stage procedure (OLS)\n",
    "            Fhat_load = set2@lmb_load@np.linalg.inv(lmb_load.T@lmb_load)\n",
    "            Y_load = set1 - Fhat_load@lmb_load.T ##these are the residuals\n",
    "            \n",
    "            covariate_load = Fhat_load\n",
    "            betas_load = lmb_load.T\n",
    "            \n",
    "            \n",
    "            ###############################################################################\n",
    "            ##########NOT time-varying for h=1 here\n",
    "            ###############################################################################\n",
    "            L, V = np.linalg.eigh(np.dot(set2.T, set2))\n",
    "            idx = L.argsort()[::-1]\n",
    "            L = L[idx]  # eigenvalues, Nx1\n",
    "            V = V[:, idx]  # eigenvectors columns, NxN\n",
    "            lmb = V[:, 0:k1]  # kx1\n",
    "            Fhat = np.dot(set2, lmb)  # Txr (r=1 for PC1)\n",
    "            Y = set1 - Fhat@lmb.T \n",
    "            Y = Y.to_numpy()\n",
    "            \n",
    "            covariate = Fhat\n",
    "            betas = lmb.T\n",
    "            \n",
    " ###############################################################################################################################                    \n",
    "            ###for h=1\n",
    "            ######## GLASSO###########\n",
    "            GL = GraphicalLassoCV().fit(set1)\n",
    "            theta_GL = GL.get_precision()\n",
    "            \n",
    "            ########Factor GLASSO#######\n",
    "            FGL = GraphicalLassoCV().fit(Y)\n",
    "            theta_FGL_error = FGL.get_precision()\n",
    "            \n",
    "            if k1==1:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            else:\n",
    "                theta_FGL = theta_FGL_error - theta_FGL_error@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@theta_FGL_error@betas.T)@betas@theta_FGL_error\n",
    "            \n",
    "            ########Time-Varying TVFGL(only precision time-varying i.e. gamma=1)#########   \n",
    "            tuning_laplacian = CVlasso(penalty = '', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)##laplacian (ridge) is defauls and was used at the beginning\n",
    "            tuning_l1 = CVlasso(penalty = 'l1', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            tuning_grouplasso = CVlasso(penalty = 'l2', X=set1,Y=Y,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat, lmb=lmb, alpha_set=alpha_set, beta_set=beta_set)                       \n",
    "            ###laplacian       \n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian[0][0], beta = tuning_laplacian[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_laplacian=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "     \n",
    "            ###l1       \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = tuning_l1[0][0], beta = tuning_l1[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_l1=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "            ###group lasso     \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso[0][0], beta = tuning_grouplasso[1][0]).fit(Y, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( (np.cov(covariate, y=None, rowvar=False))**(-1)+ betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_grouplasso=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T@np.linalg.inv( np.linalg.inv(np.cov(covariate, y=None, rowvar=False))+betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas.T)@betas@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         \n",
    "            print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "        ###############################################################   \n",
    "    ############################################################### \n",
    "    #########Time-Varying TVFGL(BOTH precision and loadings time-varying)#########        \n",
    "    ###############################################################\n",
    "            tuning_laplacian_load = CVlasso(penalty = '', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)##laplacian (ridge) is defauls and was used at the beginning\n",
    "            tuning_l1_load = CVlasso(penalty = 'l1', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            tuning_grouplasso_load = CVlasso(penalty = 'l2', X=set1,Y=Y_load,y2=y2,k1=k1, q=int(round(window/3)), window=window, forecasters = forecasters, truers = truers, Fhat = Fhat_load, lmb=lmb_load, alpha_set=alpha_set, beta_set=beta_set)\n",
    "            \n",
    "            print('laplacian =', tuning_laplacian.T, 'l1 =', tuning_l1.T,'grouplasso =', tuning_grouplasso.T)\n",
    "            ###laplacian      \n",
    "            tvfgl = TimeGraphicalLasso(max_iter=100, alpha = tuning_laplacian_load[0][0], beta = tuning_laplacian_load[1][0]).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_laplacian_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "\n",
    "            ###l1  \n",
    "            ##sometimes tuning for l1 won't converge so added these:\n",
    "            if len(tuning_l1_load[0]) == 0:\n",
    "                alpha_l1_load = 0\n",
    "            else:\n",
    "                alpha_l1_load = tuning_l1_load[0][0]\n",
    "\n",
    "            if len(tuning_l1_load[1]) == 0:\n",
    "                beta_l1_load = 0\n",
    "            else:\n",
    "                beta_l1_load = tuning_l1_load[1][0]\n",
    "            ##################################################\n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l1', max_iter=100, alpha = alpha_l1_load, beta = beta_l1_load).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_l1_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "            ###group lasso     \n",
    "            tvfgl = TimeGraphicalLasso(psi = 'l2', max_iter=100, alpha = tuning_grouplasso_load[0][0], beta = tuning_grouplasso_load[1][0]).fit(Y_load, y2)  #{psi = 'laplacian', 'l1', 'l2', 'linf', 'node'}, default 'laplacian'\n",
    "            if k1==1:\n",
    "                theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( (np.cov(covariate_load, y=None, rowvar=False))**(-1)+ betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]  \n",
    "            else:\n",
    "                theta_TVFGL_grouplasso_load=tvfgl.precision_[tvfgl.precision_.shape[0]-1] - tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T@np.linalg.inv( np.linalg.inv(np.cov(covariate_load, y=None, rowvar=False))+betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]@betas_load.T)@betas_load@tvfgl.precision_[tvfgl.precision_.shape[0]-1]\n",
    "         ###############################################################   \n",
    "           ###########Weights###################\n",
    "            weight_EW = np.repeat(1/s,s)\n",
    "            weight_GL = portfolios(set1,theta_GL)[0]\n",
    "            weight_FGL = portfolios(set1,theta_FGL)[0]       \n",
    "            weight_TVFGL_laplacian = portfolios(set1,theta_TVFGL_laplacian )[0]\n",
    "            weight_TVFGL_l1 = portfolios(set1,theta_TVFGL_l1)[0]\n",
    "            weight_TVFGL_grouplasso = portfolios(set1,theta_TVFGL_grouplasso)[0]\n",
    "            weight_TVFGL_laplacian_load = portfolios(set1,theta_TVFGL_laplacian_load )[0]\n",
    "            weight_TVFGL_l1_load = portfolios(set1,theta_TVFGL_l1_load)[0]\n",
    "            weight_TVFGL_grouplasso_load = portfolios(set1,theta_TVFGL_grouplasso_load)[0]\n",
    "            \n",
    "                      \n",
    "            #########################################################################################################\n",
    "           #######MODEL FORECASTS ARE HERE######\n",
    "            FEEW[j]=y_oos.iloc[window +j,:] - weight_EW.T@Yhat.iloc[window +j,:]\n",
    "            FEGL[j]=y_oos.iloc[window +j,:] - weight_GL.T@Yhat.iloc[window +j,:]\n",
    "            FEFGL[j]=y_oos.iloc[window +j,:] - weight_FGL.T@Yhat.iloc[window +j,:]\n",
    "            FETVFGL_laplacian[j]=y_oos.iloc[window +j,:] - weight_TVFGL_laplacian.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_l1[j]=y_oos.iloc[window +j,:] - weight_TVFGL_l1.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_grouplasso[j]=y_oos.iloc[window +j,:] - weight_TVFGL_grouplasso.T@Yhat.iloc[window +j,:] \n",
    "            \n",
    "            FETVFGL_laplacian_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_laplacian_load.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_l1_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_l1_load.T@Yhat.iloc[window +j,:] \n",
    "            FETVFGL_grouplasso_load[j]=y_oos.iloc[window +j,:] - weight_TVFGL_grouplasso_load.T@Yhat.iloc[window +j,:]\n",
    "            \n",
    "            #################SFEs ARE HERE##################\n",
    "            ###for h=1\n",
    "            SFEEW[j]=(FEEW[j])**2\n",
    "            SFEGL[j]=(FEGL[j])**2\n",
    "            SFEFGL[j]=(FEFGL[j])**2\n",
    "            SFETVFGL_laplacian[j]=(FETVFGL_laplacian[j])**2\n",
    "            SFETVFGL_l1[j]=(FETVFGL_l1[j])**2\n",
    "            SFETVFGL_grouplasso[j]=(FETVFGL_grouplasso[j])**2\n",
    "            SFETVFGL_laplacian_load[j]=(FETVFGL_laplacian_load[j])**2\n",
    "            SFETVFGL_l1_load[j]=(FETVFGL_l1_load[j])**2\n",
    "            SFETVFGL_grouplasso_load[j]=(FETVFGL_grouplasso_load[j])**2\n",
    "\n",
    "            ####################   \n",
    "        ###for h=1\n",
    "        MSFE_EW = np.mean(SFEEW)\n",
    "        MSFE_GL = np.mean(SFEGL)\n",
    "        MSFE_FGL = np.mean(SFEFGL)\n",
    "        MSFE_TVFGL_laplacian = np.mean(SFETVFGL_laplacian)\n",
    "        MSFE_TVFGL_l1 = np.mean(SFETVFGL_l1)\n",
    "        MSFE_TVFGL_grouplasso = np.mean(SFETVFGL_grouplasso)\n",
    "        MSFE_TVFGL_laplacian_load = np.mean(SFETVFGL_laplacian_load)\n",
    "        MSFE_TVFGL_l1_load = np.mean(SFETVFGL_l1_load)\n",
    "        MSFE_TVFGL_grouplasso_load = np.mean(SFETVFGL_grouplasso_load)\n",
    "       \n",
    "        print('MSFE_EW =', MSFE_EW, 'MSFE_GL =', MSFE_GL, 'MSFE_FGL =', MSFE_FGL,'MSFE_TVFGL_laplacian =', MSFE_TVFGL_laplacian,\n",
    "             'MSFE_TVFGL_l1 =', MSFE_TVFGL_l1, 'MSFE_TVFGL_grouplasso =', MSFE_TVFGL_grouplasso,\n",
    "             'MSFE_TVFGL_laplacian_load =', MSFE_TVFGL_laplacian_load,\n",
    "             'MSFE_TVFGL_l1_load =', MSFE_TVFGL_l1_load, 'MSFE_TVFGL_grouplasso_load =', MSFE_TVFGL_grouplasso_load)\n",
    "\n",
    "        ##########################################################\n",
    "        ###for h=1\n",
    "        error_EW[z] = MSFE_EW\n",
    "        error_GL[z] = MSFE_GL\n",
    "        error_FGL[z] = MSFE_FGL\n",
    "        error_TVFGL_laplacian[z] = MSFE_TVFGL_laplacian\n",
    "        error_TVFGL_l1[z] = MSFE_TVFGL_l1\n",
    "        error_TVFGL_grouplasso[z] = MSFE_TVFGL_grouplasso\n",
    "        \n",
    "        error_TVFGL_laplacian_load[z] = MSFE_TVFGL_laplacian_load\n",
    "        error_TVFGL_l1_load[z] = MSFE_TVFGL_l1_load\n",
    "        error_TVFGL_grouplasso_load[z] = MSFE_TVFGL_grouplasso_load\n",
    "\n",
    "       \n",
    "    #####################  \n",
    "    \n",
    "    ###for h=1\n",
    "    cum_EW[count] = np.mean(error_EW)\n",
    "    cum_GL[count] = np.mean(error_GL)\n",
    "    cum_FGL[count] = np.mean(error_FGL)\n",
    "    cum_TVFGL_laplacian[count] = np.mean(error_TVFGL_laplacian)\n",
    "    cum_TVFGL_l1[count] = np.mean(error_TVFGL_l1)\n",
    "    cum_TVFGL_grouplasso[count] = np.mean(error_TVFGL_grouplasso)\n",
    "    \n",
    "    cum_TVFGL_laplacian_load[count] = np.mean(error_TVFGL_laplacian_load)\n",
    "    cum_TVFGL_l1_load[count] = np.mean(error_TVFGL_l1_load)\n",
    "    cum_TVFGL_grouplasso_load[count] = np.mean(error_TVFGL_grouplasso_load)\n",
    "    \n",
    "       \n",
    "cum_h1 = np.concatenate((cum_EW,cum_GL,cum_FGL,cum_TVFGL_laplacian, cum_TVFGL_l1,cum_TVFGL_grouplasso,cum_TVFGL_laplacian_load,\n",
    "                         cum_TVFGL_l1_load,cum_TVFGL_grouplasso_load), axis=1)\n",
    "    \n",
    "savetxt('cum_h1_2breaks_c1is075.csv', cum_h1, delimiter=',')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
